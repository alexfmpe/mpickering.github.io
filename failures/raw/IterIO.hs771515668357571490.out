{-# LANGUAGE CPP #-}
#if defined(__GLASGOW_HASKELL__) && (__GLASGOW_HASKELL__ >= 702)
{-# LANGUAGE Safe #-}
#endif

{- |

This is the main module to import for the IterIO package.  It
re-exports several other modules and mostly consists of
documentation--first a high-level overview of the iteratee model, then
a more detailed tutorial, finally a discussion of the differences from
other iteratee packages and acknowledgments.

See the "Data.IterIO.Iter", "Data.IterIO.Inum", and
"Data.IterIO.ListLike" modules for more detailed documentation of data
structures and functions.  In addition, "Data.IterIO.Trans" (also
re-exported by this module) supplies functions that help you invoke
monad transformers from the mtl library from within the 'Iter' monad.

Several other potentially useful modules in the package are not
exported by default:

 * "Data.IterIO.Parse" includes parsec-like parsing combinators for
   iteratee input.

 * "Data.IterIO.Zlib" provides zlib and gzip format compression and
   decompression.

 * "Data.IterIO.SSL" provides support for SSL.

 * "Data.IterIO.Http" provides support for parsing and formatting
   HTTP, including handling form and file uploads (which can be
   processed in constant space).  This may be useful in conjunction
   with "Data.IterIO.HttpRoute", which provides simple request routing
   support for web servers.

 * "Data.IterIO.Atto" provides support for running attoparsec parsers
   on iteratee input (see
   <http://hackage.haskell.org/package/attoparsec/>).

 * "Data.IterIO.Extra" provides debugging functions, as well as a
   loopback iteratee that can be used to test a protocol
   implementation against itself.

-}

module Data.IterIO
    (module Data.IterIO.Iter
    , module Data.IterIO.Trans
    , module Data.IterIO.Inum
    , module Data.IterIO.ListLike

    -- * Overview
    -- $Overview

    -- * Tutorial
    -- $Tutorial

    -- * Differences from other iteratee packages
    -- $Differences

    -- * Acknowledgments
    -- $Acknowledgments
    ) where

import Data.IterIO.Iter hiding (null, run -- names that might collide
                               )
import Data.IterIO.Trans
import Data.IterIO.Inum
import Data.IterIO.ListLike

{- $Overview

   At a high level, an iteratee is a data sink that is fed chunks of
   data.  It may return a useful result, or its utility may lie in
   monadic side-effects, such as storing received data to a file.
   Iteratees are represented by the type @'Iter' t m a@.  Here @t@ is
   the type of data that the iteratee receives as input.  (@t@ must be
   an instance of 'ChunkData', such as 'String' or lazy @ByteString@.)
   @m@ is the 'Monad' in which the iteratee runs--for instance 'IO'
   (or an instance of 'MonadIO') for the iteratee to perform IO.  @a@
   is the type that the iteratee will return when it has consumed
   enough input to produce a result.

   An enumerator is a data source that feeds data chunks to an
   iteratee.  Enumerators are also iteratees.  We use the type @'Inum'
   tIn tOut m a@ to represent these /iteratee-enumerators/.  As an
   iteratee, an 'Inum' sinks data of some input type, generally
   designated @tIn@.  As an enumerator, the 'Inum' feeds data of a
   potentially different type, @tOut@, to another iteratee.  Thus, the
   'Inum' can be viewed as transcoding data from type @tIn@ to type
   @tOut@ for consumption by another iteratee.

   'Inum's are generally constructed using the functions @'mkInum'@
   and @'mkInumM'@ in module "Data.IterIO.Inum".  The first function
   uses a simple @'Iter' tIn m tOut@ to translate between input type
   @tIn@ and output type @tOut@.  The second function, @'mkInumM'@,
   allows construction of more complex 'Inum's.

   An important special kind of 'Inum' is an /outer enumerator/,
   which is just an 'Inum' with the void input type @()@.  Outer
   enumerators are sources of data.  Rather than transcode input
   data, they produce data from monadic actions (or from pure data
   in the case of 'inumPure').  The type 'Onum' represents outer
   enumerators and is a synonym for 'Inum' with an input type of
   @()@.

   To execute iteratee-based IO, you must apply an 'Onum' to an
   'Iter' with the '|$' (\"pipe apply\") binary operator.

   An important property of enumerators and iteratees is that they can
   be /fused/.  The '|.' (\"fuse leftward\") operator fuses two
   'Inum's together (provided the output type of the first is the
   input type of the second), yielding a new 'Inum' that transcodes
   from the input type of the first to the output type of the second.
   Similarly, the '.|' (\"fuse rightward\") operator fuses an 'Inum'
   to an 'Iter', yielding a new 'Iter' with a potentially different
   input type.

   Enumerators of the same type can also be /concatenated/, using
   the 'cat' function.  @enum1 ``cat`` enum2@ produces an enumerator
   whose effect is to feed first @enum1@'s data then @enum2@'s data
   to an 'Iter'.
-}

{- $Tutorial

 #tutorial#

The iterIO library performs IO by hooking up sources of data, called
/enumerators/, to data sinks, called /iteratees/, in a manner
reminiscent of Unix command pipelines.  Compared to lazy IO, the
enumerator/iteratee paradigm provides better error handing,
referential transparency (which should, after all, be one of the big
advantages of Haskell), and equally convenient composition of protocol
layers and parsers without worrying about IO chunk boundaries.

Enumerators, implemented by the type 'Onum' (short for
/outer enumerator/, for reasons that will become clear below), are so
called because they enumerate all data elements (e.g., bytes or
packets) in some source such as a file or socket.  Hence, an
enumerator should be viewed as a /source/ outputting chunks of data
whose type is a @'Monoid'@.  (Actually, the input type must be of
class 'ChunkData', which is a @'Monoid'@ that additionally has a
method @'null'@ to test whether a piece of data is equal to
'mempty'.)

Iteratees, implemented by the type 'Iter', should be viewed as /sinks/
consuming data.  When executing IO, the library /iterates/ over all
data elements output by the source, using an iteratee to produce a
result.  The source may output data in chunks whose boundaries do not
coincide with logical message units; iteratees handle this
transparently, simplifying programming.

Here is a simple example:

@
    -- Return the first line of a file
    headFile :: FilePath -> IO String
    headFile path = 'enumFile' path '|$' 'lineI'
@

'enumFile' enumerates the contents of a file.  'lineI' returns a line
of input (discarding the newline).  '|$' is the /pipe apply/ operator
that applies an 'Onum' to an 'Iter', returning the result of the
'Iter'--in this case the first line of the file named @path@.

An `Iter`'s main purpose may not be to produce a result.  Some 'Iter's
are primarily useful for their side effects.  For example, 'stdoutI'
writes data to standard output; 'handleI' similarly writes output to
an arbitrary file handle.  Thus, the following function copies the
contents of a file to standard output:

@
    -- Copy file to standard output
    catFile :: FilePath -> IO ()
    catFile path = 'enumFile'' path '|$' 'stdoutI'
@

'enumFile'' is like 'enumFile' above, but type restricted to data in
the lazy @'ByteString'@ format, which is more efficient than plain
'String's.  ('enumFile' supports multiple types, but in this example
there is not enough information for Haskell to choose one of them, so
we must use 'enumFile'' or use @::@ to specify a type explicitly.)
Once again, '|$' is used to execute the IO actions, but, this time,
the return value is just @()@; the interesting action lies in the side
effects of writing data to standard output while iterating over the
input with 'stdoutI'.

The real power of the iteratee abstraction lies in the fact that
'Iter's are monadic computations.  One 'Iter' may invoke another to
make use of the first one's results.  Here is an example of a function
that returns the first two lines of a file:

@
    -- | Return first two lines of file
    head2File :: FilePath -> IO (String, String)
    head2File path = 'enumFile' path '|$' lines2I
@

@
    -- | Iter that returns next two lines as a pair
    lines2I :: (Monad m) => 'Iter' String m (String, String)
    lines2I = do
      line1 <- 'lineI'
      line2 <- 'lineI'
      return (line1, line2)
@

This example illustrates several points.  First, consider the type of
the @lines2I@ function:  @'Iter' String m (String, String)@.  The
'Iter' type constructor takes three type arguments.  The first,
'String' in this case, specifies the type of input expected by the
iteratee.  The last type, @(String, String)@ in this case, specifies
the result type of the iteratee.  Finally, the middle type, @m@, is a
monad, because @'Iter' t@ (for a given input type @t@) is a monad
transformer (i.e., it is an instance of the 'MonadTrans' class).  In
this case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,
because @head2File@ is returning a result in the @IO@ monad.  However,
@lines2I@ would work equally well with any other monad.

Next, notice the functioning of @'Iter' String m@ as a monad.  The
type of 'lineI' in the above example is @'Iter' String m String@.  The
@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to
bind the results to @line1@ and @line2@.  The monadic bind operator
hides the details of IO chunk boundaries.  If, for instance, 'lineI'
needs more input because a newline character has not yet been read,
'lineI' returns to the containing enumerator asking for more data.  If
the first 'lineI' receives more than a line of input, it simply passes
the residual input to the next invocation of 'lineI'.  Both of these
actions are hidden by the syntax, making most code much easier to read
and write.

That explains the iteratee type 'Iter'.  The enumerator type, 'Onum',
has the same three type arguments.  Thus, the type of 'enumFile', as
instantiated in the above examples, is @'enumFile' :: 'Onum' String IO
a@.  Most 'Onum' types are polymorphic in the last argument, so as to
be able to return whatever type the 'Iter' is returning.  (In fact,
'enumFile' is polymorphic in the first two arguments, too, so as to
work with multiple @String@-like types and any monad in the
@'MonadIO'@ class.)

Here is an example of an 'Iter' with side effects:

@
    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()
    liftIOexampleI = do
      line <- 'lineI'
      'liftIO' $ putStrLn $ \"First line is: \" ++ line
      next <- 'takeI' 40
      'liftIO' $ putStrLn $ \"And the next 40 bytes are: \" ++ next
@

Unlike @lines2I@, @liftIOexampleI@ does not return any interesting
result, but it uses the @'liftIO'@ monad transformer method to output
the first line of the file, followed by the next 40 bytes.  The
'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the
requested number of characters or bytes, unless an EOF (end-of-file)
is encountered.

Of course, the real power of command pipelines is that you can hook
multiple commands together.  For instance, say you want to know how
many words in the system dictionary files contain a double k and start
with a lower-case letter.  You could run a command like this:

>    cat /usr/share/dict/words /usr/share/dict/extra.words \
>        | grep kk | grep '^[a-z]' | wc -l

Let's see how to do something equivalent with iteratees, starting with
the @wc -l@ command, which counts lines.  Here is an equivalent iteratee:

@
    lineCountI :: (Monad m) => 'Iter' String m Int
    lineCountI = count 0
        where count n = do
                line <- 'safeLineI'
                case line of
                  Just _  -> count (n+1)
                  Nothing -> return n
@

The 'safeLineI' function is like 'lineI', but returns a @'Maybe'
'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF
condition.  ('lineI' throws an exception on EOF.)

What about the @grep@ command?  @grep@ sits in the middle of a
pipeline, so it acts both as a data sink and as a data source.
This is why we call such a pipeline stage an
/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@
equivalent, since multiple pipeline stages are going to be considering
the file one line at a time, let's first build an 'Inum' to separate
input into lines:

@
    import Data.ByteString as S
    import Data.ByteString.Char8 as S8
@

@
    -- | Break input into lines of type S.ByteString, as this type
    -- works most conveniently with regular expressions.  (Otherwise,
    -- we would prefer lazy ByteStrings.)
    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a
    inumToLines = 'mkInum' $ do
                    line <- 'lineI'
                    return [line]
@

'Inum' takes four type arguments, compared to only three for 'Onum'.
That's because an 'Inum' is acting as both an iteratee and an
enumerator; it needn't be processing the same type of data in both
roles.  In the above example, when acting as an iteratee,
@inumToLines@ consumes data of type @S.ByteString@ (the first type
argument), accepting one long stream of unstructured bytes.  However,
as an enumerator, @inumToLines@ produces output of type
@[S.ByteString]@ (the second type argument), a /list/ of strings, one
per line of the file.  In general the type @'Inum' tIn tOut m a@ is an
iteratee-enumerator taking input type @tIn@, producing output type
@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m
a@.

In fact, an 'Onum' is just a special kind of 'Inum' with the void
input type @()@.  The type @'Onum' t m a@ is just a synonym for
@'Inum' () t m a@.  Most operations on 'Inum's can be used with
'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not
true, however.  For example, the '|$' operator requires an 'Onum', as
it wouldn't know what data to feed to an arbitrary 'Inum'.  (If you
need it, however, there is a function @run@, hidden by this module but
exported by "Data.IterIO.Iter", that executes an iteratee computation
of arbitrary input type by feeding EOF as input.)

Iteratee-enumerators are generally constructed using either 'mkInum'
or `mkInumM`, and by convention most 'Inum's have names starting
\"@inum@...\", except that 'Onum' names start \"@enum@...\".  'mkInum'
takes an argument of type @'Iter' tIn m tOut@ that consumes input of
type @tIn@ to produce output of type @tOut@.  (For @inumToLines@,
@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine
for simple stateless translation functions, but sometimes one would
like to keep state and use more complex logic in an 'Inum'.  For that,
the 'mkInumM' function creates an 'Inum' out of a computation in a
dedicated 'InumM' monad.  See the "Data.IterIO.Inum" documentation for
more information on 'mkInumM'.  In @inumToLines@, we do not need to
keep state.  We are happy just to let 'lineI' throw an exception on
EOF, which `mkInum` will catch and handle gracefully.

Throwing an EOF exception--either implicitly by executing another
'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to
exit an 'Inum' created by 'mkInum'.  The other way is to return empty
input.

We similarly define an 'Inum' to filter out lines not matching a
regular expression (using the "Text.Regex.Posix.ByteString" library),
and a simple 'Inum' to count list elements (since @lineCountI ::
'Iter' String m Int@ has input data type @String@, while after
@inumToLines@ we need an 'Iter' with input data type
@[S.ByteString]@).

@
    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a
    inumGrep re = `mkInum` $ do
      line <- 'headI'
      if line =~ packedRe then return [line] else return []
        where
          packedRe = S8.pack re
@

@
    lengthI :: (Monad m) => 'Iter' [t] m Int
    lengthI = count 0
        where count n = do
                line <- 'safeHeadI'
                case line of
                  Just _  -> count (n+1)
                  Nothing -> return n
@

Now we are almost ready to assemble all the pieces.  But recall that
the '|$' operator applies one 'Onum' to one 'Iter', yet now we have
two 'Onum's (because we want to look through two files), and three
'Inum's that we want to compose into a pipeline.  The library
supports two types of composition for pipeline stages:
/concatenation/ and /fusing/.

Two 'Inum's (or 'Onum's) of the same type can be /concatenated/ with
the 'cat' function, producing a new data source that enumerates all of
the data in the first 'Inum' followed by all of the data in the
second.

There are two /fusing/ operators.  The left-associative '|.' operator
fuses two 'Inum's, provided the output type of the first is the input
type of the second.  (Mnemonic: it produces a pipeline stage that is
open on the right hand side, as it still needs to be applied to an
iteratee with '|$'.)  The right-associative '.|' operator fuses an
'Inum' to an 'Iter', producing a new 'Iter'.

The fusing operators bind more tightly than the infix concatenation
functions, which in turn bind more tightly than '|$'.  (Concatenation
operators can also be used through prefix function application, which
binds most tightly.)  Hence, putting it all together, we produce the
following Haskell equivalent to the above Unix pipeline:

@
    grepCount :: IO Int
    grepCount = 'enumFile' \"\/usr\/share\/dict\/words\" '|.' inumToLines
                    ``cat`` 'enumFile' \"\/usr\/share\/dict\/extra.words\" '|.' inumToLines
                '|$' inumGrep \"kk\"
                        '.|' inumGrep \"^[a-z]\"
                        '.|' lengthI
@

One often has a choice as to whether to fuse an 'Inum' to the
'Onum', or to the 'Iter'.  For example, @grepCount@ could
alternatively have been implemented as:

@
    grepCount' :: IO Int
    grepCount' = 'cat' ('enumFile' \"\/usr\/share\/dict\/words\" '|.' inumToLines)
                         ('enumFile' \"\/usr\/share\/dict\/extra.words\" '|.' inumToLines)
                    '|.' inumGrep \"kk\"
                    '|.' inumGrep \"^[a-z]\"
                 '|$' lengthI
@

In this case, the two are essentially equivalent.  However, for error
handling purposes, one should fuse together pipeline stages in which
errors have similar consequences.  Often an 'Inum' or 'Onum' failure
is less serious than an 'Iter' failure.  For example, in the above
example, if 'enumFile' fails because one of the files does not exist,
we might want to continue processing lines from the next file.
Conversely, if @lengthI@ fails or one of the @inumGrep@ stages fails
(most likely because the regular expression is illegal), there is not
much point in continuing the program.  This is why the first example
fused @inumGrep@ to @lengthI@, though this won't matter until we
actually handle errors (see below).

Another alternative would have been to swap the order of concatenation
and fusing:

@
    grepCount'' :: IO Int
    grepCount'' = 'cat' ('enumFile' \"\/usr\/share\/dict\/words\")
                           ('enumFile' \"\/usr\/share\/dict\/extra.words\")
                      '|.' inumToLines
                  '|$' inumGrep \"kk\"
                      '.|' inumGrep \"^[a-z]\"
                      '.|' lengthI
@

This last version changes the semantics of the counting slightly.
With @grepCount''@, if the first file has an incomplete last line,
this line will be merged with the first line of the second file, which
is probably not what you want.  (For instance, if the incomplete last
line of the first file starts with a capital letter, then the first
line of the second file will not be counted even if it starts with a
lower-case letter and contains two \"k\"s.)

One limitation of all the @grepCount@ variants shown so far is that if
the first file does not exist, the whole operation aborts.  This
might or might not be reasonable when counting lines, but in other
contexts we may want to resume after failure.  Suppose we want to
implement a function like the Unix @grep@ command that searches for a
string in a bunch of files and prints all matching lines.  If opening
or reading a file produces an error, the function should print the
error message and continue on with the next file.

Error handling is provided by the 'catchI' and 'inumCatch' functions,
which are roughly equivalent to the standard library @'catch'@
function.  There is also a 'throwI' function analogous to @'throwIO'@
in the standard library.  Because @'catch'@ only works in the IO
monad, 'catchI' and 'inumCatch' work by propagating synchronous
exceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors
into such synchronous exceptions.  Unfortunately, there is no way to
handle asynchronous exceptions such as those that arise in lazily
evaluated pure code (e.g., divide by zero) or those thrown by another
thread using @'throwTo'@.  Fortunately, for our @grep@ example, we
only need to catch IO errors.

Here is the @grep@ code.  We will analyze it below.

@
    grep :: String -> [FilePath] -> IO ()
    grep re files
        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI
        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI
        where
          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler
          handler :: 'IOError'
                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)
                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)
          handler e result = do
            liftIO (hPutStrLn stderr $ show e)
            'resumeI' result
          linesOutI = do
            mline <- 'safeHeadI'
            case mline of
              Just line -> do liftIO $ S.putStrLn line
                              linesOutI
              Nothing -> return ()
@

There are two cases.  If the list of files to search is null, @grep@
simply reads from standard input, in which case there is only one
input stream and we do not care about resuming.  In the second case,
we use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'
is generated by the function @enumLines@, which fuses 'enumFile' to
our previously defined @inumToLines@, but also wraps the exception
handler function @handler@ around the enumerator using 'inumCatch'.

Note that unlike @catch@, 'inumCatch' expects an exception handler to
have /two/ arguments.  The first argument, @e@ in this example, is the
exception itself.  As with @catch@, the type of @e@ determines which
exceptions are caught, which is why we must either specify an explicit
type signature for @handler@ or somewhere specify @e@'s type
explicitly, for instance with:

>          ...
>            liftIO (hPutStrLn stderr $ show (e :: IOError))
>          ...

Note that 'IOError' doesn't expose a type constructor, but for
exception types that do, it often suffices to define the function with
the exception constructor, as:

>          handler e@(SomeException _) result = do ...

The second argument to @handler@, @result@, is the failed state of the
iteratee, which contains more information than just the exception.  In
the case of an 'Inum' failure, it contains the state of the 'Iter'
that the 'Inum' was feeding when it failed.  The type of 'result' is
'IterR'--which is the type returned by 'Iter's when they are fed
chunks of data.  'IterR' takes the same three type arguments as
'Iter'.  The function 'resumeI' extracts and returns an @'Iter'
[S.ByteString] IO a@ from this failed result.  Thus, the next
enumerator in a concatenated series can continue feeding it input.
If, instead of resuming, you want to re-throw the error, it suffices
to re-execute the failed result with @'reRunIter'@.  For instance,
suppose we want to continue executing @grep@ when a named file does
not exist, but if some other error happens, we want to re-throw the
exception to abort the whole program.  This could be achieved as
follows:

>          handler e result = do
>            if isDoesNotExistError e
>              then do liftIO (hPutStrLn stderr $ show e)
>                      resumeI result
>              else reRunIter result

Because printing an exception is so common, there is a function
'verboseResumeI' that prints exceptions before resuming (also
prefixing the program name).  Thus, we can simplify the above function
to:

>          handler e result = if isDoesNotExistError e
>                               then verboseResumeI result
>                               else reRunIter result

These last two @handler@ functions also do away with the need for an
explicit type signature, because the function @'isDoesNotExistError'@
has argument type 'IOError', constraining the type of @e@ to the type
of exceptions we want to catch.

-}
{- $Differences

The Iteratee approach was originally advocated by Oleg Kiselyov (see
talk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The
main implementation by Kiselyov and John Lato is simply called
/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another
realization of the iteratee concepts is the /enumerator/ package
(<http://hackage.haskell.org/package/enumerator>).  IterIO is a
re-implementation of these concepts from scratch.  This section
discusses the differences between previous packages and iterIO, both
as a means for motivating iterIO's design and as a set of suggestions
for improving other iteratee implementations.

* /Base abstraction/

The iterIO package represents an iteratee as a pure function from a
chunk of pending input data to an iteratee result of type 'IterR':

@
  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }
@

An 'IterR' can yield a result and residual input, or it can ask for
more input, or it can request to have an action executed in the
underlying monad, or it can signal failure.  The fact that all
iteratees are functions of input ensures that iteratees generally see
/all/ pending input.  Thus, iteratees can do things like measure the
length of buffered input to subtract it from the current file offset
and determine the effective position in a file.

`IterR`'s division of iteratee results into different outcomes such as
needing input or needing monadic actions allows the library to
distinguish between pure iteratees and those with potential side
effects.  The ability to know that a specific iteratee is a pure
function in many cases allows one to parse LL(*) grammars without
large amounts of input buffering for backtracking (see below).

In contrast, the iteratee package uses continuation passing style
(CPS), in which an iteratee is a function taking two continuation
functions--one to call when done, and a second to call when either
requesting more input or failing:

> -- From the iteratee package:
> newtype Iteratee s m a = Iteratee{ runIter :: forall r.
>        -- First the "onDone" function:
>           (a -> Stream s -> m r) ->
>        -- Next the "onCont" function:
>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->
>           m r}

CPS has the advantage of exposing the bind operator of the underlying
monad, making 'lift' cheap and simple.  Moreover, splitting into two
continuations saves the first and most common one (i.e., \"onDone\")
from the overhead of checking whether an error condition or request
for more input has occurred.  See
<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>
for a good discussion of the advantages of CPS.

Because of CPS, iteratee should be capable of delivering the best
performance of the three iteratee packages.  A disadvantage of
iterIO's approach is that every invocation of 'lift' must be
propagated all the way up the call chain, where a small amount of
overhead is added for each enclosing 'catchI' or similar call.  While
iterIO can handle most successful 'IterR' outcomes and caught
exceptions locally without popping back up the call stack, there is
also potentially overhead from actually checking that the outcome was
successful at each bind site.  (GHC's inliner may be able to avoid the
check in some cases.)

However, iteratee lacks several features of iterIO; offering these
features would likely reduce the benefits of CPS and complicate code.
For instance, there is no way to execute a pure iteratee without
monadic actions (the benefit touted above and described below for
LL(*) parsing).  Moreover, iteratee's exception mechanism discards the
current location in the input stream, making it unsuitable for failed
parse alternatives.  IterIO provides a general control mechanism to
make arbitrary requests from enumerators (such as seek, tell,
getpeername, get SSL information, etc.); iteratee instead overloads
the exception mechanism for control purposes, which prevents control
operations from returning values.  Thus, while iteratee can implement
seek, it cannot, for instance, implement tell.

The enumerator package's approach is closer to iterIO's, but makes
every iteratee into a monadic action in the underlying monad @m@:

> -- From the enumerator package:
> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }

Here @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper
disallows iterIO's LL(*) parsing tricks.  It also causes gratuitous
invocation of @m@'s bind function, which can be expensive when using
stacks of monad transformers.  Furthermore, enumerator discards the
input state on all errors, making it impossible to resume from
failures that leave the input in a known state (such as a parsing
lookahead failure).

* /Uniformity of abstraction/

IterIO's abstractions were refined over many iterations to become
minimal yet highly expressive and familiar to Unix shell users.  Thus,
we have 'Iter's, which are data sinks that consume input and produce a
result.  Then we have 'Inum's, which are also 'Iter's.  These two data
types and can combined through pipes (i.e., fusing) and concatenation,
both of which have direct analogues in the Unix @|@ (pipe) operator
and @cat@ command.

Basing everything around these few concepts makes the library easier
to learn and use.  For instance, because all 'Inum's are 'Iter's,
there is only one set of 'Iter' building blocks to learn.  'Inum'
implementations invoke the same 'Iter's that are used to build other
'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling
mechanism.  Finally, because 'Onum's are also 'Inum's, one set of
fusing and concatenation operators works for both.

By contrast, both the iteratee and enumerator packages use enumerator
types that are not iteratees.  Hence, constructing enumerators is
harder and requires a different error handing mechanism.  The packages
must introduce a third, hybrid \"Enumeratee\" type for inner pipeline
stages, and fusing Enumerators to Enumeratees is a different function
from fusing Enumeratees together.

Funneling everything through a small number of abstractions also
ensures that the right thing happens in corner cases.  In particular,
all enumerator application happens through the pipe operator.  Though
there are two pipe operators, a left associative one and a right
associative one, they internally use the same function:  @a '|.' b =
(a '.|') . b@.  Similarly, the pipe application operators ('|$' and
'.|$') are defined in terms of '.|'.

'.|' guarantees that its right-hand argument will receive an EOF when
the left hand argument terminates (whether normally or through an
exception).  This is crucial for managing resources such file
descriptors, and works no matter how convoluted the control structure
of your program.

Consider the following realistic scenario of a web server constructed
as an 'Inum' that translates from HTTP requests to HTTP responses.
(Such an 'Inum' is provided by the function 'inumHttpServer' in
"Data.IterIO.HTTP".)  The server's accept loop would resemble the
following:

@
   loop = do
     (sock, _) <- Net.accept $ listen_socket
     _ <- forkIO $ do
            (iter, enum) <- 'iterStream' (sock)
            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter
     loop
@

This code depends on the fact that 'iterStream' closes @sock@ after
both the @iter@ has received an EOF and the @enum@ has returned.  One
level down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',
and has code looking something like this:

@
     req <- 'httpReqI'                              -- parse HTTP request
     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler
     'irun' $ enumHttpResp resp Nothing             -- send response to client
@

The @handler@ gets run on the body of the message, and might decide to
process an HTTP POST request by saving an uploaded file to disk, for
instance with code like this:

@
     let saveFile _ field
           | ffName field == S8.pack \"file\" = do
                            h <- liftIO $ openBinaryFile \"upload\" WriteMode
                            'handleI' h ``finallyI`` liftIO (hClose h)
           | otherwise = return ()
     in foldForm req saveFile ()
@

@foldForm@ internally is invoking an 'Inum' that parses HTTP
multipart/form-data to pipe each field of the form to the @saveFile@
function.

Now suppose 'inumHttpBody' fails (most likely because it receives an
EOF before reading the number of bytes specified in the Content-Length
header).  Because 'inumHttpBody' is fused to @handler@, the failure
will cause @handler@ to receive an EOF, which will cause @foldForm@ to
fail, which will cause 'handleI' to receive an EOF and return, which
will ensure 'hClose' runs and the file handle @h@ is not leaked.

Once the EOFs have been processed, the exception will propagate
upwards making 'inumHttpServer' fail, which in turn will send an EOF
to @iter@.  Then the exception will cause @enum@ to fail, after which
@sock@ will be closed.  In summary, despite the complex structure of
the web server, because all the components are fused together with
pipe operators, corner cases like this just work with no need to worry
about leaked file descriptors.

* /Uniform error-handling and simplified monad transformers/

The iterIO library provides a traditional throw and catch exception
mechanism using its own functions 'throwI' and 'catchI', but keeping
the standard library exception hierarchy from "Control.Exception".
All of the support routines are carefully crafted to ensure that this
single exception mechanism is the only one you ever need, so that you
don't end up having to integrate different components with different
error strategies, a situation summarized amusingly in the following
blog post:
<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.

A key to uniform error handling is ensuring that errors can be
propagated cleanly across different monads and transformers.  Thus,
for instance, the iterIO 'liftIO' function translates all uncaught IO
errors into 'Iter' errors.

More importantly, iterIO is designed to support the standard mtl monad
transformers while keeping 'Iter' as the outermost monadic type.  For
instance, if deep in the middle of some @'Iter' t 'IO'@ computation
you need a state transformer monad, you can invoke one with
'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen
by comparing their effective types, 'runStateTI' keeps the 'Iter'
monad on the outside, and thus can cleanly propagate failures out of
the 'StateT' subcomputation:

> runStateT  :: StateT s m a -> s -> m (a, s)
>
> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)

Similarly, there is a function @'liftI' :: (MonadTrans t) => Iter
s m a -> Iter s (t m) a@ that can be used to execute a computation in
which a level of monad transformer is stripped off the inner monadic
type.

An equally important feature is the ability to distinguish 'Iter'
failures from 'Inum' failures, given that the former are often more
serious than the latter.  As shown by the @grep@ example in the
tutorial above, when one in a series of concatenated 'Inum's fails,
you often want to keep going without losing the state of the 'Iter'.
The enumerator package does not appear to support this distinction.
The iteratee package might, but it is not clear how to implement the
iteratee equivalent of the @grep@ example above.

By contrast, iterIO's 'Inum' mechanism was designed to be intuitive.
If you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then
you will catch exactly the errors thrown by those 'Inum's, not those
thrown by pipeline stages outside the scope of the 'inumCatch' call.

It is because of this unified error handling mechanism that examples
such as the HTTP server above can be guaranteed not to leak resources.

* /Parser combinators for LL(*) grammars/

IterIO's "Data.IterIO.Parse" module supports parsing of iteratee input
using combinators similar to those found in parsec.  However, parsec
supports only LL(1) grammars, and can lead to confusing failures--for
instance the parser @string \"foo\" \<|\> string \"for\"@ would fail
on input @\"for\"@.  IterIO, by contrast, supports full LL(*) parsing,
meaning a parser can look arbitrarily far ahead before failing.

LL(*) parsers are generally disfavored because of their potential to
consume arbitrarily large amounts of memory to remember input for
backtracking.  However, iterIO offers two mechanisms that mitigate the
problem.

First, because 'Iter's are constructed in such a way as to
differentiate requests for more input from execution of monadic
actions, it is possible to run multiple parsers in parallel.  Consider
a hypothetical parser such as the following, designed to recognize the
input format and parse either XML or JSON data:

@
  parser :: 'Iter' 'L.ByteString' m Value
  parser = ('string' \"\<!DOCTYPE\" >> parseXml)
           \<|\> ('char' \'{\' >> parseJson)
@

@\<|\>@ is an infix synonym for the iterIO function 'multiParse',
which attempts to run two parsers concurrently on input as it arrives.
Because 'string' and 'char' are both pure parser combinators with no
monadic side effects, it is possible to run them both concurrently
without fear that the second rule--if it fails--will nonetheless have
produced side effects.  In fact, at least one of the 'string' or the
'char' action will fail almost immediately, likely on the first chunk
of data.  After one of the two has signaled a parse error, there is no
longer any need to store input for backtracking.  Note this works even
if the subsequent functions @parseXml@ and @parseJson@ have monadic
side effects, because 'multiParse' doesn't need to invoke those
monadic actions to determine that one of the two parsers has failed.

A second way to avoid large amounts of storage for backtracking is to
use iterIO's '\/' operator, which is an infix synonym for 'ifNoParse'.
The formulation @iter '\/' no $ yes@ splits a parser into three
components.  @iter@ is executed with backtracking enabled.  If it
succeeds, then the saved data is discarded, @iter@'s result is fed to
the function @yes@, and any further failures will not cause input to
be rewound.  If, on the other hand, @iter@ fails, then input is
rewound and @no@ is executed.  The '\/' operator is very convenient
for long folds whose individual elements do not consume a lot of
input.  For example, to parse and sum a list of numbers (given a
parser @number@ that skips spaces then parses one number), you might
do something like this:

> parseAndSumIntegerList :: Iter String IO Int
> parseAndSumIntegerList = loop 0
>     where loop n = number \/ return n $ \n' -> loop (n + n')

Regardless of the length of the list of numbers being parsed,
@sumNumbers@ only ever needs to backtrack over the input consumed by a
single iteration of @number@, which is likely a small amount of extra
memory to keep around.

If you do want an LL(1) parser combinator library, iterIO supports
seamless integration with the attoparsec package.  The function 'atto'
in "Data.IterIO.Atto" turns an attoparsec @Parser@ into an 'Iter'
monad, treating an attoparsec failure as an 'Iter' exception that can
be handled in the usual way with 'ifParse' or 'multiParse', or just
caught with 'catchI'.  (Attoparsec has the additional advantage of
solving the annoying @string \"foo\" \<|\> string \"for\"@ issue by
special-casing @string@ to have more lookahead.)

Preliminary testing suggests that attoparsec can be about three times
faster than "Data.IterIO.Parse" on parse-intensive workloads.  The
limitation is that attoparsec parsers must be pure.  A good compromise
may be to use IterIO for coarse-grained parsing, and attoparsec for
more complex data structures.  For example, you might want to use
iterIO's parsing of HTTP multipart/form-data (so as to be able to pipe
files to disk in constant space), but for fields with JSON data, use
'atto' to pipe the contents to the excellent attoparsec-based aeson
package.

-}
{- $Acknowledgments

Daniel Giffin contributed numerous suggestions and improvements to
both the code and documentation.  Deian Stefan and David Terei helped
with testing and improving the package, as well as understanding
various relevant aspects of Haskell and GHC.  Mike Hamburg made the
key suggestion of defining 'Onum's as type-restricted 'Inum's.  The
author is grateful to John Lato for helping him understand much of the
important design rationale behind the original iteratee package.  This
work was funded by the DARPA Clean-Slate Design of Resilient,
Adaptive, Secure Hosts (CRASH) program, BAA-10-70.

-}
--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum
--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk
--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk
--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI
--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI
--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF
--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's--  LocalWords:  ByteString enumfile MonadTrans liftIOexampleI liftIO putStrLn
--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr
--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin
--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin
--  LocalWords:  linesOutI foldr enumLines IOError IterR hPutStrLn stderr mline
--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's--  LocalWords:  resumeI isDoesNotExistError reRunIter verboseResumeI Oleg Lato
--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter
--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC
--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC
--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI
--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI
--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto
--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto
--  LocalWords:  combinator aeson Giffin Deian Terei DARPA--  LocalWords:  multiParse ifNoParse parseAndSumIntegerList sumNumbers ifParse
--  LocalWords:  combinator aeson Giffin Deian Terei DARPA



==============
../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs
==============
lengths:(44247,43016)

==============

({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:1:1 }
 Just (Ann (DP (0,0)) (ColDelta 1) DP (0,0) [] [((AnnComment DComment (DP (0,0),DP (0,20)) "{-# LANGUAGE CPP #-}" Nothing),DP (0,0)),((AnnComment DComment (DP (1,1),DP (1,64)) "#if defined(__GLASGOW_HASKELL__) && (__GLASGOW_HASKELL__ >= 702)" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,22)) "{-# LANGUAGE Safe #-}" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,6)) "#endif" Nothing),DP (1,1)),((AnnComment DComment (DP (2,1),DP (41,3)) "{- |\n\nThis is the main module to import for the IterIO package.  It\nre-exports several other modules and mostly consists of\ndocumentation--first a high-level overview of the iteratee model, then\na more detailed tutorial, finally a discussion of the differences from\nother iteratee packages and acknowledgments.\n\nSee the \"Data.IterIO.Iter\", \"Data.IterIO.Inum\", and\n\"Data.IterIO.ListLike\" modules for more detailed documentation of data\nstructures and functions.  In addition, \"Data.IterIO.Trans\" (also\nre-exported by this module) supplies functions that help you invoke\nmonad transformers from the mtl library from within the 'Iter' monad.\n\nSeveral other potentially useful modules in the package are not\nexported by default:\n\n * \"Data.IterIO.Parse\" includes parsec-like parsing combinators for\n   iteratee input.\n\n * \"Data.IterIO.Zlib\" provides zlib and gzip format compression and\n   decompression.\n\n * \"Data.IterIO.SSL\" provides support for SSL.\n\n * \"Data.IterIO.Http\" provides support for parsing and formatting\n   HTTP, including handling form and file uploads (which can be\n   processed in constant space).  This may be useful in conjunction\n   with \"Data.IterIO.HttpRoute\", which provides simple request routing\n   support for web servers.\n\n * \"Data.IterIO.Atto\" provides support for running attoparsec parsers\n   on iteratee input (see\n   <http://hackage.haskell.org/package/attoparsec/>).\n\n * \"Data.IterIO.Extra\" provides debugging functions, as well as a\n   loopback iteratee that can be used to test a protocol\n   implementation against itself.\n\n-}" Nothing),DP (2,1)),((G AnnModule),DP (46,1)),((G AnnVal),DP (0,1)),((G AnnWhere),DP (0,1)),((AnnComment DComment (DP (2,1),DP (54,3)) "{- $Overview\n\n   At a high level, an iteratee is a data sink that is fed chunks of\n   data.  It may return a useful result, or its utility may lie in\n   monadic side-effects, such as storing received data to a file.\n   Iteratees are represented by the type @'Iter' t m a@.  Here @t@ is\n   the type of data that the iteratee receives as input.  (@t@ must be\n   an instance of 'ChunkData', such as 'String' or lazy @ByteString@.)\n   @m@ is the 'Monad' in which the iteratee runs--for instance 'IO'\n   (or an instance of 'MonadIO') for the iteratee to perform IO.  @a@\n   is the type that the iteratee will return when it has consumed\n   enough input to produce a result.\n\n   An enumerator is a data source that feeds data chunks to an\n   iteratee.  Enumerators are also iteratees.  We use the type @'Inum'\n   tIn tOut m a@ to represent these /iteratee-enumerators/.  As an\n   iteratee, an 'Inum' sinks data of some input type, generally\n   designated @tIn@.  As an enumerator, the 'Inum' feeds data of a\n   potentially different type, @tOut@, to another iteratee.  Thus, the\n   'Inum' can be viewed as transcoding data from type @tIn@ to type\n   @tOut@ for consumption by another iteratee.\n\n   'Inum's are generally constructed using the functions @'mkInum'@\n   and @'mkInumM'@ in module \"Data.IterIO.Inum\".  The first function\n   uses a simple @'Iter' tIn m tOut@ to translate between input type\n   @tIn@ and output type @tOut@.  The second function, @'mkInumM'@,\n   allows construction of more complex 'Inum's.\n\n   An important special kind of 'Inum' is an /outer enumerator/,\n   which is just an 'Inum' with the void input type @()@.  Outer\n   enumerators are sources of data.  Rather than transcode input\n   data, they produce data from monadic actions (or from pure data\n   in the case of 'inumPure').  The type 'Onum' represents outer\n   enumerators and is a synonym for 'Inum' with an input type of\n   @()@.\n\n   To execute iteratee-based IO, you must apply an 'Onum' to an\n   'Iter' with the '|$' (\\\"pipe apply\\\") binary operator.\n\n   An important property of enumerators and iteratees is that they can\n   be /fused/.  The '|.' (\\\"fuse leftward\\\") operator fuses two\n   'Inum's together (provided the output type of the first is the\n   input type of the second), yielding a new 'Inum' that transcodes\n   from the input type of the first to the output type of the second.\n   Similarly, the '.|' (\\\"fuse rightward\\\") operator fuses an 'Inum'\n   to an 'Iter', yielding a new 'Iter' with a potentially different\n   input type.\n\n   Enumerators of the same type can also be /concatenated/, using\n   the 'cat' function.  @enum1 ``cat`` enum2@ produces an enumerator\n   whose effect is to feed first @enum1@'s data then @enum2@'s data\n   to an 'Iter'.\n-}" Nothing),DP (2,1)),((AnnComment DComment (DP (2,1),DP (438,3)) "{- $Tutorial\n\n #tutorial#\n\nThe iterIO library performs IO by hooking up sources of data, called\n/enumerators/, to data sinks, called /iteratees/, in a manner\nreminiscent of Unix command pipelines.  Compared to lazy IO, the\nenumerator/iteratee paradigm provides better error handing,\nreferential transparency (which should, after all, be one of the big\nadvantages of Haskell), and equally convenient composition of protocol\nlayers and parsers without worrying about IO chunk boundaries.\n\nEnumerators, implemented by the type 'Onum' (short for\n/outer enumerator/, for reasons that will become clear below), are so\ncalled because they enumerate all data elements (e.g., bytes or\npackets) in some source such as a file or socket.  Hence, an\nenumerator should be viewed as a /source/ outputting chunks of data\nwhose type is a @'Monoid'@.  (Actually, the input type must be of\nclass 'ChunkData', which is a @'Monoid'@ that additionally has a\nmethod @'null'@ to test whether a piece of data is equal to\n'mempty'.)\n\nIteratees, implemented by the type 'Iter', should be viewed as /sinks/\nconsuming data.  When executing IO, the library /iterates/ over all\ndata elements output by the source, using an iteratee to produce a\nresult.  The source may output data in chunks whose boundaries do not\ncoincide with logical message units; iteratees handle this\ntransparently, simplifying programming.\n\nHere is a simple example:\n\n@\n    -- Return the first line of a file\n    headFile :: FilePath -> IO String\n    headFile path = 'enumFile' path '|$' 'lineI'\n@\n\n'enumFile' enumerates the contents of a file.  'lineI' returns a line\nof input (discarding the newline).  '|$' is the /pipe apply/ operator\nthat applies an 'Onum' to an 'Iter', returning the result of the\n'Iter'--in this case the first line of the file named @path@.\n\nAn `Iter`'s main purpose may not be to produce a result.  Some 'Iter's\nare primarily useful for their side effects.  For example, 'stdoutI'\nwrites data to standard output; 'handleI' similarly writes output to\nan arbitrary file handle.  Thus, the following function copies the\ncontents of a file to standard output:\n\n@\n    -- Copy file to standard output\n    catFile :: FilePath -> IO ()\n    catFile path = 'enumFile'' path '|$' 'stdoutI'\n@\n\n'enumFile'' is like 'enumFile' above, but type restricted to data in\nthe lazy @'ByteString'@ format, which is more efficient than plain\n'String's.  ('enumFile' supports multiple types, but in this example\nthere is not enough information for Haskell to choose one of them, so\nwe must use 'enumFile'' or use @::@ to specify a type explicitly.)\nOnce again, '|$' is used to execute the IO actions, but, this time,\nthe return value is just @()@; the interesting action lies in the side\neffects of writing data to standard output while iterating over the\ninput with 'stdoutI'.\n\nThe real power of the iteratee abstraction lies in the fact that\n'Iter's are monadic computations.  One 'Iter' may invoke another to\nmake use of the first one's results.  Here is an example of a function\nthat returns the first two lines of a file:\n\n@\n    -- | Return first two lines of file\n    head2File :: FilePath -> IO (String, String)\n    head2File path = 'enumFile' path '|$' lines2I\n@\n\n@\n    -- | Iter that returns next two lines as a pair\n    lines2I :: (Monad m) => 'Iter' String m (String, String)\n    lines2I = do\n      line1 <- 'lineI'\n      line2 <- 'lineI'\n      return (line1, line2)\n@\n\nThis example illustrates several points.  First, consider the type of\nthe @lines2I@ function:  @'Iter' String m (String, String)@.  The\n'Iter' type constructor takes three type arguments.  The first,\n'String' in this case, specifies the type of input expected by the\niteratee.  The last type, @(String, String)@ in this case, specifies\nthe result type of the iteratee.  Finally, the middle type, @m@, is a\nmonad, because @'Iter' t@ (for a given input type @t@) is a monad\ntransformer (i.e., it is an instance of the 'MonadTrans' class).  In\nthis case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,\nbecause @head2File@ is returning a result in the @IO@ monad.  However,\n@lines2I@ would work equally well with any other monad.\n\nNext, notice the functioning of @'Iter' String m@ as a monad.  The\ntype of 'lineI' in the above example is @'Iter' String m String@.  The\n@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to\nbind the results to @line1@ and @line2@.  The monadic bind operator\nhides the details of IO chunk boundaries.  If, for instance, 'lineI'\nneeds more input because a newline character has not yet been read,\n'lineI' returns to the containing enumerator asking for more data.  If\nthe first 'lineI' receives more than a line of input, it simply passes\nthe residual input to the next invocation of 'lineI'.  Both of these\nactions are hidden by the syntax, making most code much easier to read\nand write.\n\nThat explains the iteratee type 'Iter'.  The enumerator type, 'Onum',\nhas the same three type arguments.  Thus, the type of 'enumFile', as\ninstantiated in the above examples, is @'enumFile' :: 'Onum' String IO\na@.  Most 'Onum' types are polymorphic in the last argument, so as to\nbe able to return whatever type the 'Iter' is returning.  (In fact,\n'enumFile' is polymorphic in the first two arguments, too, so as to\nwork with multiple @String@-like types and any monad in the\n@'MonadIO'@ class.)\n\nHere is an example of an 'Iter' with side effects:\n\n@\n    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()\n    liftIOexampleI = do\n      line <- 'lineI'\n      'liftIO' $ putStrLn $ \\\"First line is: \\\" ++ line\n      next <- 'takeI' 40\n      'liftIO' $ putStrLn $ \\\"And the next 40 bytes are: \\\" ++ next\n@\n\nUnlike @lines2I@, @liftIOexampleI@ does not return any interesting\nresult, but it uses the @'liftIO'@ monad transformer method to output\nthe first line of the file, followed by the next 40 bytes.  The\n'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the\nrequested number of characters or bytes, unless an EOF (end-of-file)\nis encountered.\n\nOf course, the real power of command pipelines is that you can hook\nmultiple commands together.  For instance, say you want to know how\nmany words in the system dictionary files contain a double k and start\nwith a lower-case letter.  You could run a command like this:\n\n>    cat /usr/share/dict/words /usr/share/dict/extra.words \\\n>        | grep kk | grep '^[a-z]' | wc -l\n\nLet's see how to do something equivalent with iteratees, starting with\nthe @wc -l@ command, which counts lines.  Here is an equivalent iteratee:\n\n@\n    lineCountI :: (Monad m) => 'Iter' String m Int\n    lineCountI = count 0\n        where count n = do\n                line <- 'safeLineI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nThe 'safeLineI' function is like 'lineI', but returns a @'Maybe'\n'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF\ncondition.  ('lineI' throws an exception on EOF.)\n\nWhat about the @grep@ command?  @grep@ sits in the middle of a\npipeline, so it acts both as a data sink and as a data source.\nThis is why we call such a pipeline stage an\n/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@\nequivalent, since multiple pipeline stages are going to be considering\nthe file one line at a time, let's first build an 'Inum' to separate\ninput into lines:\n\n@\n    import Data.ByteString as S\n    import Data.ByteString.Char8 as S8\n@\n\n@\n    -- | Break input into lines of type S.ByteString, as this type\n    -- works most conveniently with regular expressions.  (Otherwise,\n    -- we would prefer lazy ByteStrings.)\n    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a\n    inumToLines = 'mkInum' $ do\n                    line <- 'lineI'\n                    return [line]\n@\n\n'Inum' takes four type arguments, compared to only three for 'Onum'.\nThat's because an 'Inum' is acting as both an iteratee and an\nenumerator; it needn't be processing the same type of data in both\nroles.  In the above example, when acting as an iteratee,\n@inumToLines@ consumes data of type @S.ByteString@ (the first type\nargument), accepting one long stream of unstructured bytes.  However,\nas an enumerator, @inumToLines@ produces output of type\n@[S.ByteString]@ (the second type argument), a /list/ of strings, one\nper line of the file.  In general the type @'Inum' tIn tOut m a@ is an\niteratee-enumerator taking input type @tIn@, producing output type\n@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m\na@.\n\nIn fact, an 'Onum' is just a special kind of 'Inum' with the void\ninput type @()@.  The type @'Onum' t m a@ is just a synonym for\n@'Inum' () t m a@.  Most operations on 'Inum's can be used with\n'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not\ntrue, however.  For example, the '|$' operator requires an 'Onum', as\nit wouldn't know what data to feed to an arbitrary 'Inum'.  (If you\nneed it, however, there is a function @run@, hidden by this module but\nexported by \"Data.IterIO.Iter\", that executes an iteratee computation\nof arbitrary input type by feeding EOF as input.)\n\nIteratee-enumerators are generally constructed using either 'mkInum'\nor `mkInumM`, and by convention most 'Inum's have names starting\n\\\"@inum@...\\\", except that 'Onum' names start \\\"@enum@...\\\".  'mkInum'\ntakes an argument of type @'Iter' tIn m tOut@ that consumes input of\ntype @tIn@ to produce output of type @tOut@.  (For @inumToLines@,\n@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine\nfor simple stateless translation functions, but sometimes one would\nlike to keep state and use more complex logic in an 'Inum'.  For that,\nthe 'mkInumM' function creates an 'Inum' out of a computation in a\ndedicated 'InumM' monad.  See the \"Data.IterIO.Inum\" documentation for\nmore information on 'mkInumM'.  In @inumToLines@, we do not need to\nkeep state.  We are happy just to let 'lineI' throw an exception on\nEOF, which `mkInum` will catch and handle gracefully.\n\nThrowing an EOF exception--either implicitly by executing another\n'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to\nexit an 'Inum' created by 'mkInum'.  The other way is to return empty\ninput.\n\nWe similarly define an 'Inum' to filter out lines not matching a\nregular expression (using the \"Text.Regex.Posix.ByteString\" library),\nand a simple 'Inum' to count list elements (since @lineCountI ::\n'Iter' String m Int@ has input data type @String@, while after\n@inumToLines@ we need an 'Iter' with input data type\n@[S.ByteString]@).\n\n@\n    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a\n    inumGrep re = `mkInum` $ do\n      line <- 'headI'\n      if line =~ packedRe then return [line] else return []\n        where\n          packedRe = S8.pack re\n@\n\n@\n    lengthI :: (Monad m) => 'Iter' [t] m Int\n    lengthI = count 0\n        where count n = do\n                line <- 'safeHeadI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nNow we are almost ready to assemble all the pieces.  But recall that\nthe '|$' operator applies one 'Onum' to one 'Iter', yet now we have\ntwo 'Onum's (because we want to look through two files), and three\n'Inum's that we want to compose into a pipeline.  The library\nsupports two types of composition for pipeline stages:\n/concatenation/ and /fusing/.\n\nTwo 'Inum's (or 'Onum's) of the same type can be /concatenated/ with\nthe 'cat' function, producing a new data source that enumerates all of\nthe data in the first 'Inum' followed by all of the data in the\nsecond.\n\nThere are two /fusing/ operators.  The left-associative '|.' operator\nfuses two 'Inum's, provided the output type of the first is the input\ntype of the second.  (Mnemonic: it produces a pipeline stage that is\nopen on the right hand side, as it still needs to be applied to an\niteratee with '|$'.)  The right-associative '.|' operator fuses an\n'Inum' to an 'Iter', producing a new 'Iter'.\n\nThe fusing operators bind more tightly than the infix concatenation\nfunctions, which in turn bind more tightly than '|$'.  (Concatenation\noperators can also be used through prefix function application, which\nbinds most tightly.)  Hence, putting it all together, we produce the\nfollowing Haskell equivalent to the above Unix pipeline:\n\n@\n    grepCount :: IO Int\n    grepCount = 'enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines\n                    ``cat`` 'enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines\n                '|$' inumGrep \\\"kk\\\"\n                        '.|' inumGrep \\\"^[a-z]\\\"\n                        '.|' lengthI\n@\n\nOne often has a choice as to whether to fuse an 'Inum' to the\n'Onum', or to the 'Iter'.  For example, @grepCount@ could\nalternatively have been implemented as:\n\n@\n    grepCount' :: IO Int\n    grepCount' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines)\n                         ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines)\n                    '|.' inumGrep \\\"kk\\\"\n                    '|.' inumGrep \\\"^[a-z]\\\"\n                 '|$' lengthI\n@\n\nIn this case, the two are essentially equivalent.  However, for error\nhandling purposes, one should fuse together pipeline stages in which\nerrors have similar consequences.  Often an 'Inum' or 'Onum' failure\nis less serious than an 'Iter' failure.  For example, in the above\nexample, if 'enumFile' fails because one of the files does not exist,\nwe might want to continue processing lines from the next file.\nConversely, if @lengthI@ fails or one of the @inumGrep@ stages fails\n(most likely because the regular expression is illegal), there is not\nmuch point in continuing the program.  This is why the first example\nfused @inumGrep@ to @lengthI@, though this won't matter until we\nactually handle errors (see below).\n\nAnother alternative would have been to swap the order of concatenation\nand fusing:\n\n@\n    grepCount'' :: IO Int\n    grepCount'' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\")\n                           ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\")\n                      '|.' inumToLines\n                  '|$' inumGrep \\\"kk\\\"\n                      '.|' inumGrep \\\"^[a-z]\\\"\n                      '.|' lengthI\n@\n\nThis last version changes the semantics of the counting slightly.\nWith @grepCount''@, if the first file has an incomplete last line,\nthis line will be merged with the first line of the second file, which\nis probably not what you want.  (For instance, if the incomplete last\nline of the first file starts with a capital letter, then the first\nline of the second file will not be counted even if it starts with a\nlower-case letter and contains two \\\"k\\\"s.)\n\nOne limitation of all the @grepCount@ variants shown so far is that if\nthe first file does not exist, the whole operation aborts.  This\nmight or might not be reasonable when counting lines, but in other\ncontexts we may want to resume after failure.  Suppose we want to\nimplement a function like the Unix @grep@ command that searches for a\nstring in a bunch of files and prints all matching lines.  If opening\nor reading a file produces an error, the function should print the\nerror message and continue on with the next file.\n\nError handling is provided by the 'catchI' and 'inumCatch' functions,\nwhich are roughly equivalent to the standard library @'catch'@\nfunction.  There is also a 'throwI' function analogous to @'throwIO'@\nin the standard library.  Because @'catch'@ only works in the IO\nmonad, 'catchI' and 'inumCatch' work by propagating synchronous\nexceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors\ninto such synchronous exceptions.  Unfortunately, there is no way to\nhandle asynchronous exceptions such as those that arise in lazily\nevaluated pure code (e.g., divide by zero) or those thrown by another\nthread using @'throwTo'@.  Fortunately, for our @grep@ example, we\nonly need to catch IO errors.\n\nHere is the @grep@ code.  We will analyze it below.\n\n@\n    grep :: String -> [FilePath] -> IO ()\n    grep re files\n        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI\n        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI\n        where\n          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler\n          handler :: 'IOError'\n                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)\n                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)\n          handler e result = do\n            liftIO (hPutStrLn stderr $ show e)\n            'resumeI' result\n          linesOutI = do\n            mline <- 'safeHeadI'\n            case mline of\n              Just line -> do liftIO $ S.putStrLn line\n                              linesOutI\n              Nothing -> return ()\n@\n\nThere are two cases.  If the list of files to search is null, @grep@\nsimply reads from standard input, in which case there is only one\ninput stream and we do not care about resuming.  In the second case,\nwe use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'\nis generated by the function @enumLines@, which fuses 'enumFile' to\nour previously defined @inumToLines@, but also wraps the exception\nhandler function @handler@ around the enumerator using 'inumCatch'.\n\nNote that unlike @catch@, 'inumCatch' expects an exception handler to\nhave /two/ arguments.  The first argument, @e@ in this example, is the\nexception itself.  As with @catch@, the type of @e@ determines which\nexceptions are caught, which is why we must either specify an explicit\ntype signature for @handler@ or somewhere specify @e@'s type\nexplicitly, for instance with:\n\n>          ...\n>            liftIO (hPutStrLn stderr $ show (e :: IOError))\n>          ...\n\nNote that 'IOError' doesn't expose a type constructor, but for\nexception types that do, it often suffices to define the function with\nthe exception constructor, as:\n\n>          handler e@(SomeException _) result = do ...\n\nThe second argument to @handler@, @result@, is the failed state of the\niteratee, which contains more information than just the exception.  In\nthe case of an 'Inum' failure, it contains the state of the 'Iter'\nthat the 'Inum' was feeding when it failed.  The type of 'result' is\n'IterR'--which is the type returned by 'Iter's when they are fed\nchunks of data.  'IterR' takes the same three type arguments as\n'Iter'.  The function 'resumeI' extracts and returns an @'Iter'\n[S.ByteString] IO a@ from this failed result.  Thus, the next\nenumerator in a concatenated series can continue feeding it input.\nIf, instead of resuming, you want to re-throw the error, it suffices\nto re-execute the failed result with @'reRunIter'@.  For instance,\nsuppose we want to continue executing @grep@ when a named file does\nnot exist, but if some other error happens, we want to re-throw the\nexception to abort the whole program.  This could be achieved as\nfollows:\n\n>          handler e result = do\n>            if isDoesNotExistError e\n>              then do liftIO (hPutStrLn stderr $ show e)\n>                      resumeI result\n>              else reRunIter result\n\nBecause printing an exception is so common, there is a function\n'verboseResumeI' that prints exceptions before resuming (also\nprefixing the program name).  Thus, we can simplify the above function\nto:\n\n>          handler e result = if isDoesNotExistError e\n>                               then verboseResumeI result\n>                               else reRunIter result\n\nThese last two @handler@ functions also do away with the need for an\nexplicit type signature, because the function @'isDoesNotExistError'@\nhas argument type 'IOError', constraining the type of @e@ to the type\nof exceptions we want to catch.\n\n-}" Nothing),DP (2,1)),((AnnComment DComment (DP (-436,1),DP (1,3)) "{- $Tutorial\n\n #tutorial#\n\n\nThe iterIO library performs IO by hooking up sources of data, called\n/enumerators/, to data sinks, called /iteratees/, in a manner\nreminiscent of Unix command pipelines.  Compared to lazy IO, the\nenumerator/iteratee paradigm provides better error handing,\nreferential transparency (which should, after all, be one of the big\nadvantages of Haskell), and equally convenient composition of protocol\nlayers and parsers without worrying about IO chunk boundaries.\n\nEnumerators, implemented by the type 'Onum' (short for\n/outer enumerator/, for reasons that will become clear below), are so\ncalled because they enumerate all data elements (e.g., bytes or\npackets) in some source such as a file or socket.  Hence, an\nenumerator should be viewed as a /source/ outputting chunks of data\nwhose type is a @'Monoid'@.  (Actually, the input type must be of\nclass 'ChunkData', which is a @'Monoid'@ that additionally has a\nmethod @'null'@ to test whether a piece of data is equal to\n'mempty'.)\n\nIteratees, implemented by the type 'Iter', should be viewed as /sinks/\nconsuming data.  When executing IO, the library /iterates/ over all\ndata elements output by the source, using an iteratee to produce a\nresult.  The source may output data in chunks whose boundaries do not\ncoincide with logical message units; iteratees handle this\ntransparently, simplifying programming.\n\nHere is a simple example:\n\n@\n    -- Return the first line of a file\n    headFile :: FilePath -> IO String\n    headFile path = 'enumFile' path '|$' 'lineI'\n@\n\n'enumFile' enumerates the contents of a file.  'lineI' returns a line\nof input (discarding the newline).  '|$' is the /pipe apply/ operator\nthat applies an 'Onum' to an 'Iter', returning the result of the\n'Iter'--in this case the first line of the file named @path@.\n\nAn `Iter`'s main purpose may not be to produce a result.  Some 'Iter's\nare primarily useful for their side effects.  For example, 'stdoutI'\nwrites data to standard output; 'handleI' similarly writes output to\nan arbitrary file handle.  Thus, the following function copies the\ncontents of a file to standard output:\n\n@\n    -- Copy file to standard output\n    catFile :: FilePath -> IO ()\n    catFile path = 'enumFile'' path '|$' 'stdoutI'\n@\n\n'enumFile'' is like 'enumFile' above, but type restricted to data in\nthe lazy @'ByteString'@ format, which is more efficient than plain\n'String's.  ('enumFile' supports multiple types, but in this example\nthere is not enough information for Haskell to choose one of them, so\nwe must use 'enumFile'' or use @::@ to specify a type explicitly.)\nOnce again, '|$' is used to execute the IO actions, but, this time,\nthe return value is just @()@; the interesting action lies in the side\neffects of writing data to standard output while iterating over the\ninput with 'stdoutI'.\n\nThe real power of the iteratee abstraction lies in the fact that\n'Iter's are monadic computations.  One 'Iter' may invoke another to\nmake use of the first one's results.  Here is an example of a function\nthat returns the first two lines of a file:\n\n@\n    -- | Return first two lines of file\n    head2File :: FilePath -> IO (String, String)\n    head2File path = 'enumFile' path '|$' lines2I\n@\n\n@\n    -- | Iter that returns next two lines as a pair\n    lines2I :: (Monad m) => 'Iter' String m (String, String)\n    lines2I = do\n      line1 <- 'lineI'\n      line2 <- 'lineI'\n      return (line1, line2)\n@\n\nThis example illustrates several points.  First, consider the type of\nthe @lines2I@ function:  @'Iter' String m (String, String)@.  The\n'Iter' type constructor takes three type arguments.  The first,\n'String' in this case, specifies the type of input expected by the\niteratee.  The last type, @(String, String)@ in this case, specifies\nthe result type of the iteratee.  Finally, the middle type, @m@, is a\nmonad, because @'Iter' t@ (for a given input type @t@) is a monad\ntransformer (i.e., it is an instance of the 'MonadTrans' class).  In\nthis case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,\nbecause @head2File@ is returning a result in the @IO@ monad.  However,\n@lines2I@ would work equally well with any other monad.\n\nNext, notice the functioning of @'Iter' String m@ as a monad.  The\ntype of 'lineI' in the above example is @'Iter' String m String@.  The\n@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to\nbind the results to @line1@ and @line2@.  The monadic bind operator\nhides the details of IO chunk boundaries.  If, for instance, 'lineI'\nneeds more input because a newline character has not yet been read,\n'lineI' returns to the containing enumerator asking for more data.  If\nthe first 'lineI' receives more than a line of input, it simply passes\nthe residual input to the next invocation of 'lineI'.  Both of these\nactions are hidden by the syntax, making most code much easier to read\nand write.\n\nThat explains the iteratee type 'Iter'.  The enumerator type, 'Onum',\nhas the same three type arguments.  Thus, the type of 'enumFile', as\ninstantiated in the above examples, is @'enumFile' :: 'Onum' String IO\na@.  Most 'Onum' types are polymorphic in the last argument, so as to\nbe able to return whatever type the 'Iter' is returning.  (In fact,\n'enumFile' is polymorphic in the first two arguments, too, so as to\nwork with multiple @String@-like types and any monad in the\n@'MonadIO'@ class.)\n\nHere is an example of an 'Iter' with side effects:\n\n@\n    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()\n    liftIOexampleI = do\n      line <- 'lineI'\n      'liftIO' $ putStrLn $ \\\"First line is: \\\" ++ line\n      next <- 'takeI' 40\n      'liftIO' $ putStrLn $ \\\"And the next 40 bytes are: \\\" ++ next\n@\n\nUnlike @lines2I@, @liftIOexampleI@ does not return any interesting\nresult, but it uses the @'liftIO'@ monad transformer method to output\nthe first line of the file, followed by the next 40 bytes.  The\n'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the\nrequested number of characters or bytes, unless an EOF (end-of-file)\nis encountered.\n\nOf course, the real power of command pipelines is that you can hook\nmultiple commands together.  For instance, say you want to know how\nmany words in the system dictionary files contain a double k and start\nwith a lower-case letter.  You could run a command like this:\n\n>    cat /usr/share/dict/words /usr/share/dict/extra.words >        | grep kk | grep '^[a-z]' | wc -l\n\n\nLet's see how to do something equivalent with iteratees, starting with\nthe @wc -l@ command, which counts lines.  Here is an equivalent iteratee:\n\n@\n    lineCountI :: (Monad m) => 'Iter' String m Int\n    lineCountI = count 0\n        where count n = do\n                line <- 'safeLineI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nThe 'safeLineI' function is like 'lineI', but returns a @'Maybe'\n'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF\ncondition.  ('lineI' throws an exception on EOF.)\n\nWhat about the @grep@ command?  @grep@ sits in the middle of a\npipeline, so it acts both as a data sink and as a data source.\nThis is why we call such a pipeline stage an\n/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@\nequivalent, since multiple pipeline stages are going to be considering\nthe file one line at a time, let's first build an 'Inum' to separate\ninput into lines:\n\n@\n    import Data.ByteString as S\n    import Data.ByteString.Char8 as S8\n@\n\n@\n    -- | Break input into lines of type S.ByteString, as this type\n    -- works most conveniently with regular expressions.  (Otherwise,\n    -- we would prefer lazy ByteStrings.)\n    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a\n    inumToLines = 'mkInum' $ do\n                    line <- 'lineI'\n                    return [line]\n@\n\n'Inum' takes four type arguments, compared to only three for 'Onum'.\nThat's because an 'Inum' is acting as both an iteratee and an\nenumerator; it needn't be processing the same type of data in both\nroles.  In the above example, when acting as an iteratee,\n@inumToLines@ consumes data of type @S.ByteString@ (the first type\nargument), accepting one long stream of unstructured bytes.  However,\nas an enumerator, @inumToLines@ produces output of type\n@[S.ByteString]@ (the second type argument), a /list/ of strings, one\nper line of the file.  In general the type @'Inum' tIn tOut m a@ is an\niteratee-enumerator taking input type @tIn@, producing output type\n@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m\na@.\n\nIn fact, an 'Onum' is just a special kind of 'Inum' with the void\ninput type @()@.  The type @'Onum' t m a@ is just a synonym for\n@'Inum' () t m a@.  Most operations on 'Inum's can be used with\n'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not\ntrue, however.  For example, the '|$' operator requires an 'Onum', as\nit wouldn't know what data to feed to an arbitrary 'Inum'.  (If you\nneed it, however, there is a function @run@, hidden by this module but\nexported by \"Data.IterIO.Iter\", that executes an iteratee computation\nof arbitrary input type by feeding EOF as input.)\n\nIteratee-enumerators are generally constructed using either 'mkInum'\nor `mkInumM`, and by convention most 'Inum's have names starting\n\\\"@inum@...\\\", except that 'Onum' names start \\\"@enum@...\\\".  'mkInum'\ntakes an argument of type @'Iter' tIn m tOut@ that consumes input of\ntype @tIn@ to produce output of type @tOut@.  (For @inumToLines@,\n@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine\nfor simple stateless translation functions, but sometimes one would\nlike to keep state and use more complex logic in an 'Inum'.  For that,\nthe 'mkInumM' function creates an 'Inum' out of a computation in a\ndedicated 'InumM' monad.  See the \"Data.IterIO.Inum\" documentation for\nmore information on 'mkInumM'.  In @inumToLines@, we do not need to\nkeep state.  We are happy just to let 'lineI' throw an exception on\nEOF, which `mkInum` will catch and handle gracefully.\n\nThrowing an EOF exception--either implicitly by executing another\n'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to\nexit an 'Inum' created by 'mkInum'.  The other way is to return empty\ninput.\n\nWe similarly define an 'Inum' to filter out lines not matching a\nregular expression (using the \"Text.Regex.Posix.ByteString\" library),\nand a simple 'Inum' to count list elements (since @lineCountI ::\n'Iter' String m Int@ has input data type @String@, while after\n@inumToLines@ we need an 'Iter' with input data type\n@[S.ByteString]@).\n\n@\n    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a\n    inumGrep re = `mkInum` $ do\n      line <- 'headI'\n      if line =~ packedRe then return [line] else return []\n        where\n          packedRe = S8.pack re\n@\n\n@\n    lengthI :: (Monad m) => 'Iter' [t] m Int\n    lengthI = count 0\n        where count n = do\n                line <- 'safeHeadI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nNow we are almost ready to assemble all the pieces.  But recall that\nthe '|$' operator applies one 'Onum' to one 'Iter', yet now we have\ntwo 'Onum's (because we want to look through two files), and three\n'Inum's that we want to compose into a pipeline.  The library\nsupports two types of composition for pipeline stages:\n/concatenation/ and /fusing/.\n\nTwo 'Inum's (or 'Onum's) of the same type can be /concatenated/ with\nthe 'cat' function, producing a new data source that enumerates all of\nthe data in the first 'Inum' followed by all of the data in the\nsecond.\n\nThere are two /fusing/ operators.  The left-associative '|.' operator\nfuses two 'Inum's, provided the output type of the first is the input\ntype of the second.  (Mnemonic: it produces a pipeline stage that is\nopen on the right hand side, as it still needs to be applied to an\niteratee with '|$'.)  The right-associative '.|' operator fuses an\n'Inum' to an 'Iter', producing a new 'Iter'.\n\nThe fusing operators bind more tightly than the infix concatenation\nfunctions, which in turn bind more tightly than '|$'.  (Concatenation\noperators can also be used through prefix function application, which\nbinds most tightly.)  Hence, putting it all together, we produce the\nfollowing Haskell equivalent to the above Unix pipeline:\n\n@\n    grepCount :: IO Int\n    grepCount = 'enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines\n                    ``cat`` 'enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines\n                '|$' inumGrep \\\"kk\\\"\n                        '.|' inumGrep \\\"^[a-z]\\\"\n                        '.|' lengthI\n@\n\nOne often has a choice as to whether to fuse an 'Inum' to the\n'Onum', or to the 'Iter'.  For example, @grepCount@ could\nalternatively have been implemented as:\n\n@\n    grepCount' :: IO Int\n    grepCount' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines)\n                         ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines)\n                    '|.' inumGrep \\\"kk\\\"\n                    '|.' inumGrep \\\"^[a-z]\\\"\n                 '|$' lengthI\n@\n\nIn this case, the two are essentially equivalent.  However, for error\nhandling purposes, one should fuse together pipeline stages in which\nerrors have similar consequences.  Often an 'Inum' or 'Onum' failure\nis less serious than an 'Iter' failure.  For example, in the above\nexample, if 'enumFile' fails because one of the files does not exist,\nwe might want to continue processing lines from the next file.\nConversely, if @lengthI@ fails or one of the @inumGrep@ stages fails\n(most likely because the regular expression is illegal), there is not\nmuch point in continuing the program.  This is why the first example\nfused @inumGrep@ to @lengthI@, though this won't matter until we\nactually handle errors (see below).\n\nAnother alternative would have been to swap the order of concatenation\nand fusing:\n\n@\n    grepCount'' :: IO Int\n    grepCount'' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\")\n                           ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\")\n                      '|.' inumToLines\n                  '|$' inumGrep \\\"kk\\\"\n                      '.|' inumGrep \\\"^[a-z]\\\"\n                      '.|' lengthI\n@\n\nThis last version changes the semantics of the counting slightly.\nWith @grepCount''@, if the first file has an incomplete last line,\nthis line will be merged with the first line of the second file, which\nis probably not what you want.  (For instance, if the incomplete last\nline of the first file starts with a capital letter, then the first\nline of the second file will not be counted even if it starts with a\nlower-case letter and contains two \\\"k\\\"s.)\n\nOne limitation of all the @grepCount@ variants shown so far is that if\nthe first file does not exist, the whole operation aborts.  This\nmight or might not be reasonable when counting lines, but in other\ncontexts we may want to resume after failure.  Suppose we want to\nimplement a function like the Unix @grep@ command that searches for a\nstring in a bunch of files and prints all matching lines.  If opening\nor reading a file produces an error, the function should print the\nerror message and continue on with the next file.\n\nError handling is provided by the 'catchI' and 'inumCatch' functions,\nwhich are roughly equivalent to the standard library @'catch'@\nfunction.  There is also a 'throwI' function analogous to @'throwIO'@\nin the standard library.  Because @'catch'@ only works in the IO\nmonad, 'catchI' and 'inumCatch' work by propagating synchronous\nexceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors\ninto such synchronous exceptions.  Unfortunately, there is no way to\nhandle asynchronous exceptions such as those that arise in lazily\nevaluated pure code (e.g., divide by zero) or those thrown by another\nthread using @'throwTo'@.  Fortunately, for our @grep@ example, we\nonly need to catch IO errors.\n\nHere is the @grep@ code.  We will analyze it below.\n\n@\n    grep :: String -> [FilePath] -> IO ()\n    grep re files\n        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI\n        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI\n        where\n          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler\n          handler :: 'IOError'\n                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)\n                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)\n          handler e result = do\n            liftIO (hPutStrLn stderr $ show e)\n            'resumeI' result\n          linesOutI = do\n            mline <- 'safeHeadI'\n            case mline of\n              Just line -> do liftIO $ S.putStrLn line\n                              linesOutI\n              Nothing -> return ()\n@\n\nThere are two cases.  If the list of files to search is null, @grep@\nsimply reads from standard input, in which case there is only one\ninput stream and we do not care about resuming.  In the second case,\nwe use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'\nis generated by the function @enumLines@, which fuses 'enumFile' to\nour previously defined @inumToLines@, but also wraps the exception\nhandler function @handler@ around the enumerator using 'inumCatch'.\n\nNote that unlike @catch@, 'inumCatch' expects an exception handler to\nhave /two/ arguments.  The first argument, @e@ in this example, is the\nexception itself.  As with @catch@, the type of @e@ determines which\nexceptions are caught, which is why we must either specify an explicit\ntype signature for @handler@ or somewhere specify @e@'s type\nexplicitly, for instance with:\n\n>          ...\n>            liftIO (hPutStrLn stderr $ show (e :: IOError))\n>          ...\n\nNote that 'IOError' doesn't expose a type constructor, but for\nexception types that do, it often suffices to define the function with\nthe exception constructor, as:\n\n>          handler e@(SomeException _) result = do ...\n\nThe second argument to @handler@, @result@, is the failed state of the\niteratee, which contains more information than just the exception.  In\nthe case of an 'Inum' failure, it contains the state of the 'Iter'\nthat the 'Inum' was feeding when it failed.  The type of 'result' is\n'IterR'--which is the type returned by 'Iter's when they are fed\nchunks of data.  'IterR' takes the same three type arguments as\n'Iter'.  The function 'resumeI' extracts and returns an @'Iter'\n[S.ByteString] IO a@ from this failed result.  Thus, the next\nenumerator in a concatenated series can continue feeding it input.\nIf, instead of resuming, you want to re-throw the error, it suffices\nto re-execute the failed result with @'reRunIter'@.  For instance,\nsuppose we want to continue executing @grep@ when a named file does\nnot exist, but if some other error happens, we want to re-throw the\nexception to abort the whole program.  This could be achieved as\nfollows:\n\n>          handler e result = do\n>            if isDoesNotExistError e\n>              then do liftIO (hPutStrLn stderr $ show e)\n>                      resumeI result\n>              else reRunIter result\n\nBecause printing an exception is so common, there is a function\n'verboseResumeI' that prints exceptions before resuming (also\nprefixing the program name).  Thus, we can simplify the above function\nto:\n\n>          handler e result = if isDoesNotExistError e\n>                               then verboseResumeI result\n>                               else reRunIter result\n\nThese last two @handler@ functions also do away with the need for an\nexplicit type signature, because the function @'isDoesNotExistError'@\nhas argument type 'IOError', constraining the type of @e@ to the type\nof exceptions we want to catch.\n\n-}" Nothing),DP (-436,1)),((AnnComment DComment (DP (1,1),DP (326,3)) "{- $Differences\n\nThe Iteratee approach was originally advocated by Oleg Kiselyov (see\ntalk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The\nmain implementation by Kiselyov and John Lato is simply called\n/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another\nrealization of the iteratee concepts is the /enumerator/ package\n(<http://hackage.haskell.org/package/enumerator>).  IterIO is a\nre-implementation of these concepts from scratch.  This section\ndiscusses the differences between previous packages and iterIO, both\nas a means for motivating iterIO's design and as a set of suggestions\nfor improving other iteratee implementations.\n\n* /Base abstraction/\n\nThe iterIO package represents an iteratee as a pure function from a\nchunk of pending input data to an iteratee result of type 'IterR':\n\n@\n  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }\n@\n\nAn 'IterR' can yield a result and residual input, or it can ask for\nmore input, or it can request to have an action executed in the\nunderlying monad, or it can signal failure.  The fact that all\niteratees are functions of input ensures that iteratees generally see\n/all/ pending input.  Thus, iteratees can do things like measure the\nlength of buffered input to subtract it from the current file offset\nand determine the effective position in a file.\n\n`IterR`'s division of iteratee results into different outcomes such as\nneeding input or needing monadic actions allows the library to\ndistinguish between pure iteratees and those with potential side\neffects.  The ability to know that a specific iteratee is a pure\nfunction in many cases allows one to parse LL(*) grammars without\nlarge amounts of input buffering for backtracking (see below).\n\nIn contrast, the iteratee package uses continuation passing style\n(CPS), in which an iteratee is a function taking two continuation\nfunctions--one to call when done, and a second to call when either\nrequesting more input or failing:\n\n> -- From the iteratee package:\n> newtype Iteratee s m a = Iteratee{ runIter :: forall r.\n>        -- First the \"onDone\" function:\n>           (a -> Stream s -> m r) ->\n>        -- Next the \"onCont\" function:\n>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->\n>           m r}\n\nCPS has the advantage of exposing the bind operator of the underlying\nmonad, making 'lift' cheap and simple.  Moreover, splitting into two\ncontinuations saves the first and most common one (i.e., \\\"onDone\\\")\nfrom the overhead of checking whether an error condition or request\nfor more input has occurred.  See\n<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>\nfor a good discussion of the advantages of CPS.\n\nBecause of CPS, iteratee should be capable of delivering the best\nperformance of the three iteratee packages.  A disadvantage of\niterIO's approach is that every invocation of 'lift' must be\npropagated all the way up the call chain, where a small amount of\noverhead is added for each enclosing 'catchI' or similar call.  While\niterIO can handle most successful 'IterR' outcomes and caught\nexceptions locally without popping back up the call stack, there is\nalso potentially overhead from actually checking that the outcome was\nsuccessful at each bind site.  (GHC's inliner may be able to avoid the\ncheck in some cases.)\n\nHowever, iteratee lacks several features of iterIO; offering these\nfeatures would likely reduce the benefits of CPS and complicate code.\nFor instance, there is no way to execute a pure iteratee without\nmonadic actions (the benefit touted above and described below for\nLL(*) parsing).  Moreover, iteratee's exception mechanism discards the\ncurrent location in the input stream, making it unsuitable for failed\nparse alternatives.  IterIO provides a general control mechanism to\nmake arbitrary requests from enumerators (such as seek, tell,\ngetpeername, get SSL information, etc.); iteratee instead overloads\nthe exception mechanism for control purposes, which prevents control\noperations from returning values.  Thus, while iteratee can implement\nseek, it cannot, for instance, implement tell.\n\nThe enumerator package's approach is closer to iterIO's, but makes\nevery iteratee into a monadic action in the underlying monad @m@:\n\n> -- From the enumerator package:\n> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }\n\nHere @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper\ndisallows iterIO's LL(*) parsing tricks.  It also causes gratuitous\ninvocation of @m@'s bind function, which can be expensive when using\nstacks of monad transformers.  Furthermore, enumerator discards the\ninput state on all errors, making it impossible to resume from\nfailures that leave the input in a known state (such as a parsing\nlookahead failure).\n\n* /Uniformity of abstraction/\n\nIterIO's abstractions were refined over many iterations to become\nminimal yet highly expressive and familiar to Unix shell users.  Thus,\nwe have 'Iter's, which are data sinks that consume input and produce a\nresult.  Then we have 'Inum's, which are also 'Iter's.  These two data\ntypes and can combined through pipes (i.e., fusing) and concatenation,\nboth of which have direct analogues in the Unix @|@ (pipe) operator\nand @cat@ command.\n\nBasing everything around these few concepts makes the library easier\nto learn and use.  For instance, because all 'Inum's are 'Iter's,\nthere is only one set of 'Iter' building blocks to learn.  'Inum'\nimplementations invoke the same 'Iter's that are used to build other\n'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling\nmechanism.  Finally, because 'Onum's are also 'Inum's, one set of\nfusing and concatenation operators works for both.\n\nBy contrast, both the iteratee and enumerator packages use enumerator\ntypes that are not iteratees.  Hence, constructing enumerators is\nharder and requires a different error handing mechanism.  The packages\nmust introduce a third, hybrid \\\"Enumeratee\\\" type for inner pipeline\nstages, and fusing Enumerators to Enumeratees is a different function\nfrom fusing Enumeratees together.\n\nFunneling everything through a small number of abstractions also\nensures that the right thing happens in corner cases.  In particular,\nall enumerator application happens through the pipe operator.  Though\nthere are two pipe operators, a left associative one and a right\nassociative one, they internally use the same function:  @a '|.' b =\n(a '.|') . b@.  Similarly, the pipe application operators ('|$' and\n'.|$') are defined in terms of '.|'.\n\n'.|' guarantees that its right-hand argument will receive an EOF when\nthe left hand argument terminates (whether normally or through an\nexception).  This is crucial for managing resources such file\ndescriptors, and works no matter how convoluted the control structure\nof your program.\n\nConsider the following realistic scenario of a web server constructed\nas an 'Inum' that translates from HTTP requests to HTTP responses.\n(Such an 'Inum' is provided by the function 'inumHttpServer' in\n\"Data.IterIO.HTTP\".)  The server's accept loop would resemble the\nfollowing:\n\n@\n   loop = do\n     (sock, _) <- Net.accept $ listen_socket\n     _ <- forkIO $ do\n            (iter, enum) <- 'iterStream' (sock)\n            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter\n     loop\n@\n\nThis code depends on the fact that 'iterStream' closes @sock@ after\nboth the @iter@ has received an EOF and the @enum@ has returned.  One\nlevel down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',\nand has code looking something like this:\n\n@\n     req <- 'httpReqI'                              -- parse HTTP request\n     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler\n     'irun' $ enumHttpResp resp Nothing             -- send response to client\n@\n\nThe @handler@ gets run on the body of the message, and might decide to\nprocess an HTTP POST request by saving an uploaded file to disk, for\ninstance with code like this:\n\n@\n     let saveFile _ field\n           | ffName field == S8.pack \\\"file\\\" = do\n                            h <- liftIO $ openBinaryFile \\\"upload\\\" WriteMode\n                            'handleI' h ``finallyI`` liftIO (hClose h)\n           | otherwise = return ()\n     in foldForm req saveFile ()\n@\n\n@foldForm@ internally is invoking an 'Inum' that parses HTTP\nmultipart/form-data to pipe each field of the form to the @saveFile@\nfunction.\n\nNow suppose 'inumHttpBody' fails (most likely because it receives an\nEOF before reading the number of bytes specified in the Content-Length\nheader).  Because 'inumHttpBody' is fused to @handler@, the failure\nwill cause @handler@ to receive an EOF, which will cause @foldForm@ to\nfail, which will cause 'handleI' to receive an EOF and return, which\nwill ensure 'hClose' runs and the file handle @h@ is not leaked.\n\nOnce the EOFs have been processed, the exception will propagate\nupwards making 'inumHttpServer' fail, which in turn will send an EOF\nto @iter@.  Then the exception will cause @enum@ to fail, after which\n@sock@ will be closed.  In summary, despite the complex structure of\nthe web server, because all the components are fused together with\npipe operators, corner cases like this just work with no need to worry\nabout leaked file descriptors.\n\n* /Uniform error-handling and simplified monad transformers/\n\nThe iterIO library provides a traditional throw and catch exception\nmechanism using its own functions 'throwI' and 'catchI', but keeping\nthe standard library exception hierarchy from \"Control.Exception\".\nAll of the support routines are carefully crafted to ensure that this\nsingle exception mechanism is the only one you ever need, so that you\ndon't end up having to integrate different components with different\nerror strategies, a situation summarized amusingly in the following\nblog post:\n<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.\n\nA key to uniform error handling is ensuring that errors can be\npropagated cleanly across different monads and transformers.  Thus,\nfor instance, the iterIO 'liftIO' function translates all uncaught IO\nerrors into 'Iter' errors.\n\nMore importantly, iterIO is designed to support the standard mtl monad\ntransformers while keeping 'Iter' as the outermost monadic type.  For\ninstance, if deep in the middle of some @'Iter' t 'IO'@ computation\nyou need a state transformer monad, you can invoke one with\n'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen\nby comparing their effective types, 'runStateTI' keeps the 'Iter'\nmonad on the outside, and thus can cleanly propagate failures out of\nthe 'StateT' subcomputation:\n\n> runStateT  :: StateT s m a -> s -> m (a, s)\n>\n> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)\n\nSimilarly, there is a function @'liftI' :: (MonadTrans t) => Iter\ns m a -> Iter s (t m) a@ that can be used to execute a computation in\nwhich a level of monad transformer is stripped off the inner monadic\ntype.\n\nAn equally important feature is the ability to distinguish 'Iter'\nfailures from 'Inum' failures, given that the former are often more\nserious than the latter.  As shown by the @grep@ example in the\ntutorial above, when one in a series of concatenated 'Inum's fails,\nyou often want to keep going without losing the state of the 'Iter'.\nThe enumerator package does not appear to support this distinction.\nThe iteratee package might, but it is not clear how to implement the\niteratee equivalent of the @grep@ example above.\n\nBy contrast, iterIO's 'Inum' mechanism was designed to be intuitive.\nIf you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then\nyou will catch exactly the errors thrown by those 'Inum's, not those\nthrown by pipeline stages outside the scope of the 'inumCatch' call.\n\nIt is because of this unified error handling mechanism that examples\nsuch as the HTTP server above can be guaranteed not to leak resources.\n\n* /Parser combinators for LL(*) grammars/\n\nIterIO's \"Data.IterIO.Parse\" module supports parsing of iteratee input\nusing combinators similar to those found in parsec.  However, parsec\nsupports only LL(1) grammars, and can lead to confusing failures--for\ninstance the parser @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ would fail\non input @\\\"for\\\"@.  IterIO, by contrast, supports full LL(*) parsing,\nmeaning a parser can look arbitrarily far ahead before failing.\n\nLL(*) parsers are generally disfavored because of their potential to\nconsume arbitrarily large amounts of memory to remember input for\nbacktracking.  However, iterIO offers two mechanisms that mitigate the\nproblem.\n\nFirst, because 'Iter's are constructed in such a way as to\ndifferentiate requests for more input from execution of monadic\nactions, it is possible to run multiple parsers in parallel.  Consider\na hypothetical parser such as the following, designed to recognize the\ninput format and parse either XML or JSON data:\n\n@\n  parser :: 'Iter' 'L.ByteString' m Value\n  parser = ('string' \\\"\\<!DOCTYPE\\\" >> parseXml)\n           \\<|\\> ('char' \\'{\\' >> parseJson)\n@\n\n@\\<|\\>@ is an infix synonym for the iterIO function 'multiParse',\nwhich attempts to run two parsers concurrently on input as it arrives.\nBecause 'string' and 'char' are both pure parser combinators with no\nmonadic side effects, it is possible to run them both concurrently\nwithout fear that the second rule--if it fails--will nonetheless have\nproduced side effects.  In fact, at least one of the 'string' or the\n'char' action will fail almost immediately, likely on the first chunk\nof data.  After one of the two has signaled a parse error, there is no\nlonger any need to store input for backtracking.  Note this works even\nif the subsequent functions @parseXml@ and @parseJson@ have monadic\nside effects, because 'multiParse' doesn't need to invoke those\nmonadic actions to determine that one of the two parsers has failed.\n\nA second way to avoid large amounts of storage for backtracking is to\nuse iterIO's '\\/' operator, which is an infix synonym for 'ifNoParse'.\nThe formulation @iter '\\/' no $ yes@ splits a parser into three\ncomponents.  @iter@ is executed with backtracking enabled.  If it\nsucceeds, then the saved data is discarded, @iter@'s result is fed to\nthe function @yes@, and any further failures will not cause input to\nbe rewound.  If, on the other hand, @iter@ fails, then input is\nrewound and @no@ is executed.  The '\\/' operator is very convenient\nfor long folds whose individual elements do not consume a lot of\ninput.  For example, to parse and sum a list of numbers (given a\nparser @number@ that skips spaces then parses one number), you might\ndo something like this:\n\n> parseAndSumIntegerList :: Iter String IO Int\n> parseAndSumIntegerList = loop 0\n>     where loop n = number \\/ return n $ \\n' -> loop (n + n')\n\nRegardless of the length of the list of numbers being parsed,\n@sumNumbers@ only ever needs to backtrack over the input consumed by a\nsingle iteration of @number@, which is likely a small amount of extra\nmemory to keep around.\n\nIf you do want an LL(1) parser combinator library, iterIO supports\nseamless integration with the attoparsec package.  The function 'atto'\nin \"Data.IterIO.Atto\" turns an attoparsec @Parser@ into an 'Iter'\nmonad, treating an attoparsec failure as an 'Iter' exception that can\nbe handled in the usual way with 'ifParse' or 'multiParse', or just\ncaught with 'catchI'.  (Attoparsec has the additional advantage of\nsolving the annoying @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ issue by\nspecial-casing @string@ to have more lookahead.)\n\nPreliminary testing suggests that attoparsec can be about three times\nfaster than \"Data.IterIO.Parse\" on parse-intensive workloads.  The\nlimitation is that attoparsec parsers must be pure.  A good compromise\nmay be to use IterIO for coarse-grained parsing, and attoparsec for\nmore complex data structures.  For example, you might want to use\niterIO's parsing of HTTP multipart/form-data (so as to be able to pipe\nfiles to disk in constant space), but for fields with JSON data, use\n'atto' to pipe the contents to the excellent attoparsec-based aeson\npackage.\n\n-}" Nothing),DP (1,1)),((AnnComment DComment (DP (-324,1),DP (1,3)) "{- $Differences\n\nThe Iteratee approach was originally advocated by Oleg Kiselyov (see\ntalk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The\nmain implementation by Kiselyov and John Lato is simply called\n/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another\nrealization of the iteratee concepts is the /enumerator/ package\n(<http://hackage.haskell.org/package/enumerator>).  IterIO is a\nre-implementation of these concepts from scratch.  This section\ndiscusses the differences between previous packages and iterIO, both\nas a means for motivating iterIO's design and as a set of suggestions\nfor improving other iteratee implementations.\n\n* /Base abstraction/\n\nThe iterIO package represents an iteratee as a pure function from a\nchunk of pending input data to an iteratee result of type 'IterR':\n\n@\n  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }\n@\n\nAn 'IterR' can yield a result and residual input, or it can ask for\nmore input, or it can request to have an action executed in the\nunderlying monad, or it can signal failure.  The fact that all\niteratees are functions of input ensures that iteratees generally see\n/all/ pending input.  Thus, iteratees can do things like measure the\nlength of buffered input to subtract it from the current file offset\nand determine the effective position in a file.\n\n`IterR`'s division of iteratee results into different outcomes such as\nneeding input or needing monadic actions allows the library to\ndistinguish between pure iteratees and those with potential side\neffects.  The ability to know that a specific iteratee is a pure\nfunction in many cases allows one to parse LL(*) grammars without\nlarge amounts of input buffering for backtracking (see below).\n\nIn contrast, the iteratee package uses continuation passing style\n(CPS), in which an iteratee is a function taking two continuation\nfunctions--one to call when done, and a second to call when either\nrequesting more input or failing:\n\n> -- From the iteratee package:\n> newtype Iteratee s m a = Iteratee{ runIter :: forall r.\n>        -- First the \"onDone\" function:\n>           (a -> Stream s -> m r) ->\n>        -- Next the \"onCont\" function:\n>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->\n>           m r}\n\nCPS has the advantage of exposing the bind operator of the underlying\nmonad, making 'lift' cheap and simple.  Moreover, splitting into two\ncontinuations saves the first and most common one (i.e., \\\"onDone\\\")\nfrom the overhead of checking whether an error condition or request\nfor more input has occurred.  See\n<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>\nfor a good discussion of the advantages of CPS.\n\nBecause of CPS, iteratee should be capable of delivering the best\nperformance of the three iteratee packages.  A disadvantage of\niterIO's approach is that every invocation of 'lift' must be\npropagated all the way up the call chain, where a small amount of\noverhead is added for each enclosing 'catchI' or similar call.  While\niterIO can handle most successful 'IterR' outcomes and caught\nexceptions locally without popping back up the call stack, there is\nalso potentially overhead from actually checking that the outcome was\nsuccessful at each bind site.  (GHC's inliner may be able to avoid the\ncheck in some cases.)\n\nHowever, iteratee lacks several features of iterIO; offering these\nfeatures would likely reduce the benefits of CPS and complicate code.\nFor instance, there is no way to execute a pure iteratee without\nmonadic actions (the benefit touted above and described below for\nLL(*) parsing).  Moreover, iteratee's exception mechanism discards the\ncurrent location in the input stream, making it unsuitable for failed\nparse alternatives.  IterIO provides a general control mechanism to\nmake arbitrary requests from enumerators (such as seek, tell,\ngetpeername, get SSL information, etc.); iteratee instead overloads\nthe exception mechanism for control purposes, which prevents control\noperations from returning values.  Thus, while iteratee can implement\nseek, it cannot, for instance, implement tell.\n\nThe enumerator package's approach is closer to iterIO's, but makes\nevery iteratee into a monadic action in the underlying monad @m@:\n\n> -- From the enumerator package:\n> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }\n\nHere @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper\ndisallows iterIO's LL(*) parsing tricks.  It also causes gratuitous\ninvocation of @m@'s bind function, which can be expensive when using\nstacks of monad transformers.  Furthermore, enumerator discards the\ninput state on all errors, making it impossible to resume from\nfailures that leave the input in a known state (such as a parsing\nlookahead failure).\n\n* /Uniformity of abstraction/\n\nIterIO's abstractions were refined over many iterations to become\nminimal yet highly expressive and familiar to Unix shell users.  Thus,\nwe have 'Iter's, which are data sinks that consume input and produce a\nresult.  Then we have 'Inum's, which are also 'Iter's.  These two data\ntypes and can combined through pipes (i.e., fusing) and concatenation,\nboth of which have direct analogues in the Unix @|@ (pipe) operator\nand @cat@ command.\n\nBasing everything around these few concepts makes the library easier\nto learn and use.  For instance, because all 'Inum's are 'Iter's,\nthere is only one set of 'Iter' building blocks to learn.  'Inum'\nimplementations invoke the same 'Iter's that are used to build other\n'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling\nmechanism.  Finally, because 'Onum's are also 'Inum's, one set of\nfusing and concatenation operators works for both.\n\nBy contrast, both the iteratee and enumerator packages use enumerator\ntypes that are not iteratees.  Hence, constructing enumerators is\nharder and requires a different error handing mechanism.  The packages\nmust introduce a third, hybrid \\\"Enumeratee\\\" type for inner pipeline\nstages, and fusing Enumerators to Enumeratees is a different function\nfrom fusing Enumeratees together.\n\nFunneling everything through a small number of abstractions also\nensures that the right thing happens in corner cases.  In particular,\nall enumerator application happens through the pipe operator.  Though\nthere are two pipe operators, a left associative one and a right\nassociative one, they internally use the same function:  @a '|.' b =\n(a '.|') . b@.  Similarly, the pipe application operators ('|$' and\n'.|$') are defined in terms of '.|'.\n\n'.|' guarantees that its right-hand argument will receive an EOF when\nthe left hand argument terminates (whether normally or through an\nexception).  This is crucial for managing resources such file\ndescriptors, and works no matter how convoluted the control structure\nof your program.\n\nConsider the following realistic scenario of a web server constructed\nas an 'Inum' that translates from HTTP requests to HTTP responses.\n(Such an 'Inum' is provided by the function 'inumHttpServer' in\n\"Data.IterIO.HTTP\".)  The server's accept loop would resemble the\nfollowing:\n\n@\n   loop = do\n     (sock, _) <- Net.accept $ listen_socket\n     _ <- forkIO $ do\n            (iter, enum) <- 'iterStream' (sock)\n            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter\n     loop\n@\n\nThis code depends on the fact that 'iterStream' closes @sock@ after\nboth the @iter@ has received an EOF and the @enum@ has returned.  One\nlevel down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',\nand has code looking something like this:\n\n@\n     req <- 'httpReqI'                              -- parse HTTP request\n     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler\n     'irun' $ enumHttpResp resp Nothing             -- send response to client\n@\n\nThe @handler@ gets run on the body of the message, and might decide to\nprocess an HTTP POST request by saving an uploaded file to disk, for\ninstance with code like this:\n\n@\n     let saveFile _ field\n           | ffName field == S8.pack \\\"file\\\" = do\n                            h <- liftIO $ openBinaryFile \\\"upload\\\" WriteMode\n                            'handleI' h ``finallyI`` liftIO (hClose h)\n           | otherwise = return ()\n     in foldForm req saveFile ()\n@\n\n@foldForm@ internally is invoking an 'Inum' that parses HTTP\nmultipart/form-data to pipe each field of the form to the @saveFile@\nfunction.\n\nNow suppose 'inumHttpBody' fails (most likely because it receives an\nEOF before reading the number of bytes specified in the Content-Length\nheader).  Because 'inumHttpBody' is fused to @handler@, the failure\nwill cause @handler@ to receive an EOF, which will cause @foldForm@ to\nfail, which will cause 'handleI' to receive an EOF and return, which\nwill ensure 'hClose' runs and the file handle @h@ is not leaked.\n\nOnce the EOFs have been processed, the exception will propagate\nupwards making 'inumHttpServer' fail, which in turn will send an EOF\nto @iter@.  Then the exception will cause @enum@ to fail, after which\n@sock@ will be closed.  In summary, despite the complex structure of\nthe web server, because all the components are fused together with\npipe operators, corner cases like this just work with no need to worry\nabout leaked file descriptors.\n\n* /Uniform error-handling and simplified monad transformers/\n\nThe iterIO library provides a traditional throw and catch exception\nmechanism using its own functions 'throwI' and 'catchI', but keeping\nthe standard library exception hierarchy from \"Control.Exception\".\nAll of the support routines are carefully crafted to ensure that this\nsingle exception mechanism is the only one you ever need, so that you\ndon't end up having to integrate different components with different\nerror strategies, a situation summarized amusingly in the following\nblog post:\n<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.\n\nA key to uniform error handling is ensuring that errors can be\npropagated cleanly across different monads and transformers.  Thus,\nfor instance, the iterIO 'liftIO' function translates all uncaught IO\nerrors into 'Iter' errors.\n\nMore importantly, iterIO is designed to support the standard mtl monad\ntransformers while keeping 'Iter' as the outermost monadic type.  For\ninstance, if deep in the middle of some @'Iter' t 'IO'@ computation\nyou need a state transformer monad, you can invoke one with\n'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen\nby comparing their effective types, 'runStateTI' keeps the 'Iter'\nmonad on the outside, and thus can cleanly propagate failures out of\nthe 'StateT' subcomputation:\n\n> runStateT  :: StateT s m a -> s -> m (a, s)\n>\n> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)\n\nSimilarly, there is a function @'liftI' :: (MonadTrans t) => Iter\ns m a -> Iter s (t m) a@ that can be used to execute a computation in\nwhich a level of monad transformer is stripped off the inner monadic\ntype.\n\nAn equally important feature is the ability to distinguish 'Iter'\nfailures from 'Inum' failures, given that the former are often more\nserious than the latter.  As shown by the @grep@ example in the\ntutorial above, when one in a series of concatenated 'Inum's fails,\nyou often want to keep going without losing the state of the 'Iter'.\nThe enumerator package does not appear to support this distinction.\nThe iteratee package might, but it is not clear how to implement the\niteratee equivalent of the @grep@ example above.\n\nBy contrast, iterIO's 'Inum' mechanism was designed to be intuitive.\nIf you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then\nyou will catch exactly the errors thrown by those 'Inum's, not those\nthrown by pipeline stages outside the scope of the 'inumCatch' call.\n\nIt is because of this unified error handling mechanism that examples\nsuch as the HTTP server above can be guaranteed not to leak resources.\n\n* /Parser combinators for LL(*) grammars/\n\nIterIO's \"Data.IterIO.Parse\" module supports parsing of iteratee input\nusing combinators similar to those found in parsec.  However, parsec\nsupports only LL(1) grammars, and can lead to confusing failures--for\ninstance the parser @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ would fail\non input @\\\"for\\\"@.  IterIO, by contrast, supports full LL(*) parsing,\nmeaning a parser can look arbitrarily far ahead before failing.\n\nLL(*) parsers are generally disfavored because of their potential to\nconsume arbitrarily large amounts of memory to remember input for\nbacktracking.  However, iterIO offers two mechanisms that mitigate the\nproblem.\n\nFirst, because 'Iter's are constructed in such a way as to\ndifferentiate requests for more input from execution of monadic\nactions, it is possible to run multiple parsers in parallel.  Consider\na hypothetical parser such as the following, designed to recognize the\ninput format and parse either XML or JSON data:\n\n@\n  parser :: 'Iter' 'L.ByteString' m Value\n  parser = ('string' \\\"\\<!DOCTYPE\\\" >> parseXml)\n           \\<|\\> ('char' \\'{\\' >> parseJson)\n@\n\n@\\<|\\>@ is an infix synonym for the iterIO function 'multiParse',\nwhich attempts to run two parsers concurrently on input as it arrives.\nBecause 'string' and 'char' are both pure parser combinators with no\nmonadic side effects, it is possible to run them both concurrently\nwithout fear that the second rule--if it fails--will nonetheless have\nproduced side effects.  In fact, at least one of the 'string' or the\n'char' action will fail almost immediately, likely on the first chunk\nof data.  After one of the two has signaled a parse error, there is no\nlonger any need to store input for backtracking.  Note this works even\nif the subsequent functions @parseXml@ and @parseJson@ have monadic\nside effects, because 'multiParse' doesn't need to invoke those\nmonadic actions to determine that one of the two parsers has failed.\n\nA second way to avoid large amounts of storage for backtracking is to\nuse iterIO's '\\/' operator, which is an infix synonym for 'ifNoParse'.\nThe formulation @iter '\\/' no $ yes@ splits a parser into three\ncomponents.  @iter@ is executed with backtracking enabled.  If it\nsucceeds, then the saved data is discarded, @iter@'s result is fed to\nthe function @yes@, and any further failures will not cause input to\nbe rewound.  If, on the other hand, @iter@ fails, then input is\nrewound and @no@ is executed.  The '\\/' operator is very convenient\nfor long folds whose individual elements do not consume a lot of\ninput.  For example, to parse and sum a list of numbers (given a\nparser @number@ that skips spaces then parses one number), you might\ndo something like this:\n\n> parseAndSumIntegerList :: Iter String IO Int\n> parseAndSumIntegerList = loop 0\n>     where loop n = number \\/ return n $ \\n' -> loop (n + n')\n\nRegardless of the length of the list of numbers being parsed,\n@sumNumbers@ only ever needs to backtrack over the input consumed by a\nsingle iteration of @number@, which is likely a small amount of extra\nmemory to keep around.\n\nIf you do want an LL(1) parser combinator library, iterIO supports\nseamless integration with the attoparsec package.  The function 'atto'\nin \"Data.IterIO.Atto\" turns an attoparsec @Parser@ into an 'Iter'\nmonad, treating an attoparsec failure as an 'Iter' exception that can\nbe handled in the usual way with 'ifParse' or 'multiParse', or just\ncaught with 'catchI'.  (Attoparsec has the additional advantage of\nsolving the annoying @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ issue by\nspecial-casing @string@ to have more lookahead.)\n\nPreliminary testing suggests that attoparsec can be about three times\nfaster than \"Data.IterIO.Parse\" on parse-intensive workloads.  The\nlimitation is that attoparsec parsers must be pure.  A good compromise\nmay be to use IterIO for coarse-grained parsing, and attoparsec for\nmore complex data structures.  For example, you might want to use\niterIO's parsing of HTTP multipart/form-data (so as to be able to pipe\nfiles to disk in constant space), but for fields with JSON data, use\n'atto' to pipe the contents to the excellent attoparsec-based aeson\npackage.\n\n-}" Nothing),DP (-324,1)),((AnnComment DComment (DP (1,1),DP (13,3)) "{- $Acknowledgments\n\nDaniel Giffin contributed numerous suggestions and improvements to\nboth the code and documentation.  Deian Stefan and David Terei helped\nwith testing and improving the package, as well as understanding\nvarious relevant aspects of Haskell and GHC.  Mike Hamburg made the\nkey suggestion of defining 'Onum's as type-restricted 'Inum's.  The\nauthor is grateful to John Lato for helping him understand much of the\nimportant design rationale behind the original iteratee package.  This\nwork was funded by the DARPA Clean-Slate Design of Resilient,\nAdaptive, Secure Hosts (CRASH) program, BAA-10-70.\n\n-}" Nothing),DP (1,1)),((AnnComment DComment (DP (-11,1),DP (1,3)) "{- $Acknowledgments\n\nDaniel Giffin contributed numerous suggestions and improvements to\nboth the code and documentation.  Deian Stefan and David Terei helped\nwith testing and improving the package, as well as understanding\nvarious relevant aspects of Haskell and GHC.  Mike Hamburg made the\nkey suggestion of defining 'Onum's as type-restricted 'Inum's.  The\nauthor is grateful to John Lato for helping him understand much of the\nimportant design rationale behind the original iteratee package.  This\nwork was funded by the DARPA Clean-Slate Design of Resilient,\nAdaptive, Secure Hosts (CRASH) program, BAA-10-70.\n\n-}" Nothing),DP (-11,1)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  ByteString enumfile MonadTrans liftIOexampleI liftIO putStrLn" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  linesOutI foldr enumLines IOError IterR hPutStrLn stderr mline" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  resumeI isDoesNotExistError reRunIter verboseResumeI Oleg Lato" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,59)) "--  LocalWords:  combinator aeson Giffin Deian Terei DARPA" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-58),DP (0,21)) "--  LocalWords:  multiParse ifNoParse parseAndSumIntegerList sumNumbers ifParse" Nothing),DP (0,-58)),((AnnComment DComment (DP (1,1),DP (1,1)) "" Nothing),DP (1,1)),((AnnComment DComment (DP (0,0),DP (0,58)) "--  LocalWords:  combinator aeson Giffin Deian Terei DARPA" Nothing),DP (0,0)),((G AnnEofPos),DP (857,0))])
 (HsModule 
  (Just 
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:47:8-18 }
    Nothing{ModuleName: Data.IterIO})) 
  (Just 
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(48,5)-(64,5) }
    Just (Ann (DP (1,5)) (ColDelta 5) DP (1,5) [] [((G AnnOpenP),DP (0,0)),((AnnComment DComment (DP (2,5),DP (2,18)) "-- * Overview" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,17)) "-- $Overview" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,18)) "-- * Tutorial" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,17)) "-- $Tutorial" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,50)) "-- * Differences from other iteratee packages" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,20)) "-- $Differences" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,25)) "-- * Acknowledgments" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,24)) "-- $Acknowledgments" Nothing),DP (1,5)),((G AnnCloseP),DP (13,5))])
    [
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:6-28 }
      Just (Ann (DP (0,0)) (ColDelta 6) DP (0,0) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])
      (IEModuleContents 
       ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:13-28 }
        Nothing{ModuleName: Data.IterIO.Iter}))),
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:7-30 }
      Just (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])
      (IEModuleContents 
       ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:14-30 }
        Nothing{ModuleName: Data.IterIO.Trans}))),
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:7-29 }
      Just (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])
      (IEModuleContents 
       ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:14-29 }
        Nothing{ModuleName: Data.IterIO.Inum}))),
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:7-33 }
      Just (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1))])
      (IEModuleContents 
       ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:14-33 }
        Nothing{ModuleName: Data.IterIO.ListLike})))])) 
  [
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,1)-(67,32) }
    Just (Ann (DP (2,1)) (ColDelta 1) DP (2,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])
    (ImportDecl 
     (Nothing) 
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:8-23 }
      Nothing{ModuleName: Data.IterIO.Iter}) 
     (Nothing) 
     (False) 
     (False) 
     (False) 
     (False) 
     (Nothing) 
     (Just 
      ((,) 
       (True) 
       ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32) }
        Just (Ann (DP (0,1)) (ColDelta 25) DP (0,1) [] [((G AnnHiding),DP (0,0)),((G AnnOpenP),DP (0,1)),((AnnComment DComment (DP (0,1),DP (0,28)) "-- names that might collide" Nothing),DP (0,1)),((G AnnCloseP),DP (1,32))])
        [
         ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:33-36 }
          Just (Ann (DP (0,0)) (ColDelta 33) DP (0,0) [] [])
          (IEVar 
           ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:33-36 }
            Just (Ann (DP (0,0)) (ColDelta 33) DP (0,0) [] [((G AnnVal),DP (0,0)),((G AnnComma),DP (0,0))])
            (Unqual {OccName: null})))),
         ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:39-41 }
          Just (Ann (DP (0,1)) (ColDelta 39) DP (0,1) [] [])
          (IEVar 
           ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:39-41 }
            Just (Ann (DP (0,0)) (ColDelta 39) DP (0,0) [] [((G AnnVal),DP (0,0))])
            (Unqual {OccName: run}))))]))))),
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1-24 }
    Just (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])
    (ImportDecl 
     (Nothing) 
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:8-24 }
      Nothing{ModuleName: Data.IterIO.Trans}) 
     (Nothing) 
     (False) 
     (False) 
     (False) 
     (False) 
     (Nothing) 
     (Nothing))),
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1-23 }
    Just (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])
    (ImportDecl 
     (Nothing) 
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:8-23 }
      Nothing{ModuleName: Data.IterIO.Inum}) 
     (Nothing) 
     (False) 
     (False) 
     (False) 
     (False) 
     (Nothing) 
     (Nothing))),
   ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1-27 }
    Just (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])
    (ImportDecl 
     (Nothing) 
     ({ ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:8-27 }
      Nothing{ModuleName: Data.IterIO.ListLike}) 
     (Nothing) 
     (False) 
     (False) 
     (False) 
     (False) 
     (Nothing) 
     (Nothing)))] 
  [] 
  (Nothing) 
  (Nothing)))
==============
[(AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:1:1 CN "HsModule" NotNeeded,
  (Ann (DP (0,0)) (ColDelta 1) DP (0,0) [] [((AnnComment DComment (DP (0,0),DP (0,20)) "{-# LANGUAGE CPP #-}" Nothing),DP (0,0)),((AnnComment DComment (DP (1,1),DP (1,64)) "#if defined(__GLASGOW_HASKELL__) && (__GLASGOW_HASKELL__ >= 702)" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,22)) "{-# LANGUAGE Safe #-}" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,6)) "#endif" Nothing),DP (1,1)),((AnnComment DComment (DP (2,1),DP (41,3)) "{- |\n\nThis is the main module to import for the IterIO package.  It\nre-exports several other modules and mostly consists of\ndocumentation--first a high-level overview of the iteratee model, then\na more detailed tutorial, finally a discussion of the differences from\nother iteratee packages and acknowledgments.\n\nSee the \"Data.IterIO.Iter\", \"Data.IterIO.Inum\", and\n\"Data.IterIO.ListLike\" modules for more detailed documentation of data\nstructures and functions.  In addition, \"Data.IterIO.Trans\" (also\nre-exported by this module) supplies functions that help you invoke\nmonad transformers from the mtl library from within the 'Iter' monad.\n\nSeveral other potentially useful modules in the package are not\nexported by default:\n\n * \"Data.IterIO.Parse\" includes parsec-like parsing combinators for\n   iteratee input.\n\n * \"Data.IterIO.Zlib\" provides zlib and gzip format compression and\n   decompression.\n\n * \"Data.IterIO.SSL\" provides support for SSL.\n\n * \"Data.IterIO.Http\" provides support for parsing and formatting\n   HTTP, including handling form and file uploads (which can be\n   processed in constant space).  This may be useful in conjunction\n   with \"Data.IterIO.HttpRoute\", which provides simple request routing\n   support for web servers.\n\n * \"Data.IterIO.Atto\" provides support for running attoparsec parsers\n   on iteratee input (see\n   <http://hackage.haskell.org/package/attoparsec/>).\n\n * \"Data.IterIO.Extra\" provides debugging functions, as well as a\n   loopback iteratee that can be used to test a protocol\n   implementation against itself.\n\n-}" Nothing),DP (2,1)),((G AnnModule),DP (46,1)),((G AnnVal),DP (0,1)),((G AnnWhere),DP (0,1)),((AnnComment DComment (DP (2,1),DP (54,3)) "{- $Overview\n\n   At a high level, an iteratee is a data sink that is fed chunks of\n   data.  It may return a useful result, or its utility may lie in\n   monadic side-effects, such as storing received data to a file.\n   Iteratees are represented by the type @'Iter' t m a@.  Here @t@ is\n   the type of data that the iteratee receives as input.  (@t@ must be\n   an instance of 'ChunkData', such as 'String' or lazy @ByteString@.)\n   @m@ is the 'Monad' in which the iteratee runs--for instance 'IO'\n   (or an instance of 'MonadIO') for the iteratee to perform IO.  @a@\n   is the type that the iteratee will return when it has consumed\n   enough input to produce a result.\n\n   An enumerator is a data source that feeds data chunks to an\n   iteratee.  Enumerators are also iteratees.  We use the type @'Inum'\n   tIn tOut m a@ to represent these /iteratee-enumerators/.  As an\n   iteratee, an 'Inum' sinks data of some input type, generally\n   designated @tIn@.  As an enumerator, the 'Inum' feeds data of a\n   potentially different type, @tOut@, to another iteratee.  Thus, the\n   'Inum' can be viewed as transcoding data from type @tIn@ to type\n   @tOut@ for consumption by another iteratee.\n\n   'Inum's are generally constructed using the functions @'mkInum'@\n   and @'mkInumM'@ in module \"Data.IterIO.Inum\".  The first function\n   uses a simple @'Iter' tIn m tOut@ to translate between input type\n   @tIn@ and output type @tOut@.  The second function, @'mkInumM'@,\n   allows construction of more complex 'Inum's.\n\n   An important special kind of 'Inum' is an /outer enumerator/,\n   which is just an 'Inum' with the void input type @()@.  Outer\n   enumerators are sources of data.  Rather than transcode input\n   data, they produce data from monadic actions (or from pure data\n   in the case of 'inumPure').  The type 'Onum' represents outer\n   enumerators and is a synonym for 'Inum' with an input type of\n   @()@.\n\n   To execute iteratee-based IO, you must apply an 'Onum' to an\n   'Iter' with the '|$' (\\\"pipe apply\\\") binary operator.\n\n   An important property of enumerators and iteratees is that they can\n   be /fused/.  The '|.' (\\\"fuse leftward\\\") operator fuses two\n   'Inum's together (provided the output type of the first is the\n   input type of the second), yielding a new 'Inum' that transcodes\n   from the input type of the first to the output type of the second.\n   Similarly, the '.|' (\\\"fuse rightward\\\") operator fuses an 'Inum'\n   to an 'Iter', yielding a new 'Iter' with a potentially different\n   input type.\n\n   Enumerators of the same type can also be /concatenated/, using\n   the 'cat' function.  @enum1 ``cat`` enum2@ produces an enumerator\n   whose effect is to feed first @enum1@'s data then @enum2@'s data\n   to an 'Iter'.\n-}" Nothing),DP (2,1)),((AnnComment DComment (DP (2,1),DP (438,3)) "{- $Tutorial\n\n #tutorial#\n\nThe iterIO library performs IO by hooking up sources of data, called\n/enumerators/, to data sinks, called /iteratees/, in a manner\nreminiscent of Unix command pipelines.  Compared to lazy IO, the\nenumerator/iteratee paradigm provides better error handing,\nreferential transparency (which should, after all, be one of the big\nadvantages of Haskell), and equally convenient composition of protocol\nlayers and parsers without worrying about IO chunk boundaries.\n\nEnumerators, implemented by the type 'Onum' (short for\n/outer enumerator/, for reasons that will become clear below), are so\ncalled because they enumerate all data elements (e.g., bytes or\npackets) in some source such as a file or socket.  Hence, an\nenumerator should be viewed as a /source/ outputting chunks of data\nwhose type is a @'Monoid'@.  (Actually, the input type must be of\nclass 'ChunkData', which is a @'Monoid'@ that additionally has a\nmethod @'null'@ to test whether a piece of data is equal to\n'mempty'.)\n\nIteratees, implemented by the type 'Iter', should be viewed as /sinks/\nconsuming data.  When executing IO, the library /iterates/ over all\ndata elements output by the source, using an iteratee to produce a\nresult.  The source may output data in chunks whose boundaries do not\ncoincide with logical message units; iteratees handle this\ntransparently, simplifying programming.\n\nHere is a simple example:\n\n@\n    -- Return the first line of a file\n    headFile :: FilePath -> IO String\n    headFile path = 'enumFile' path '|$' 'lineI'\n@\n\n'enumFile' enumerates the contents of a file.  'lineI' returns a line\nof input (discarding the newline).  '|$' is the /pipe apply/ operator\nthat applies an 'Onum' to an 'Iter', returning the result of the\n'Iter'--in this case the first line of the file named @path@.\n\nAn `Iter`'s main purpose may not be to produce a result.  Some 'Iter's\nare primarily useful for their side effects.  For example, 'stdoutI'\nwrites data to standard output; 'handleI' similarly writes output to\nan arbitrary file handle.  Thus, the following function copies the\ncontents of a file to standard output:\n\n@\n    -- Copy file to standard output\n    catFile :: FilePath -> IO ()\n    catFile path = 'enumFile'' path '|$' 'stdoutI'\n@\n\n'enumFile'' is like 'enumFile' above, but type restricted to data in\nthe lazy @'ByteString'@ format, which is more efficient than plain\n'String's.  ('enumFile' supports multiple types, but in this example\nthere is not enough information for Haskell to choose one of them, so\nwe must use 'enumFile'' or use @::@ to specify a type explicitly.)\nOnce again, '|$' is used to execute the IO actions, but, this time,\nthe return value is just @()@; the interesting action lies in the side\neffects of writing data to standard output while iterating over the\ninput with 'stdoutI'.\n\nThe real power of the iteratee abstraction lies in the fact that\n'Iter's are monadic computations.  One 'Iter' may invoke another to\nmake use of the first one's results.  Here is an example of a function\nthat returns the first two lines of a file:\n\n@\n    -- | Return first two lines of file\n    head2File :: FilePath -> IO (String, String)\n    head2File path = 'enumFile' path '|$' lines2I\n@\n\n@\n    -- | Iter that returns next two lines as a pair\n    lines2I :: (Monad m) => 'Iter' String m (String, String)\n    lines2I = do\n      line1 <- 'lineI'\n      line2 <- 'lineI'\n      return (line1, line2)\n@\n\nThis example illustrates several points.  First, consider the type of\nthe @lines2I@ function:  @'Iter' String m (String, String)@.  The\n'Iter' type constructor takes three type arguments.  The first,\n'String' in this case, specifies the type of input expected by the\niteratee.  The last type, @(String, String)@ in this case, specifies\nthe result type of the iteratee.  Finally, the middle type, @m@, is a\nmonad, because @'Iter' t@ (for a given input type @t@) is a monad\ntransformer (i.e., it is an instance of the 'MonadTrans' class).  In\nthis case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,\nbecause @head2File@ is returning a result in the @IO@ monad.  However,\n@lines2I@ would work equally well with any other monad.\n\nNext, notice the functioning of @'Iter' String m@ as a monad.  The\ntype of 'lineI' in the above example is @'Iter' String m String@.  The\n@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to\nbind the results to @line1@ and @line2@.  The monadic bind operator\nhides the details of IO chunk boundaries.  If, for instance, 'lineI'\nneeds more input because a newline character has not yet been read,\n'lineI' returns to the containing enumerator asking for more data.  If\nthe first 'lineI' receives more than a line of input, it simply passes\nthe residual input to the next invocation of 'lineI'.  Both of these\nactions are hidden by the syntax, making most code much easier to read\nand write.\n\nThat explains the iteratee type 'Iter'.  The enumerator type, 'Onum',\nhas the same three type arguments.  Thus, the type of 'enumFile', as\ninstantiated in the above examples, is @'enumFile' :: 'Onum' String IO\na@.  Most 'Onum' types are polymorphic in the last argument, so as to\nbe able to return whatever type the 'Iter' is returning.  (In fact,\n'enumFile' is polymorphic in the first two arguments, too, so as to\nwork with multiple @String@-like types and any monad in the\n@'MonadIO'@ class.)\n\nHere is an example of an 'Iter' with side effects:\n\n@\n    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()\n    liftIOexampleI = do\n      line <- 'lineI'\n      'liftIO' $ putStrLn $ \\\"First line is: \\\" ++ line\n      next <- 'takeI' 40\n      'liftIO' $ putStrLn $ \\\"And the next 40 bytes are: \\\" ++ next\n@\n\nUnlike @lines2I@, @liftIOexampleI@ does not return any interesting\nresult, but it uses the @'liftIO'@ monad transformer method to output\nthe first line of the file, followed by the next 40 bytes.  The\n'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the\nrequested number of characters or bytes, unless an EOF (end-of-file)\nis encountered.\n\nOf course, the real power of command pipelines is that you can hook\nmultiple commands together.  For instance, say you want to know how\nmany words in the system dictionary files contain a double k and start\nwith a lower-case letter.  You could run a command like this:\n\n>    cat /usr/share/dict/words /usr/share/dict/extra.words \\\n>        | grep kk | grep '^[a-z]' | wc -l\n\nLet's see how to do something equivalent with iteratees, starting with\nthe @wc -l@ command, which counts lines.  Here is an equivalent iteratee:\n\n@\n    lineCountI :: (Monad m) => 'Iter' String m Int\n    lineCountI = count 0\n        where count n = do\n                line <- 'safeLineI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nThe 'safeLineI' function is like 'lineI', but returns a @'Maybe'\n'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF\ncondition.  ('lineI' throws an exception on EOF.)\n\nWhat about the @grep@ command?  @grep@ sits in the middle of a\npipeline, so it acts both as a data sink and as a data source.\nThis is why we call such a pipeline stage an\n/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@\nequivalent, since multiple pipeline stages are going to be considering\nthe file one line at a time, let's first build an 'Inum' to separate\ninput into lines:\n\n@\n    import Data.ByteString as S\n    import Data.ByteString.Char8 as S8\n@\n\n@\n    -- | Break input into lines of type S.ByteString, as this type\n    -- works most conveniently with regular expressions.  (Otherwise,\n    -- we would prefer lazy ByteStrings.)\n    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a\n    inumToLines = 'mkInum' $ do\n                    line <- 'lineI'\n                    return [line]\n@\n\n'Inum' takes four type arguments, compared to only three for 'Onum'.\nThat's because an 'Inum' is acting as both an iteratee and an\nenumerator; it needn't be processing the same type of data in both\nroles.  In the above example, when acting as an iteratee,\n@inumToLines@ consumes data of type @S.ByteString@ (the first type\nargument), accepting one long stream of unstructured bytes.  However,\nas an enumerator, @inumToLines@ produces output of type\n@[S.ByteString]@ (the second type argument), a /list/ of strings, one\nper line of the file.  In general the type @'Inum' tIn tOut m a@ is an\niteratee-enumerator taking input type @tIn@, producing output type\n@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m\na@.\n\nIn fact, an 'Onum' is just a special kind of 'Inum' with the void\ninput type @()@.  The type @'Onum' t m a@ is just a synonym for\n@'Inum' () t m a@.  Most operations on 'Inum's can be used with\n'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not\ntrue, however.  For example, the '|$' operator requires an 'Onum', as\nit wouldn't know what data to feed to an arbitrary 'Inum'.  (If you\nneed it, however, there is a function @run@, hidden by this module but\nexported by \"Data.IterIO.Iter\", that executes an iteratee computation\nof arbitrary input type by feeding EOF as input.)\n\nIteratee-enumerators are generally constructed using either 'mkInum'\nor `mkInumM`, and by convention most 'Inum's have names starting\n\\\"@inum@...\\\", except that 'Onum' names start \\\"@enum@...\\\".  'mkInum'\ntakes an argument of type @'Iter' tIn m tOut@ that consumes input of\ntype @tIn@ to produce output of type @tOut@.  (For @inumToLines@,\n@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine\nfor simple stateless translation functions, but sometimes one would\nlike to keep state and use more complex logic in an 'Inum'.  For that,\nthe 'mkInumM' function creates an 'Inum' out of a computation in a\ndedicated 'InumM' monad.  See the \"Data.IterIO.Inum\" documentation for\nmore information on 'mkInumM'.  In @inumToLines@, we do not need to\nkeep state.  We are happy just to let 'lineI' throw an exception on\nEOF, which `mkInum` will catch and handle gracefully.\n\nThrowing an EOF exception--either implicitly by executing another\n'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to\nexit an 'Inum' created by 'mkInum'.  The other way is to return empty\ninput.\n\nWe similarly define an 'Inum' to filter out lines not matching a\nregular expression (using the \"Text.Regex.Posix.ByteString\" library),\nand a simple 'Inum' to count list elements (since @lineCountI ::\n'Iter' String m Int@ has input data type @String@, while after\n@inumToLines@ we need an 'Iter' with input data type\n@[S.ByteString]@).\n\n@\n    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a\n    inumGrep re = `mkInum` $ do\n      line <- 'headI'\n      if line =~ packedRe then return [line] else return []\n        where\n          packedRe = S8.pack re\n@\n\n@\n    lengthI :: (Monad m) => 'Iter' [t] m Int\n    lengthI = count 0\n        where count n = do\n                line <- 'safeHeadI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nNow we are almost ready to assemble all the pieces.  But recall that\nthe '|$' operator applies one 'Onum' to one 'Iter', yet now we have\ntwo 'Onum's (because we want to look through two files), and three\n'Inum's that we want to compose into a pipeline.  The library\nsupports two types of composition for pipeline stages:\n/concatenation/ and /fusing/.\n\nTwo 'Inum's (or 'Onum's) of the same type can be /concatenated/ with\nthe 'cat' function, producing a new data source that enumerates all of\nthe data in the first 'Inum' followed by all of the data in the\nsecond.\n\nThere are two /fusing/ operators.  The left-associative '|.' operator\nfuses two 'Inum's, provided the output type of the first is the input\ntype of the second.  (Mnemonic: it produces a pipeline stage that is\nopen on the right hand side, as it still needs to be applied to an\niteratee with '|$'.)  The right-associative '.|' operator fuses an\n'Inum' to an 'Iter', producing a new 'Iter'.\n\nThe fusing operators bind more tightly than the infix concatenation\nfunctions, which in turn bind more tightly than '|$'.  (Concatenation\noperators can also be used through prefix function application, which\nbinds most tightly.)  Hence, putting it all together, we produce the\nfollowing Haskell equivalent to the above Unix pipeline:\n\n@\n    grepCount :: IO Int\n    grepCount = 'enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines\n                    ``cat`` 'enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines\n                '|$' inumGrep \\\"kk\\\"\n                        '.|' inumGrep \\\"^[a-z]\\\"\n                        '.|' lengthI\n@\n\nOne often has a choice as to whether to fuse an 'Inum' to the\n'Onum', or to the 'Iter'.  For example, @grepCount@ could\nalternatively have been implemented as:\n\n@\n    grepCount' :: IO Int\n    grepCount' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines)\n                         ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines)\n                    '|.' inumGrep \\\"kk\\\"\n                    '|.' inumGrep \\\"^[a-z]\\\"\n                 '|$' lengthI\n@\n\nIn this case, the two are essentially equivalent.  However, for error\nhandling purposes, one should fuse together pipeline stages in which\nerrors have similar consequences.  Often an 'Inum' or 'Onum' failure\nis less serious than an 'Iter' failure.  For example, in the above\nexample, if 'enumFile' fails because one of the files does not exist,\nwe might want to continue processing lines from the next file.\nConversely, if @lengthI@ fails or one of the @inumGrep@ stages fails\n(most likely because the regular expression is illegal), there is not\nmuch point in continuing the program.  This is why the first example\nfused @inumGrep@ to @lengthI@, though this won't matter until we\nactually handle errors (see below).\n\nAnother alternative would have been to swap the order of concatenation\nand fusing:\n\n@\n    grepCount'' :: IO Int\n    grepCount'' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\")\n                           ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\")\n                      '|.' inumToLines\n                  '|$' inumGrep \\\"kk\\\"\n                      '.|' inumGrep \\\"^[a-z]\\\"\n                      '.|' lengthI\n@\n\nThis last version changes the semantics of the counting slightly.\nWith @grepCount''@, if the first file has an incomplete last line,\nthis line will be merged with the first line of the second file, which\nis probably not what you want.  (For instance, if the incomplete last\nline of the first file starts with a capital letter, then the first\nline of the second file will not be counted even if it starts with a\nlower-case letter and contains two \\\"k\\\"s.)\n\nOne limitation of all the @grepCount@ variants shown so far is that if\nthe first file does not exist, the whole operation aborts.  This\nmight or might not be reasonable when counting lines, but in other\ncontexts we may want to resume after failure.  Suppose we want to\nimplement a function like the Unix @grep@ command that searches for a\nstring in a bunch of files and prints all matching lines.  If opening\nor reading a file produces an error, the function should print the\nerror message and continue on with the next file.\n\nError handling is provided by the 'catchI' and 'inumCatch' functions,\nwhich are roughly equivalent to the standard library @'catch'@\nfunction.  There is also a 'throwI' function analogous to @'throwIO'@\nin the standard library.  Because @'catch'@ only works in the IO\nmonad, 'catchI' and 'inumCatch' work by propagating synchronous\nexceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors\ninto such synchronous exceptions.  Unfortunately, there is no way to\nhandle asynchronous exceptions such as those that arise in lazily\nevaluated pure code (e.g., divide by zero) or those thrown by another\nthread using @'throwTo'@.  Fortunately, for our @grep@ example, we\nonly need to catch IO errors.\n\nHere is the @grep@ code.  We will analyze it below.\n\n@\n    grep :: String -> [FilePath] -> IO ()\n    grep re files\n        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI\n        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI\n        where\n          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler\n          handler :: 'IOError'\n                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)\n                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)\n          handler e result = do\n            liftIO (hPutStrLn stderr $ show e)\n            'resumeI' result\n          linesOutI = do\n            mline <- 'safeHeadI'\n            case mline of\n              Just line -> do liftIO $ S.putStrLn line\n                              linesOutI\n              Nothing -> return ()\n@\n\nThere are two cases.  If the list of files to search is null, @grep@\nsimply reads from standard input, in which case there is only one\ninput stream and we do not care about resuming.  In the second case,\nwe use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'\nis generated by the function @enumLines@, which fuses 'enumFile' to\nour previously defined @inumToLines@, but also wraps the exception\nhandler function @handler@ around the enumerator using 'inumCatch'.\n\nNote that unlike @catch@, 'inumCatch' expects an exception handler to\nhave /two/ arguments.  The first argument, @e@ in this example, is the\nexception itself.  As with @catch@, the type of @e@ determines which\nexceptions are caught, which is why we must either specify an explicit\ntype signature for @handler@ or somewhere specify @e@'s type\nexplicitly, for instance with:\n\n>          ...\n>            liftIO (hPutStrLn stderr $ show (e :: IOError))\n>          ...\n\nNote that 'IOError' doesn't expose a type constructor, but for\nexception types that do, it often suffices to define the function with\nthe exception constructor, as:\n\n>          handler e@(SomeException _) result = do ...\n\nThe second argument to @handler@, @result@, is the failed state of the\niteratee, which contains more information than just the exception.  In\nthe case of an 'Inum' failure, it contains the state of the 'Iter'\nthat the 'Inum' was feeding when it failed.  The type of 'result' is\n'IterR'--which is the type returned by 'Iter's when they are fed\nchunks of data.  'IterR' takes the same three type arguments as\n'Iter'.  The function 'resumeI' extracts and returns an @'Iter'\n[S.ByteString] IO a@ from this failed result.  Thus, the next\nenumerator in a concatenated series can continue feeding it input.\nIf, instead of resuming, you want to re-throw the error, it suffices\nto re-execute the failed result with @'reRunIter'@.  For instance,\nsuppose we want to continue executing @grep@ when a named file does\nnot exist, but if some other error happens, we want to re-throw the\nexception to abort the whole program.  This could be achieved as\nfollows:\n\n>          handler e result = do\n>            if isDoesNotExistError e\n>              then do liftIO (hPutStrLn stderr $ show e)\n>                      resumeI result\n>              else reRunIter result\n\nBecause printing an exception is so common, there is a function\n'verboseResumeI' that prints exceptions before resuming (also\nprefixing the program name).  Thus, we can simplify the above function\nto:\n\n>          handler e result = if isDoesNotExistError e\n>                               then verboseResumeI result\n>                               else reRunIter result\n\nThese last two @handler@ functions also do away with the need for an\nexplicit type signature, because the function @'isDoesNotExistError'@\nhas argument type 'IOError', constraining the type of @e@ to the type\nof exceptions we want to catch.\n\n-}" Nothing),DP (2,1)),((AnnComment DComment (DP (-436,1),DP (1,3)) "{- $Tutorial\n\n #tutorial#\n\n\nThe iterIO library performs IO by hooking up sources of data, called\n/enumerators/, to data sinks, called /iteratees/, in a manner\nreminiscent of Unix command pipelines.  Compared to lazy IO, the\nenumerator/iteratee paradigm provides better error handing,\nreferential transparency (which should, after all, be one of the big\nadvantages of Haskell), and equally convenient composition of protocol\nlayers and parsers without worrying about IO chunk boundaries.\n\nEnumerators, implemented by the type 'Onum' (short for\n/outer enumerator/, for reasons that will become clear below), are so\ncalled because they enumerate all data elements (e.g., bytes or\npackets) in some source such as a file or socket.  Hence, an\nenumerator should be viewed as a /source/ outputting chunks of data\nwhose type is a @'Monoid'@.  (Actually, the input type must be of\nclass 'ChunkData', which is a @'Monoid'@ that additionally has a\nmethod @'null'@ to test whether a piece of data is equal to\n'mempty'.)\n\nIteratees, implemented by the type 'Iter', should be viewed as /sinks/\nconsuming data.  When executing IO, the library /iterates/ over all\ndata elements output by the source, using an iteratee to produce a\nresult.  The source may output data in chunks whose boundaries do not\ncoincide with logical message units; iteratees handle this\ntransparently, simplifying programming.\n\nHere is a simple example:\n\n@\n    -- Return the first line of a file\n    headFile :: FilePath -> IO String\n    headFile path = 'enumFile' path '|$' 'lineI'\n@\n\n'enumFile' enumerates the contents of a file.  'lineI' returns a line\nof input (discarding the newline).  '|$' is the /pipe apply/ operator\nthat applies an 'Onum' to an 'Iter', returning the result of the\n'Iter'--in this case the first line of the file named @path@.\n\nAn `Iter`'s main purpose may not be to produce a result.  Some 'Iter's\nare primarily useful for their side effects.  For example, 'stdoutI'\nwrites data to standard output; 'handleI' similarly writes output to\nan arbitrary file handle.  Thus, the following function copies the\ncontents of a file to standard output:\n\n@\n    -- Copy file to standard output\n    catFile :: FilePath -> IO ()\n    catFile path = 'enumFile'' path '|$' 'stdoutI'\n@\n\n'enumFile'' is like 'enumFile' above, but type restricted to data in\nthe lazy @'ByteString'@ format, which is more efficient than plain\n'String's.  ('enumFile' supports multiple types, but in this example\nthere is not enough information for Haskell to choose one of them, so\nwe must use 'enumFile'' or use @::@ to specify a type explicitly.)\nOnce again, '|$' is used to execute the IO actions, but, this time,\nthe return value is just @()@; the interesting action lies in the side\neffects of writing data to standard output while iterating over the\ninput with 'stdoutI'.\n\nThe real power of the iteratee abstraction lies in the fact that\n'Iter's are monadic computations.  One 'Iter' may invoke another to\nmake use of the first one's results.  Here is an example of a function\nthat returns the first two lines of a file:\n\n@\n    -- | Return first two lines of file\n    head2File :: FilePath -> IO (String, String)\n    head2File path = 'enumFile' path '|$' lines2I\n@\n\n@\n    -- | Iter that returns next two lines as a pair\n    lines2I :: (Monad m) => 'Iter' String m (String, String)\n    lines2I = do\n      line1 <- 'lineI'\n      line2 <- 'lineI'\n      return (line1, line2)\n@\n\nThis example illustrates several points.  First, consider the type of\nthe @lines2I@ function:  @'Iter' String m (String, String)@.  The\n'Iter' type constructor takes three type arguments.  The first,\n'String' in this case, specifies the type of input expected by the\niteratee.  The last type, @(String, String)@ in this case, specifies\nthe result type of the iteratee.  Finally, the middle type, @m@, is a\nmonad, because @'Iter' t@ (for a given input type @t@) is a monad\ntransformer (i.e., it is an instance of the 'MonadTrans' class).  In\nthis case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,\nbecause @head2File@ is returning a result in the @IO@ monad.  However,\n@lines2I@ would work equally well with any other monad.\n\nNext, notice the functioning of @'Iter' String m@ as a monad.  The\ntype of 'lineI' in the above example is @'Iter' String m String@.  The\n@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to\nbind the results to @line1@ and @line2@.  The monadic bind operator\nhides the details of IO chunk boundaries.  If, for instance, 'lineI'\nneeds more input because a newline character has not yet been read,\n'lineI' returns to the containing enumerator asking for more data.  If\nthe first 'lineI' receives more than a line of input, it simply passes\nthe residual input to the next invocation of 'lineI'.  Both of these\nactions are hidden by the syntax, making most code much easier to read\nand write.\n\nThat explains the iteratee type 'Iter'.  The enumerator type, 'Onum',\nhas the same three type arguments.  Thus, the type of 'enumFile', as\ninstantiated in the above examples, is @'enumFile' :: 'Onum' String IO\na@.  Most 'Onum' types are polymorphic in the last argument, so as to\nbe able to return whatever type the 'Iter' is returning.  (In fact,\n'enumFile' is polymorphic in the first two arguments, too, so as to\nwork with multiple @String@-like types and any monad in the\n@'MonadIO'@ class.)\n\nHere is an example of an 'Iter' with side effects:\n\n@\n    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()\n    liftIOexampleI = do\n      line <- 'lineI'\n      'liftIO' $ putStrLn $ \\\"First line is: \\\" ++ line\n      next <- 'takeI' 40\n      'liftIO' $ putStrLn $ \\\"And the next 40 bytes are: \\\" ++ next\n@\n\nUnlike @lines2I@, @liftIOexampleI@ does not return any interesting\nresult, but it uses the @'liftIO'@ monad transformer method to output\nthe first line of the file, followed by the next 40 bytes.  The\n'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the\nrequested number of characters or bytes, unless an EOF (end-of-file)\nis encountered.\n\nOf course, the real power of command pipelines is that you can hook\nmultiple commands together.  For instance, say you want to know how\nmany words in the system dictionary files contain a double k and start\nwith a lower-case letter.  You could run a command like this:\n\n>    cat /usr/share/dict/words /usr/share/dict/extra.words >        | grep kk | grep '^[a-z]' | wc -l\n\n\nLet's see how to do something equivalent with iteratees, starting with\nthe @wc -l@ command, which counts lines.  Here is an equivalent iteratee:\n\n@\n    lineCountI :: (Monad m) => 'Iter' String m Int\n    lineCountI = count 0\n        where count n = do\n                line <- 'safeLineI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nThe 'safeLineI' function is like 'lineI', but returns a @'Maybe'\n'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF\ncondition.  ('lineI' throws an exception on EOF.)\n\nWhat about the @grep@ command?  @grep@ sits in the middle of a\npipeline, so it acts both as a data sink and as a data source.\nThis is why we call such a pipeline stage an\n/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@\nequivalent, since multiple pipeline stages are going to be considering\nthe file one line at a time, let's first build an 'Inum' to separate\ninput into lines:\n\n@\n    import Data.ByteString as S\n    import Data.ByteString.Char8 as S8\n@\n\n@\n    -- | Break input into lines of type S.ByteString, as this type\n    -- works most conveniently with regular expressions.  (Otherwise,\n    -- we would prefer lazy ByteStrings.)\n    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a\n    inumToLines = 'mkInum' $ do\n                    line <- 'lineI'\n                    return [line]\n@\n\n'Inum' takes four type arguments, compared to only three for 'Onum'.\nThat's because an 'Inum' is acting as both an iteratee and an\nenumerator; it needn't be processing the same type of data in both\nroles.  In the above example, when acting as an iteratee,\n@inumToLines@ consumes data of type @S.ByteString@ (the first type\nargument), accepting one long stream of unstructured bytes.  However,\nas an enumerator, @inumToLines@ produces output of type\n@[S.ByteString]@ (the second type argument), a /list/ of strings, one\nper line of the file.  In general the type @'Inum' tIn tOut m a@ is an\niteratee-enumerator taking input type @tIn@, producing output type\n@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m\na@.\n\nIn fact, an 'Onum' is just a special kind of 'Inum' with the void\ninput type @()@.  The type @'Onum' t m a@ is just a synonym for\n@'Inum' () t m a@.  Most operations on 'Inum's can be used with\n'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not\ntrue, however.  For example, the '|$' operator requires an 'Onum', as\nit wouldn't know what data to feed to an arbitrary 'Inum'.  (If you\nneed it, however, there is a function @run@, hidden by this module but\nexported by \"Data.IterIO.Iter\", that executes an iteratee computation\nof arbitrary input type by feeding EOF as input.)\n\nIteratee-enumerators are generally constructed using either 'mkInum'\nor `mkInumM`, and by convention most 'Inum's have names starting\n\\\"@inum@...\\\", except that 'Onum' names start \\\"@enum@...\\\".  'mkInum'\ntakes an argument of type @'Iter' tIn m tOut@ that consumes input of\ntype @tIn@ to produce output of type @tOut@.  (For @inumToLines@,\n@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine\nfor simple stateless translation functions, but sometimes one would\nlike to keep state and use more complex logic in an 'Inum'.  For that,\nthe 'mkInumM' function creates an 'Inum' out of a computation in a\ndedicated 'InumM' monad.  See the \"Data.IterIO.Inum\" documentation for\nmore information on 'mkInumM'.  In @inumToLines@, we do not need to\nkeep state.  We are happy just to let 'lineI' throw an exception on\nEOF, which `mkInum` will catch and handle gracefully.\n\nThrowing an EOF exception--either implicitly by executing another\n'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to\nexit an 'Inum' created by 'mkInum'.  The other way is to return empty\ninput.\n\nWe similarly define an 'Inum' to filter out lines not matching a\nregular expression (using the \"Text.Regex.Posix.ByteString\" library),\nand a simple 'Inum' to count list elements (since @lineCountI ::\n'Iter' String m Int@ has input data type @String@, while after\n@inumToLines@ we need an 'Iter' with input data type\n@[S.ByteString]@).\n\n@\n    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a\n    inumGrep re = `mkInum` $ do\n      line <- 'headI'\n      if line =~ packedRe then return [line] else return []\n        where\n          packedRe = S8.pack re\n@\n\n@\n    lengthI :: (Monad m) => 'Iter' [t] m Int\n    lengthI = count 0\n        where count n = do\n                line <- 'safeHeadI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nNow we are almost ready to assemble all the pieces.  But recall that\nthe '|$' operator applies one 'Onum' to one 'Iter', yet now we have\ntwo 'Onum's (because we want to look through two files), and three\n'Inum's that we want to compose into a pipeline.  The library\nsupports two types of composition for pipeline stages:\n/concatenation/ and /fusing/.\n\nTwo 'Inum's (or 'Onum's) of the same type can be /concatenated/ with\nthe 'cat' function, producing a new data source that enumerates all of\nthe data in the first 'Inum' followed by all of the data in the\nsecond.\n\nThere are two /fusing/ operators.  The left-associative '|.' operator\nfuses two 'Inum's, provided the output type of the first is the input\ntype of the second.  (Mnemonic: it produces a pipeline stage that is\nopen on the right hand side, as it still needs to be applied to an\niteratee with '|$'.)  The right-associative '.|' operator fuses an\n'Inum' to an 'Iter', producing a new 'Iter'.\n\nThe fusing operators bind more tightly than the infix concatenation\nfunctions, which in turn bind more tightly than '|$'.  (Concatenation\noperators can also be used through prefix function application, which\nbinds most tightly.)  Hence, putting it all together, we produce the\nfollowing Haskell equivalent to the above Unix pipeline:\n\n@\n    grepCount :: IO Int\n    grepCount = 'enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines\n                    ``cat`` 'enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines\n                '|$' inumGrep \\\"kk\\\"\n                        '.|' inumGrep \\\"^[a-z]\\\"\n                        '.|' lengthI\n@\n\nOne often has a choice as to whether to fuse an 'Inum' to the\n'Onum', or to the 'Iter'.  For example, @grepCount@ could\nalternatively have been implemented as:\n\n@\n    grepCount' :: IO Int\n    grepCount' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines)\n                         ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines)\n                    '|.' inumGrep \\\"kk\\\"\n                    '|.' inumGrep \\\"^[a-z]\\\"\n                 '|$' lengthI\n@\n\nIn this case, the two are essentially equivalent.  However, for error\nhandling purposes, one should fuse together pipeline stages in which\nerrors have similar consequences.  Often an 'Inum' or 'Onum' failure\nis less serious than an 'Iter' failure.  For example, in the above\nexample, if 'enumFile' fails because one of the files does not exist,\nwe might want to continue processing lines from the next file.\nConversely, if @lengthI@ fails or one of the @inumGrep@ stages fails\n(most likely because the regular expression is illegal), there is not\nmuch point in continuing the program.  This is why the first example\nfused @inumGrep@ to @lengthI@, though this won't matter until we\nactually handle errors (see below).\n\nAnother alternative would have been to swap the order of concatenation\nand fusing:\n\n@\n    grepCount'' :: IO Int\n    grepCount'' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\")\n                           ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\")\n                      '|.' inumToLines\n                  '|$' inumGrep \\\"kk\\\"\n                      '.|' inumGrep \\\"^[a-z]\\\"\n                      '.|' lengthI\n@\n\nThis last version changes the semantics of the counting slightly.\nWith @grepCount''@, if the first file has an incomplete last line,\nthis line will be merged with the first line of the second file, which\nis probably not what you want.  (For instance, if the incomplete last\nline of the first file starts with a capital letter, then the first\nline of the second file will not be counted even if it starts with a\nlower-case letter and contains two \\\"k\\\"s.)\n\nOne limitation of all the @grepCount@ variants shown so far is that if\nthe first file does not exist, the whole operation aborts.  This\nmight or might not be reasonable when counting lines, but in other\ncontexts we may want to resume after failure.  Suppose we want to\nimplement a function like the Unix @grep@ command that searches for a\nstring in a bunch of files and prints all matching lines.  If opening\nor reading a file produces an error, the function should print the\nerror message and continue on with the next file.\n\nError handling is provided by the 'catchI' and 'inumCatch' functions,\nwhich are roughly equivalent to the standard library @'catch'@\nfunction.  There is also a 'throwI' function analogous to @'throwIO'@\nin the standard library.  Because @'catch'@ only works in the IO\nmonad, 'catchI' and 'inumCatch' work by propagating synchronous\nexceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors\ninto such synchronous exceptions.  Unfortunately, there is no way to\nhandle asynchronous exceptions such as those that arise in lazily\nevaluated pure code (e.g., divide by zero) or those thrown by another\nthread using @'throwTo'@.  Fortunately, for our @grep@ example, we\nonly need to catch IO errors.\n\nHere is the @grep@ code.  We will analyze it below.\n\n@\n    grep :: String -> [FilePath] -> IO ()\n    grep re files\n        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI\n        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI\n        where\n          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler\n          handler :: 'IOError'\n                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)\n                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)\n          handler e result = do\n            liftIO (hPutStrLn stderr $ show e)\n            'resumeI' result\n          linesOutI = do\n            mline <- 'safeHeadI'\n            case mline of\n              Just line -> do liftIO $ S.putStrLn line\n                              linesOutI\n              Nothing -> return ()\n@\n\nThere are two cases.  If the list of files to search is null, @grep@\nsimply reads from standard input, in which case there is only one\ninput stream and we do not care about resuming.  In the second case,\nwe use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'\nis generated by the function @enumLines@, which fuses 'enumFile' to\nour previously defined @inumToLines@, but also wraps the exception\nhandler function @handler@ around the enumerator using 'inumCatch'.\n\nNote that unlike @catch@, 'inumCatch' expects an exception handler to\nhave /two/ arguments.  The first argument, @e@ in this example, is the\nexception itself.  As with @catch@, the type of @e@ determines which\nexceptions are caught, which is why we must either specify an explicit\ntype signature for @handler@ or somewhere specify @e@'s type\nexplicitly, for instance with:\n\n>          ...\n>            liftIO (hPutStrLn stderr $ show (e :: IOError))\n>          ...\n\nNote that 'IOError' doesn't expose a type constructor, but for\nexception types that do, it often suffices to define the function with\nthe exception constructor, as:\n\n>          handler e@(SomeException _) result = do ...\n\nThe second argument to @handler@, @result@, is the failed state of the\niteratee, which contains more information than just the exception.  In\nthe case of an 'Inum' failure, it contains the state of the 'Iter'\nthat the 'Inum' was feeding when it failed.  The type of 'result' is\n'IterR'--which is the type returned by 'Iter's when they are fed\nchunks of data.  'IterR' takes the same three type arguments as\n'Iter'.  The function 'resumeI' extracts and returns an @'Iter'\n[S.ByteString] IO a@ from this failed result.  Thus, the next\nenumerator in a concatenated series can continue feeding it input.\nIf, instead of resuming, you want to re-throw the error, it suffices\nto re-execute the failed result with @'reRunIter'@.  For instance,\nsuppose we want to continue executing @grep@ when a named file does\nnot exist, but if some other error happens, we want to re-throw the\nexception to abort the whole program.  This could be achieved as\nfollows:\n\n>          handler e result = do\n>            if isDoesNotExistError e\n>              then do liftIO (hPutStrLn stderr $ show e)\n>                      resumeI result\n>              else reRunIter result\n\nBecause printing an exception is so common, there is a function\n'verboseResumeI' that prints exceptions before resuming (also\nprefixing the program name).  Thus, we can simplify the above function\nto:\n\n>          handler e result = if isDoesNotExistError e\n>                               then verboseResumeI result\n>                               else reRunIter result\n\nThese last two @handler@ functions also do away with the need for an\nexplicit type signature, because the function @'isDoesNotExistError'@\nhas argument type 'IOError', constraining the type of @e@ to the type\nof exceptions we want to catch.\n\n-}" Nothing),DP (-436,1)),((AnnComment DComment (DP (1,1),DP (326,3)) "{- $Differences\n\nThe Iteratee approach was originally advocated by Oleg Kiselyov (see\ntalk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The\nmain implementation by Kiselyov and John Lato is simply called\n/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another\nrealization of the iteratee concepts is the /enumerator/ package\n(<http://hackage.haskell.org/package/enumerator>).  IterIO is a\nre-implementation of these concepts from scratch.  This section\ndiscusses the differences between previous packages and iterIO, both\nas a means for motivating iterIO's design and as a set of suggestions\nfor improving other iteratee implementations.\n\n* /Base abstraction/\n\nThe iterIO package represents an iteratee as a pure function from a\nchunk of pending input data to an iteratee result of type 'IterR':\n\n@\n  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }\n@\n\nAn 'IterR' can yield a result and residual input, or it can ask for\nmore input, or it can request to have an action executed in the\nunderlying monad, or it can signal failure.  The fact that all\niteratees are functions of input ensures that iteratees generally see\n/all/ pending input.  Thus, iteratees can do things like measure the\nlength of buffered input to subtract it from the current file offset\nand determine the effective position in a file.\n\n`IterR`'s division of iteratee results into different outcomes such as\nneeding input or needing monadic actions allows the library to\ndistinguish between pure iteratees and those with potential side\neffects.  The ability to know that a specific iteratee is a pure\nfunction in many cases allows one to parse LL(*) grammars without\nlarge amounts of input buffering for backtracking (see below).\n\nIn contrast, the iteratee package uses continuation passing style\n(CPS), in which an iteratee is a function taking two continuation\nfunctions--one to call when done, and a second to call when either\nrequesting more input or failing:\n\n> -- From the iteratee package:\n> newtype Iteratee s m a = Iteratee{ runIter :: forall r.\n>        -- First the \"onDone\" function:\n>           (a -> Stream s -> m r) ->\n>        -- Next the \"onCont\" function:\n>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->\n>           m r}\n\nCPS has the advantage of exposing the bind operator of the underlying\nmonad, making 'lift' cheap and simple.  Moreover, splitting into two\ncontinuations saves the first and most common one (i.e., \\\"onDone\\\")\nfrom the overhead of checking whether an error condition or request\nfor more input has occurred.  See\n<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>\nfor a good discussion of the advantages of CPS.\n\nBecause of CPS, iteratee should be capable of delivering the best\nperformance of the three iteratee packages.  A disadvantage of\niterIO's approach is that every invocation of 'lift' must be\npropagated all the way up the call chain, where a small amount of\noverhead is added for each enclosing 'catchI' or similar call.  While\niterIO can handle most successful 'IterR' outcomes and caught\nexceptions locally without popping back up the call stack, there is\nalso potentially overhead from actually checking that the outcome was\nsuccessful at each bind site.  (GHC's inliner may be able to avoid the\ncheck in some cases.)\n\nHowever, iteratee lacks several features of iterIO; offering these\nfeatures would likely reduce the benefits of CPS and complicate code.\nFor instance, there is no way to execute a pure iteratee without\nmonadic actions (the benefit touted above and described below for\nLL(*) parsing).  Moreover, iteratee's exception mechanism discards the\ncurrent location in the input stream, making it unsuitable for failed\nparse alternatives.  IterIO provides a general control mechanism to\nmake arbitrary requests from enumerators (such as seek, tell,\ngetpeername, get SSL information, etc.); iteratee instead overloads\nthe exception mechanism for control purposes, which prevents control\noperations from returning values.  Thus, while iteratee can implement\nseek, it cannot, for instance, implement tell.\n\nThe enumerator package's approach is closer to iterIO's, but makes\nevery iteratee into a monadic action in the underlying monad @m@:\n\n> -- From the enumerator package:\n> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }\n\nHere @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper\ndisallows iterIO's LL(*) parsing tricks.  It also causes gratuitous\ninvocation of @m@'s bind function, which can be expensive when using\nstacks of monad transformers.  Furthermore, enumerator discards the\ninput state on all errors, making it impossible to resume from\nfailures that leave the input in a known state (such as a parsing\nlookahead failure).\n\n* /Uniformity of abstraction/\n\nIterIO's abstractions were refined over many iterations to become\nminimal yet highly expressive and familiar to Unix shell users.  Thus,\nwe have 'Iter's, which are data sinks that consume input and produce a\nresult.  Then we have 'Inum's, which are also 'Iter's.  These two data\ntypes and can combined through pipes (i.e., fusing) and concatenation,\nboth of which have direct analogues in the Unix @|@ (pipe) operator\nand @cat@ command.\n\nBasing everything around these few concepts makes the library easier\nto learn and use.  For instance, because all 'Inum's are 'Iter's,\nthere is only one set of 'Iter' building blocks to learn.  'Inum'\nimplementations invoke the same 'Iter's that are used to build other\n'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling\nmechanism.  Finally, because 'Onum's are also 'Inum's, one set of\nfusing and concatenation operators works for both.\n\nBy contrast, both the iteratee and enumerator packages use enumerator\ntypes that are not iteratees.  Hence, constructing enumerators is\nharder and requires a different error handing mechanism.  The packages\nmust introduce a third, hybrid \\\"Enumeratee\\\" type for inner pipeline\nstages, and fusing Enumerators to Enumeratees is a different function\nfrom fusing Enumeratees together.\n\nFunneling everything through a small number of abstractions also\nensures that the right thing happens in corner cases.  In particular,\nall enumerator application happens through the pipe operator.  Though\nthere are two pipe operators, a left associative one and a right\nassociative one, they internally use the same function:  @a '|.' b =\n(a '.|') . b@.  Similarly, the pipe application operators ('|$' and\n'.|$') are defined in terms of '.|'.\n\n'.|' guarantees that its right-hand argument will receive an EOF when\nthe left hand argument terminates (whether normally or through an\nexception).  This is crucial for managing resources such file\ndescriptors, and works no matter how convoluted the control structure\nof your program.\n\nConsider the following realistic scenario of a web server constructed\nas an 'Inum' that translates from HTTP requests to HTTP responses.\n(Such an 'Inum' is provided by the function 'inumHttpServer' in\n\"Data.IterIO.HTTP\".)  The server's accept loop would resemble the\nfollowing:\n\n@\n   loop = do\n     (sock, _) <- Net.accept $ listen_socket\n     _ <- forkIO $ do\n            (iter, enum) <- 'iterStream' (sock)\n            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter\n     loop\n@\n\nThis code depends on the fact that 'iterStream' closes @sock@ after\nboth the @iter@ has received an EOF and the @enum@ has returned.  One\nlevel down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',\nand has code looking something like this:\n\n@\n     req <- 'httpReqI'                              -- parse HTTP request\n     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler\n     'irun' $ enumHttpResp resp Nothing             -- send response to client\n@\n\nThe @handler@ gets run on the body of the message, and might decide to\nprocess an HTTP POST request by saving an uploaded file to disk, for\ninstance with code like this:\n\n@\n     let saveFile _ field\n           | ffName field == S8.pack \\\"file\\\" = do\n                            h <- liftIO $ openBinaryFile \\\"upload\\\" WriteMode\n                            'handleI' h ``finallyI`` liftIO (hClose h)\n           | otherwise = return ()\n     in foldForm req saveFile ()\n@\n\n@foldForm@ internally is invoking an 'Inum' that parses HTTP\nmultipart/form-data to pipe each field of the form to the @saveFile@\nfunction.\n\nNow suppose 'inumHttpBody' fails (most likely because it receives an\nEOF before reading the number of bytes specified in the Content-Length\nheader).  Because 'inumHttpBody' is fused to @handler@, the failure\nwill cause @handler@ to receive an EOF, which will cause @foldForm@ to\nfail, which will cause 'handleI' to receive an EOF and return, which\nwill ensure 'hClose' runs and the file handle @h@ is not leaked.\n\nOnce the EOFs have been processed, the exception will propagate\nupwards making 'inumHttpServer' fail, which in turn will send an EOF\nto @iter@.  Then the exception will cause @enum@ to fail, after which\n@sock@ will be closed.  In summary, despite the complex structure of\nthe web server, because all the components are fused together with\npipe operators, corner cases like this just work with no need to worry\nabout leaked file descriptors.\n\n* /Uniform error-handling and simplified monad transformers/\n\nThe iterIO library provides a traditional throw and catch exception\nmechanism using its own functions 'throwI' and 'catchI', but keeping\nthe standard library exception hierarchy from \"Control.Exception\".\nAll of the support routines are carefully crafted to ensure that this\nsingle exception mechanism is the only one you ever need, so that you\ndon't end up having to integrate different components with different\nerror strategies, a situation summarized amusingly in the following\nblog post:\n<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.\n\nA key to uniform error handling is ensuring that errors can be\npropagated cleanly across different monads and transformers.  Thus,\nfor instance, the iterIO 'liftIO' function translates all uncaught IO\nerrors into 'Iter' errors.\n\nMore importantly, iterIO is designed to support the standard mtl monad\ntransformers while keeping 'Iter' as the outermost monadic type.  For\ninstance, if deep in the middle of some @'Iter' t 'IO'@ computation\nyou need a state transformer monad, you can invoke one with\n'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen\nby comparing their effective types, 'runStateTI' keeps the 'Iter'\nmonad on the outside, and thus can cleanly propagate failures out of\nthe 'StateT' subcomputation:\n\n> runStateT  :: StateT s m a -> s -> m (a, s)\n>\n> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)\n\nSimilarly, there is a function @'liftI' :: (MonadTrans t) => Iter\ns m a -> Iter s (t m) a@ that can be used to execute a computation in\nwhich a level of monad transformer is stripped off the inner monadic\ntype.\n\nAn equally important feature is the ability to distinguish 'Iter'\nfailures from 'Inum' failures, given that the former are often more\nserious than the latter.  As shown by the @grep@ example in the\ntutorial above, when one in a series of concatenated 'Inum's fails,\nyou often want to keep going without losing the state of the 'Iter'.\nThe enumerator package does not appear to support this distinction.\nThe iteratee package might, but it is not clear how to implement the\niteratee equivalent of the @grep@ example above.\n\nBy contrast, iterIO's 'Inum' mechanism was designed to be intuitive.\nIf you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then\nyou will catch exactly the errors thrown by those 'Inum's, not those\nthrown by pipeline stages outside the scope of the 'inumCatch' call.\n\nIt is because of this unified error handling mechanism that examples\nsuch as the HTTP server above can be guaranteed not to leak resources.\n\n* /Parser combinators for LL(*) grammars/\n\nIterIO's \"Data.IterIO.Parse\" module supports parsing of iteratee input\nusing combinators similar to those found in parsec.  However, parsec\nsupports only LL(1) grammars, and can lead to confusing failures--for\ninstance the parser @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ would fail\non input @\\\"for\\\"@.  IterIO, by contrast, supports full LL(*) parsing,\nmeaning a parser can look arbitrarily far ahead before failing.\n\nLL(*) parsers are generally disfavored because of their potential to\nconsume arbitrarily large amounts of memory to remember input for\nbacktracking.  However, iterIO offers two mechanisms that mitigate the\nproblem.\n\nFirst, because 'Iter's are constructed in such a way as to\ndifferentiate requests for more input from execution of monadic\nactions, it is possible to run multiple parsers in parallel.  Consider\na hypothetical parser such as the following, designed to recognize the\ninput format and parse either XML or JSON data:\n\n@\n  parser :: 'Iter' 'L.ByteString' m Value\n  parser = ('string' \\\"\\<!DOCTYPE\\\" >> parseXml)\n           \\<|\\> ('char' \\'{\\' >> parseJson)\n@\n\n@\\<|\\>@ is an infix synonym for the iterIO function 'multiParse',\nwhich attempts to run two parsers concurrently on input as it arrives.\nBecause 'string' and 'char' are both pure parser combinators with no\nmonadic side effects, it is possible to run them both concurrently\nwithout fear that the second rule--if it fails--will nonetheless have\nproduced side effects.  In fact, at least one of the 'string' or the\n'char' action will fail almost immediately, likely on the first chunk\nof data.  After one of the two has signaled a parse error, there is no\nlonger any need to store input for backtracking.  Note this works even\nif the subsequent functions @parseXml@ and @parseJson@ have monadic\nside effects, because 'multiParse' doesn't need to invoke those\nmonadic actions to determine that one of the two parsers has failed.\n\nA second way to avoid large amounts of storage for backtracking is to\nuse iterIO's '\\/' operator, which is an infix synonym for 'ifNoParse'.\nThe formulation @iter '\\/' no $ yes@ splits a parser into three\ncomponents.  @iter@ is executed with backtracking enabled.  If it\nsucceeds, then the saved data is discarded, @iter@'s result is fed to\nthe function @yes@, and any further failures will not cause input to\nbe rewound.  If, on the other hand, @iter@ fails, then input is\nrewound and @no@ is executed.  The '\\/' operator is very convenient\nfor long folds whose individual elements do not consume a lot of\ninput.  For example, to parse and sum a list of numbers (given a\nparser @number@ that skips spaces then parses one number), you might\ndo something like this:\n\n> parseAndSumIntegerList :: Iter String IO Int\n> parseAndSumIntegerList = loop 0\n>     where loop n = number \\/ return n $ \\n' -> loop (n + n')\n\nRegardless of the length of the list of numbers being parsed,\n@sumNumbers@ only ever needs to backtrack over the input consumed by a\nsingle iteration of @number@, which is likely a small amount of extra\nmemory to keep around.\n\nIf you do want an LL(1) parser combinator library, iterIO supports\nseamless integration with the attoparsec package.  The function 'atto'\nin \"Data.IterIO.Atto\" turns an attoparsec @Parser@ into an 'Iter'\nmonad, treating an attoparsec failure as an 'Iter' exception that can\nbe handled in the usual way with 'ifParse' or 'multiParse', or just\ncaught with 'catchI'.  (Attoparsec has the additional advantage of\nsolving the annoying @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ issue by\nspecial-casing @string@ to have more lookahead.)\n\nPreliminary testing suggests that attoparsec can be about three times\nfaster than \"Data.IterIO.Parse\" on parse-intensive workloads.  The\nlimitation is that attoparsec parsers must be pure.  A good compromise\nmay be to use IterIO for coarse-grained parsing, and attoparsec for\nmore complex data structures.  For example, you might want to use\niterIO's parsing of HTTP multipart/form-data (so as to be able to pipe\nfiles to disk in constant space), but for fields with JSON data, use\n'atto' to pipe the contents to the excellent attoparsec-based aeson\npackage.\n\n-}" Nothing),DP (1,1)),((AnnComment DComment (DP (-324,1),DP (1,3)) "{- $Differences\n\nThe Iteratee approach was originally advocated by Oleg Kiselyov (see\ntalk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The\nmain implementation by Kiselyov and John Lato is simply called\n/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another\nrealization of the iteratee concepts is the /enumerator/ package\n(<http://hackage.haskell.org/package/enumerator>).  IterIO is a\nre-implementation of these concepts from scratch.  This section\ndiscusses the differences between previous packages and iterIO, both\nas a means for motivating iterIO's design and as a set of suggestions\nfor improving other iteratee implementations.\n\n* /Base abstraction/\n\nThe iterIO package represents an iteratee as a pure function from a\nchunk of pending input data to an iteratee result of type 'IterR':\n\n@\n  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }\n@\n\nAn 'IterR' can yield a result and residual input, or it can ask for\nmore input, or it can request to have an action executed in the\nunderlying monad, or it can signal failure.  The fact that all\niteratees are functions of input ensures that iteratees generally see\n/all/ pending input.  Thus, iteratees can do things like measure the\nlength of buffered input to subtract it from the current file offset\nand determine the effective position in a file.\n\n`IterR`'s division of iteratee results into different outcomes such as\nneeding input or needing monadic actions allows the library to\ndistinguish between pure iteratees and those with potential side\neffects.  The ability to know that a specific iteratee is a pure\nfunction in many cases allows one to parse LL(*) grammars without\nlarge amounts of input buffering for backtracking (see below).\n\nIn contrast, the iteratee package uses continuation passing style\n(CPS), in which an iteratee is a function taking two continuation\nfunctions--one to call when done, and a second to call when either\nrequesting more input or failing:\n\n> -- From the iteratee package:\n> newtype Iteratee s m a = Iteratee{ runIter :: forall r.\n>        -- First the \"onDone\" function:\n>           (a -> Stream s -> m r) ->\n>        -- Next the \"onCont\" function:\n>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->\n>           m r}\n\nCPS has the advantage of exposing the bind operator of the underlying\nmonad, making 'lift' cheap and simple.  Moreover, splitting into two\ncontinuations saves the first and most common one (i.e., \\\"onDone\\\")\nfrom the overhead of checking whether an error condition or request\nfor more input has occurred.  See\n<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>\nfor a good discussion of the advantages of CPS.\n\nBecause of CPS, iteratee should be capable of delivering the best\nperformance of the three iteratee packages.  A disadvantage of\niterIO's approach is that every invocation of 'lift' must be\npropagated all the way up the call chain, where a small amount of\noverhead is added for each enclosing 'catchI' or similar call.  While\niterIO can handle most successful 'IterR' outcomes and caught\nexceptions locally without popping back up the call stack, there is\nalso potentially overhead from actually checking that the outcome was\nsuccessful at each bind site.  (GHC's inliner may be able to avoid the\ncheck in some cases.)\n\nHowever, iteratee lacks several features of iterIO; offering these\nfeatures would likely reduce the benefits of CPS and complicate code.\nFor instance, there is no way to execute a pure iteratee without\nmonadic actions (the benefit touted above and described below for\nLL(*) parsing).  Moreover, iteratee's exception mechanism discards the\ncurrent location in the input stream, making it unsuitable for failed\nparse alternatives.  IterIO provides a general control mechanism to\nmake arbitrary requests from enumerators (such as seek, tell,\ngetpeername, get SSL information, etc.); iteratee instead overloads\nthe exception mechanism for control purposes, which prevents control\noperations from returning values.  Thus, while iteratee can implement\nseek, it cannot, for instance, implement tell.\n\nThe enumerator package's approach is closer to iterIO's, but makes\nevery iteratee into a monadic action in the underlying monad @m@:\n\n> -- From the enumerator package:\n> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }\n\nHere @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper\ndisallows iterIO's LL(*) parsing tricks.  It also causes gratuitous\ninvocation of @m@'s bind function, which can be expensive when using\nstacks of monad transformers.  Furthermore, enumerator discards the\ninput state on all errors, making it impossible to resume from\nfailures that leave the input in a known state (such as a parsing\nlookahead failure).\n\n* /Uniformity of abstraction/\n\nIterIO's abstractions were refined over many iterations to become\nminimal yet highly expressive and familiar to Unix shell users.  Thus,\nwe have 'Iter's, which are data sinks that consume input and produce a\nresult.  Then we have 'Inum's, which are also 'Iter's.  These two data\ntypes and can combined through pipes (i.e., fusing) and concatenation,\nboth of which have direct analogues in the Unix @|@ (pipe) operator\nand @cat@ command.\n\nBasing everything around these few concepts makes the library easier\nto learn and use.  For instance, because all 'Inum's are 'Iter's,\nthere is only one set of 'Iter' building blocks to learn.  'Inum'\nimplementations invoke the same 'Iter's that are used to build other\n'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling\nmechanism.  Finally, because 'Onum's are also 'Inum's, one set of\nfusing and concatenation operators works for both.\n\nBy contrast, both the iteratee and enumerator packages use enumerator\ntypes that are not iteratees.  Hence, constructing enumerators is\nharder and requires a different error handing mechanism.  The packages\nmust introduce a third, hybrid \\\"Enumeratee\\\" type for inner pipeline\nstages, and fusing Enumerators to Enumeratees is a different function\nfrom fusing Enumeratees together.\n\nFunneling everything through a small number of abstractions also\nensures that the right thing happens in corner cases.  In particular,\nall enumerator application happens through the pipe operator.  Though\nthere are two pipe operators, a left associative one and a right\nassociative one, they internally use the same function:  @a '|.' b =\n(a '.|') . b@.  Similarly, the pipe application operators ('|$' and\n'.|$') are defined in terms of '.|'.\n\n'.|' guarantees that its right-hand argument will receive an EOF when\nthe left hand argument terminates (whether normally or through an\nexception).  This is crucial for managing resources such file\ndescriptors, and works no matter how convoluted the control structure\nof your program.\n\nConsider the following realistic scenario of a web server constructed\nas an 'Inum' that translates from HTTP requests to HTTP responses.\n(Such an 'Inum' is provided by the function 'inumHttpServer' in\n\"Data.IterIO.HTTP\".)  The server's accept loop would resemble the\nfollowing:\n\n@\n   loop = do\n     (sock, _) <- Net.accept $ listen_socket\n     _ <- forkIO $ do\n            (iter, enum) <- 'iterStream' (sock)\n            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter\n     loop\n@\n\nThis code depends on the fact that 'iterStream' closes @sock@ after\nboth the @iter@ has received an EOF and the @enum@ has returned.  One\nlevel down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',\nand has code looking something like this:\n\n@\n     req <- 'httpReqI'                              -- parse HTTP request\n     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler\n     'irun' $ enumHttpResp resp Nothing             -- send response to client\n@\n\nThe @handler@ gets run on the body of the message, and might decide to\nprocess an HTTP POST request by saving an uploaded file to disk, for\ninstance with code like this:\n\n@\n     let saveFile _ field\n           | ffName field == S8.pack \\\"file\\\" = do\n                            h <- liftIO $ openBinaryFile \\\"upload\\\" WriteMode\n                            'handleI' h ``finallyI`` liftIO (hClose h)\n           | otherwise = return ()\n     in foldForm req saveFile ()\n@\n\n@foldForm@ internally is invoking an 'Inum' that parses HTTP\nmultipart/form-data to pipe each field of the form to the @saveFile@\nfunction.\n\nNow suppose 'inumHttpBody' fails (most likely because it receives an\nEOF before reading the number of bytes specified in the Content-Length\nheader).  Because 'inumHttpBody' is fused to @handler@, the failure\nwill cause @handler@ to receive an EOF, which will cause @foldForm@ to\nfail, which will cause 'handleI' to receive an EOF and return, which\nwill ensure 'hClose' runs and the file handle @h@ is not leaked.\n\nOnce the EOFs have been processed, the exception will propagate\nupwards making 'inumHttpServer' fail, which in turn will send an EOF\nto @iter@.  Then the exception will cause @enum@ to fail, after which\n@sock@ will be closed.  In summary, despite the complex structure of\nthe web server, because all the components are fused together with\npipe operators, corner cases like this just work with no need to worry\nabout leaked file descriptors.\n\n* /Uniform error-handling and simplified monad transformers/\n\nThe iterIO library provides a traditional throw and catch exception\nmechanism using its own functions 'throwI' and 'catchI', but keeping\nthe standard library exception hierarchy from \"Control.Exception\".\nAll of the support routines are carefully crafted to ensure that this\nsingle exception mechanism is the only one you ever need, so that you\ndon't end up having to integrate different components with different\nerror strategies, a situation summarized amusingly in the following\nblog post:\n<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.\n\nA key to uniform error handling is ensuring that errors can be\npropagated cleanly across different monads and transformers.  Thus,\nfor instance, the iterIO 'liftIO' function translates all uncaught IO\nerrors into 'Iter' errors.\n\nMore importantly, iterIO is designed to support the standard mtl monad\ntransformers while keeping 'Iter' as the outermost monadic type.  For\ninstance, if deep in the middle of some @'Iter' t 'IO'@ computation\nyou need a state transformer monad, you can invoke one with\n'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen\nby comparing their effective types, 'runStateTI' keeps the 'Iter'\nmonad on the outside, and thus can cleanly propagate failures out of\nthe 'StateT' subcomputation:\n\n> runStateT  :: StateT s m a -> s -> m (a, s)\n>\n> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)\n\nSimilarly, there is a function @'liftI' :: (MonadTrans t) => Iter\ns m a -> Iter s (t m) a@ that can be used to execute a computation in\nwhich a level of monad transformer is stripped off the inner monadic\ntype.\n\nAn equally important feature is the ability to distinguish 'Iter'\nfailures from 'Inum' failures, given that the former are often more\nserious than the latter.  As shown by the @grep@ example in the\ntutorial above, when one in a series of concatenated 'Inum's fails,\nyou often want to keep going without losing the state of the 'Iter'.\nThe enumerator package does not appear to support this distinction.\nThe iteratee package might, but it is not clear how to implement the\niteratee equivalent of the @grep@ example above.\n\nBy contrast, iterIO's 'Inum' mechanism was designed to be intuitive.\nIf you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then\nyou will catch exactly the errors thrown by those 'Inum's, not those\nthrown by pipeline stages outside the scope of the 'inumCatch' call.\n\nIt is because of this unified error handling mechanism that examples\nsuch as the HTTP server above can be guaranteed not to leak resources.\n\n* /Parser combinators for LL(*) grammars/\n\nIterIO's \"Data.IterIO.Parse\" module supports parsing of iteratee input\nusing combinators similar to those found in parsec.  However, parsec\nsupports only LL(1) grammars, and can lead to confusing failures--for\ninstance the parser @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ would fail\non input @\\\"for\\\"@.  IterIO, by contrast, supports full LL(*) parsing,\nmeaning a parser can look arbitrarily far ahead before failing.\n\nLL(*) parsers are generally disfavored because of their potential to\nconsume arbitrarily large amounts of memory to remember input for\nbacktracking.  However, iterIO offers two mechanisms that mitigate the\nproblem.\n\nFirst, because 'Iter's are constructed in such a way as to\ndifferentiate requests for more input from execution of monadic\nactions, it is possible to run multiple parsers in parallel.  Consider\na hypothetical parser such as the following, designed to recognize the\ninput format and parse either XML or JSON data:\n\n@\n  parser :: 'Iter' 'L.ByteString' m Value\n  parser = ('string' \\\"\\<!DOCTYPE\\\" >> parseXml)\n           \\<|\\> ('char' \\'{\\' >> parseJson)\n@\n\n@\\<|\\>@ is an infix synonym for the iterIO function 'multiParse',\nwhich attempts to run two parsers concurrently on input as it arrives.\nBecause 'string' and 'char' are both pure parser combinators with no\nmonadic side effects, it is possible to run them both concurrently\nwithout fear that the second rule--if it fails--will nonetheless have\nproduced side effects.  In fact, at least one of the 'string' or the\n'char' action will fail almost immediately, likely on the first chunk\nof data.  After one of the two has signaled a parse error, there is no\nlonger any need to store input for backtracking.  Note this works even\nif the subsequent functions @parseXml@ and @parseJson@ have monadic\nside effects, because 'multiParse' doesn't need to invoke those\nmonadic actions to determine that one of the two parsers has failed.\n\nA second way to avoid large amounts of storage for backtracking is to\nuse iterIO's '\\/' operator, which is an infix synonym for 'ifNoParse'.\nThe formulation @iter '\\/' no $ yes@ splits a parser into three\ncomponents.  @iter@ is executed with backtracking enabled.  If it\nsucceeds, then the saved data is discarded, @iter@'s result is fed to\nthe function @yes@, and any further failures will not cause input to\nbe rewound.  If, on the other hand, @iter@ fails, then input is\nrewound and @no@ is executed.  The '\\/' operator is very convenient\nfor long folds whose individual elements do not consume a lot of\ninput.  For example, to parse and sum a list of numbers (given a\nparser @number@ that skips spaces then parses one number), you might\ndo something like this:\n\n> parseAndSumIntegerList :: Iter String IO Int\n> parseAndSumIntegerList = loop 0\n>     where loop n = number \\/ return n $ \\n' -> loop (n + n')\n\nRegardless of the length of the list of numbers being parsed,\n@sumNumbers@ only ever needs to backtrack over the input consumed by a\nsingle iteration of @number@, which is likely a small amount of extra\nmemory to keep around.\n\nIf you do want an LL(1) parser combinator library, iterIO supports\nseamless integration with the attoparsec package.  The function 'atto'\nin \"Data.IterIO.Atto\" turns an attoparsec @Parser@ into an 'Iter'\nmonad, treating an attoparsec failure as an 'Iter' exception that can\nbe handled in the usual way with 'ifParse' or 'multiParse', or just\ncaught with 'catchI'.  (Attoparsec has the additional advantage of\nsolving the annoying @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ issue by\nspecial-casing @string@ to have more lookahead.)\n\nPreliminary testing suggests that attoparsec can be about three times\nfaster than \"Data.IterIO.Parse\" on parse-intensive workloads.  The\nlimitation is that attoparsec parsers must be pure.  A good compromise\nmay be to use IterIO for coarse-grained parsing, and attoparsec for\nmore complex data structures.  For example, you might want to use\niterIO's parsing of HTTP multipart/form-data (so as to be able to pipe\nfiles to disk in constant space), but for fields with JSON data, use\n'atto' to pipe the contents to the excellent attoparsec-based aeson\npackage.\n\n-}" Nothing),DP (-324,1)),((AnnComment DComment (DP (1,1),DP (13,3)) "{- $Acknowledgments\n\nDaniel Giffin contributed numerous suggestions and improvements to\nboth the code and documentation.  Deian Stefan and David Terei helped\nwith testing and improving the package, as well as understanding\nvarious relevant aspects of Haskell and GHC.  Mike Hamburg made the\nkey suggestion of defining 'Onum's as type-restricted 'Inum's.  The\nauthor is grateful to John Lato for helping him understand much of the\nimportant design rationale behind the original iteratee package.  This\nwork was funded by the DARPA Clean-Slate Design of Resilient,\nAdaptive, Secure Hosts (CRASH) program, BAA-10-70.\n\n-}" Nothing),DP (1,1)),((AnnComment DComment (DP (-11,1),DP (1,3)) "{- $Acknowledgments\n\nDaniel Giffin contributed numerous suggestions and improvements to\nboth the code and documentation.  Deian Stefan and David Terei helped\nwith testing and improving the package, as well as understanding\nvarious relevant aspects of Haskell and GHC.  Mike Hamburg made the\nkey suggestion of defining 'Onum's as type-restricted 'Inum's.  The\nauthor is grateful to John Lato for helping him understand much of the\nimportant design rationale behind the original iteratee package.  This\nwork was funded by the DARPA Clean-Slate Design of Resilient,\nAdaptive, Secure Hosts (CRASH) program, BAA-10-70.\n\n-}" Nothing),DP (-11,1)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  ByteString enumfile MonadTrans liftIOexampleI liftIO putStrLn" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  linesOutI foldr enumLines IOError IterR hPutStrLn stderr mline" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  resumeI isDoesNotExistError reRunIter verboseResumeI Oleg Lato" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,1)) "--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,79)) "--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-78),DP (0,1)) "--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI" Nothing),DP (0,-78)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,78)) "--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-77),DP (0,2)) "--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto" Nothing),DP (0,-77)),((AnnComment DComment (DP (1,1),DP (1,80)) "--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto" Nothing),DP (1,1)),((AnnComment DComment (DP (1,1),DP (1,59)) "--  LocalWords:  combinator aeson Giffin Deian Terei DARPA" Nothing),DP (1,1)),((AnnComment DComment (DP (0,-58),DP (0,21)) "--  LocalWords:  multiParse ifNoParse parseAndSumIntegerList sumNumbers ifParse" Nothing),DP (0,-58)),((AnnComment DComment (DP (1,1),DP (1,1)) "" Nothing),DP (1,1)),((AnnComment DComment (DP (0,0),DP (0,58)) "--  LocalWords:  combinator aeson Giffin Deian Terei DARPA" Nothing),DP (0,0)),((G AnnEofPos),DP (857,0))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(48,5)-(64,5) CN "(:)" NotNeeded,
  (Ann (DP (1,5)) (ColDelta 5) DP (1,5) [] [((G AnnOpenP),DP (0,0)),((AnnComment DComment (DP (2,5),DP (2,18)) "-- * Overview" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,17)) "-- $Overview" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,18)) "-- * Tutorial" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,17)) "-- $Tutorial" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,50)) "-- * Differences from other iteratee packages" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,20)) "-- $Differences" Nothing),DP (1,5)),((AnnComment DComment (DP (2,5),DP (2,25)) "-- * Acknowledgments" Nothing),DP (2,5)),((AnnComment DComment (DP (1,5),DP (1,24)) "-- $Acknowledgments" Nothing),DP (1,5)),((G AnnCloseP),DP (13,5))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:6-28 CN "IEModuleContents" NotNeeded,
  (Ann (DP (0,0)) (ColDelta 6) DP (0,0) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:7-30 CN "IEModuleContents" NotNeeded,
  (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:7-29 CN "IEModuleContents" NotNeeded,
  (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1)),((G AnnComma),DP (1,5))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:7-33 CN "IEModuleContents" NotNeeded,
  (Ann (DP (0,1)) (ColDelta 7) DP (0,1) [] [((G AnnModule),DP (0,0)),((G AnnVal),DP (0,1))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,1)-(67,32) CN "ImportDecl" NotNeeded,
  (Ann (DP (2,1)) (ColDelta 1) DP (2,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32) CN "(:)" NotNeeded,
  (Ann (DP (0,1)) (ColDelta 25) DP (0,1) [] [((G AnnHiding),DP (0,0)),((G AnnOpenP),DP (0,1)),((AnnComment DComment (DP (0,1),DP (0,28)) "-- names that might collide" Nothing),DP (0,1)),((G AnnCloseP),DP (1,32))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:33-36 CN "IEVar" NotNeeded,
  (Ann (DP (0,0)) (ColDelta 33) DP (0,0) [] [])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:33-36 CN "Unqual" NotNeeded,
  (Ann (DP (0,0)) (ColDelta 33) DP (0,0) [] [((G AnnVal),DP (0,0)),((G AnnComma),DP (0,0))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:39-41 CN "IEVar" NotNeeded,
  (Ann (DP (0,1)) (ColDelta 39) DP (0,1) [] [])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:39-41 CN "Unqual" NotNeeded,
  (Ann (DP (0,0)) (ColDelta 39) DP (0,0) [] [((G AnnVal),DP (0,0))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1-24 CN "ImportDecl" NotNeeded,
  (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1-23 CN "ImportDecl" NotNeeded,
  (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))])),
 (AnnKey ../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1-27 CN "ImportDecl" NotNeeded,
  (Ann (DP (1,1)) (ColDelta 1) DP (1,1) [] [((G AnnImport),DP (0,0)),((G AnnVal),DP (0,1))]))]
==============
([((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:1:1,
    AnnModule),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:47:1-6]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:1:1,
    AnnWhere),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:64:7-11]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(48,5)-(64,5),
    AnnCloseP),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:64:5]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(48,5)-(64,5),
    AnnOpenP),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:5]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:6-28,
    AnnComma),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:5]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:6-28,
    AnnModule),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:48:6-11]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:7-30,
    AnnComma),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:5]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:7-30,
    AnnModule),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:49:7-12]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:7-29,
    AnnComma),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:5]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:7-29,
    AnnModule),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:50:7-12]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:7-33,
    AnnModule),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:51:7-12]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,1)-(67,32),
    AnnImport),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:1-6]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,1)-(67,32),
    AnnSemi),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32),
    AnnCloseP),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:67:32]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32),
    AnnHiding),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:25-30]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32),
    AnnOpenP),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:32]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:33-36,
    AnnComma),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:66:37]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1-24,
    AnnImport),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1-6]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:68:1-24,
    AnnSemi),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1-23,
    AnnImport),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1-6]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:69:1-23,
    AnnSemi),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1-27,
    AnnImport),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1-6]),
  ((../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:70:1-27,
    AnnSemi),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:927:1]),
  ((<no location info>, AnnEofPos),
   [../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:927:1])],
 [(../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(48,5)-(64,5),
   [AnnLineComment "-- $Acknowledgments",
    AnnLineComment "-- * Acknowledgments",
    AnnLineComment "-- $Differences",
    AnnLineComment "-- * Differences from other iteratee packages",
    AnnLineComment "-- $Tutorial", AnnLineComment "-- * Tutorial",
    AnnLineComment "-- $Overview", AnnLineComment "-- * Overview"]),
  (../../hackage-packages/iterIO-0.2.2/Data/IterIO.hs:(66,25)-(67,32),
   [AnnLineComment "-- names that might collide"]),
  (<no location info>,
   [AnnLineComment "--  LocalWords:  combinator aeson Giffin Deian Terei DARPA",
    AnnLineComment "--  LocalWords:  multiParse ifNoParse parseAndSumIntegerList sumNumbers ifParse",
    AnnLineComment "--  LocalWords:  subcomputation enumeratee JSON DOCTYPE parseXml parseJson atto",
    AnnLineComment "--  LocalWords:  hClose foldForm multipart monads runStateTI runStateT StateT",
    AnnLineComment "--  LocalWords:  enumHttpResp saveFile ffName openBinaryFile WriteMode finallyI",
    AnnLineComment "--  LocalWords:  iterStream ioHttpServer httpReqI liftI inumHttpBody irun EOFs",
    AnnLineComment "--  LocalWords:  lookahead Enumeratee Enumeratees inumHttpServer forkIO req GHC",
    AnnLineComment "--  LocalWords:  SomeException inliner iteratee's getpeername runIteratee iter",
    AnnLineComment "--  LocalWords:  Kiselyov iterIO's newtype runIter forall onDone onCont GHC's",
    AnnLineComment "--  LocalWords:  resumeI isDoesNotExistError reRunIter verboseResumeI Oleg Lato",
    AnnLineComment "--  LocalWords:  linesOutI foldr enumLines IOError IterR hPutStrLn stderr mline",
    AnnLineComment "--  LocalWords:  whileNullI grepCount catchI inumCatch throwI throwIO enumStdin",
    AnnLineComment "--  LocalWords:  InumM throwEOFI inumGrep headI packedRe lengthI safeHeadI usr",
    AnnLineComment "--  LocalWords:  takeI wc lineCountI safeLineI ByteStrings inumToLines Onum's",
    AnnLineComment "--  LocalWords:  ByteString enumfile MonadTrans liftIOexampleI liftIO putStrLn",
    AnnLineComment "--  LocalWords:  headFile FilePath enumFile Iter's stdoutI handleI catFile EOF",
    AnnLineComment "--  LocalWords:  transcode inumPure transcodes enum iterIO Haskell mempty lineI",
    AnnLineComment "--  LocalWords:  MonadIO iteratees tOut transcoding Inum's mkInum mkInumM Onum",
    AnnLineComment "--  LocalWords:  attoparsec parsers loopback monadic Iteratees ChunkData tIn kk",
    AnnLineComment "--  LocalWords:  IterIO iteratee monad mtl Iter combinators zlib gzip SSL Inum",
    AnnBlockComment "{- $Acknowledgments\n\nDaniel Giffin contributed numerous suggestions and improvements to\nboth the code and documentation.  Deian Stefan and David Terei helped\nwith testing and improving the package, as well as understanding\nvarious relevant aspects of Haskell and GHC.  Mike Hamburg made the\nkey suggestion of defining 'Onum's as type-restricted 'Inum's.  The\nauthor is grateful to John Lato for helping him understand much of the\nimportant design rationale behind the original iteratee package.  This\nwork was funded by the DARPA Clean-Slate Design of Resilient,\nAdaptive, Secure Hosts (CRASH) program, BAA-10-70.\n\n-}",
    AnnBlockComment "{- $Differences\n\nThe Iteratee approach was originally advocated by Oleg Kiselyov (see\ntalk slides at <http://okmij.org/ftp/Streams.html#iteratee>).  The\nmain implementation by Kiselyov and John Lato is simply called\n/iteratee/ (<http://hackage.haskell.org/package/iteratee>).  Another\nrealization of the iteratee concepts is the /enumerator/ package\n(<http://hackage.haskell.org/package/enumerator>).  IterIO is a\nre-implementation of these concepts from scratch.  This section\ndiscusses the differences between previous packages and iterIO, both\nas a means for motivating iterIO's design and as a set of suggestions\nfor improving other iteratee implementations.\n\n* /Base abstraction/\n\nThe iterIO package represents an iteratee as a pure function from a\nchunk of pending input data to an iteratee result of type 'IterR':\n\n@\n  newtype 'Iter' t m a = 'Iter' { runIter :: 'Chunk' t -> 'IterR' t m a }\n@\n\nAn 'IterR' can yield a result and residual input, or it can ask for\nmore input, or it can request to have an action executed in the\nunderlying monad, or it can signal failure.  The fact that all\niteratees are functions of input ensures that iteratees generally see\n/all/ pending input.  Thus, iteratees can do things like measure the\nlength of buffered input to subtract it from the current file offset\nand determine the effective position in a file.\n\n`IterR`'s division of iteratee results into different outcomes such as\nneeding input or needing monadic actions allows the library to\ndistinguish between pure iteratees and those with potential side\neffects.  The ability to know that a specific iteratee is a pure\nfunction in many cases allows one to parse LL(*) grammars without\nlarge amounts of input buffering for backtracking (see below).\n\nIn contrast, the iteratee package uses continuation passing style\n(CPS), in which an iteratee is a function taking two continuation\nfunctions--one to call when done, and a second to call when either\nrequesting more input or failing:\n\n> -- From the iteratee package:\n> newtype Iteratee s m a = Iteratee{ runIter :: forall r.\n>        -- First the \"onDone\" function:\n>           (a -> Stream s -> m r) ->\n>        -- Next the \"onCont\" function:\n>           ((Stream s -> Iteratee s m a) -> Maybe SomeException -> m r) ->\n>           m r}\n\nCPS has the advantage of exposing the bind operator of the underlying\nmonad, making 'lift' cheap and simple.  Moreover, splitting into two\ncontinuations saves the first and most common one (i.e., \\\"onDone\\\")\nfrom the overhead of checking whether an error condition or request\nfor more input has occurred.  See\n<http://haskell.org/haskellwiki/Performance/Monads#Use__Continuation_Passing_Style>\nfor a good discussion of the advantages of CPS.\n\nBecause of CPS, iteratee should be capable of delivering the best\nperformance of the three iteratee packages.  A disadvantage of\niterIO's approach is that every invocation of 'lift' must be\npropagated all the way up the call chain, where a small amount of\noverhead is added for each enclosing 'catchI' or similar call.  While\niterIO can handle most successful 'IterR' outcomes and caught\nexceptions locally without popping back up the call stack, there is\nalso potentially overhead from actually checking that the outcome was\nsuccessful at each bind site.  (GHC's inliner may be able to avoid the\ncheck in some cases.)\n\nHowever, iteratee lacks several features of iterIO; offering these\nfeatures would likely reduce the benefits of CPS and complicate code.\nFor instance, there is no way to execute a pure iteratee without\nmonadic actions (the benefit touted above and described below for\nLL(*) parsing).  Moreover, iteratee's exception mechanism discards the\ncurrent location in the input stream, making it unsuitable for failed\nparse alternatives.  IterIO provides a general control mechanism to\nmake arbitrary requests from enumerators (such as seek, tell,\ngetpeername, get SSL information, etc.); iteratee instead overloads\nthe exception mechanism for control purposes, which prevents control\noperations from returning values.  Thus, while iteratee can implement\nseek, it cannot, for instance, implement tell.\n\nThe enumerator package's approach is closer to iterIO's, but makes\nevery iteratee into a monadic action in the underlying monad @m@:\n\n> -- From the enumerator package:\n> newtype Iteratee a m b = Iteratee { runIteratee :: m (Step a m b) }\n\nHere @Step@ is similar to iterIO's 'IterR' type, but the @m@ wrapper\ndisallows iterIO's LL(*) parsing tricks.  It also causes gratuitous\ninvocation of @m@'s bind function, which can be expensive when using\nstacks of monad transformers.  Furthermore, enumerator discards the\ninput state on all errors, making it impossible to resume from\nfailures that leave the input in a known state (such as a parsing\nlookahead failure).\n\n* /Uniformity of abstraction/\n\nIterIO's abstractions were refined over many iterations to become\nminimal yet highly expressive and familiar to Unix shell users.  Thus,\nwe have 'Iter's, which are data sinks that consume input and produce a\nresult.  Then we have 'Inum's, which are also 'Iter's.  These two data\ntypes and can combined through pipes (i.e., fusing) and concatenation,\nboth of which have direct analogues in the Unix @|@ (pipe) operator\nand @cat@ command.\n\nBasing everything around these few concepts makes the library easier\nto learn and use.  For instance, because all 'Inum's are 'Iter's,\nthere is only one set of 'Iter' building blocks to learn.  'Inum'\nimplementations invoke the same 'Iter's that are used to build other\n'Iter's.  Moreover, 'Inum's and 'Iter's use the same error handling\nmechanism.  Finally, because 'Onum's are also 'Inum's, one set of\nfusing and concatenation operators works for both.\n\nBy contrast, both the iteratee and enumerator packages use enumerator\ntypes that are not iteratees.  Hence, constructing enumerators is\nharder and requires a different error handing mechanism.  The packages\nmust introduce a third, hybrid \\\"Enumeratee\\\" type for inner pipeline\nstages, and fusing Enumerators to Enumeratees is a different function\nfrom fusing Enumeratees together.\n\nFunneling everything through a small number of abstractions also\nensures that the right thing happens in corner cases.  In particular,\nall enumerator application happens through the pipe operator.  Though\nthere are two pipe operators, a left associative one and a right\nassociative one, they internally use the same function:  @a '|.' b =\n(a '.|') . b@.  Similarly, the pipe application operators ('|$' and\n'.|$') are defined in terms of '.|'.\n\n'.|' guarantees that its right-hand argument will receive an EOF when\nthe left hand argument terminates (whether normally or through an\nexception).  This is crucial for managing resources such file\ndescriptors, and works no matter how convoluted the control structure\nof your program.\n\nConsider the following realistic scenario of a web server constructed\nas an 'Inum' that translates from HTTP requests to HTTP responses.\n(Such an 'Inum' is provided by the function 'inumHttpServer' in\n\"Data.IterIO.HTTP\".)  The server's accept loop would resemble the\nfollowing:\n\n@\n   loop = do\n     (sock, _) <- Net.accept $ listen_socket\n     _ <- forkIO $ do\n            (iter, enum) <- 'iterStream' (sock)\n            enum '|$' 'inumHttpServer' ('ioHttpServer' handler) '.|' iter\n     loop\n@\n\nThis code depends on the fact that 'iterStream' closes @sock@ after\nboth the @iter@ has received an EOF and the @enum@ has returned.  One\nlevel down, 'inumHttpServer' uses 'mkInumM' to construct an 'Inum',\nand has code looking something like this:\n\n@\n     req <- 'httpReqI'                              -- parse HTTP request\n     resp <- 'liftI' $ inumHttpBody .| handler req  -- invoke handler\n     'irun' $ enumHttpResp resp Nothing             -- send response to client\n@\n\nThe @handler@ gets run on the body of the message, and might decide to\nprocess an HTTP POST request by saving an uploaded file to disk, for\ninstance with code like this:\n\n@\n     let saveFile _ field\n           | ffName field == S8.pack \\\"file\\\" = do\n                            h <- liftIO $ openBinaryFile \\\"upload\\\" WriteMode\n                            'handleI' h ``finallyI`` liftIO (hClose h)\n           | otherwise = return ()\n     in foldForm req saveFile ()\n@\n\n@foldForm@ internally is invoking an 'Inum' that parses HTTP\nmultipart/form-data to pipe each field of the form to the @saveFile@\nfunction.\n\nNow suppose 'inumHttpBody' fails (most likely because it receives an\nEOF before reading the number of bytes specified in the Content-Length\nheader).  Because 'inumHttpBody' is fused to @handler@, the failure\nwill cause @handler@ to receive an EOF, which will cause @foldForm@ to\nfail, which will cause 'handleI' to receive an EOF and return, which\nwill ensure 'hClose' runs and the file handle @h@ is not leaked.\n\nOnce the EOFs have been processed, the exception will propagate\nupwards making 'inumHttpServer' fail, which in turn will send an EOF\nto @iter@.  Then the exception will cause @enum@ to fail, after which\n@sock@ will be closed.  In summary, despite the complex structure of\nthe web server, because all the components are fused together with\npipe operators, corner cases like this just work with no need to worry\nabout leaked file descriptors.\n\n* /Uniform error-handling and simplified monad transformers/\n\nThe iterIO library provides a traditional throw and catch exception\nmechanism using its own functions 'throwI' and 'catchI', but keeping\nthe standard library exception hierarchy from \"Control.Exception\".\nAll of the support routines are carefully crafted to ensure that this\nsingle exception mechanism is the only one you ever need, so that you\ndon't end up having to integrate different components with different\nerror strategies, a situation summarized amusingly in the following\nblog post:\n<http://www.randomhacks.net/articles/2007/03/10/haskell-8-ways-to-report-errors>.\n\nA key to uniform error handling is ensuring that errors can be\npropagated cleanly across different monads and transformers.  Thus,\nfor instance, the iterIO 'liftIO' function translates all uncaught IO\nerrors into 'Iter' errors.\n\nMore importantly, iterIO is designed to support the standard mtl monad\ntransformers while keeping 'Iter' as the outermost monadic type.  For\ninstance, if deep in the middle of some @'Iter' t 'IO'@ computation\nyou need a state transformer monad, you can invoke one with\n'runStateTI', which is the iterIO equivalent of 'runStateT'.  As seen\nby comparing their effective types, 'runStateTI' keeps the 'Iter'\nmonad on the outside, and thus can cleanly propagate failures out of\nthe 'StateT' subcomputation:\n\n> runStateT  :: StateT s m a -> s -> m (a, s)\n>\n> runStateTI :: Iter t (StateT s m) a -> s -> Iter t m (a, s)\n\nSimilarly, there is a function @'liftI' :: (MonadTrans t) => Iter\ns m a -> Iter s (t m) a@ that can be used to execute a computation in\nwhich a level of monad transformer is stripped off the inner monadic\ntype.\n\nAn equally important feature is the ability to distinguish 'Iter'\nfailures from 'Inum' failures, given that the former are often more\nserious than the latter.  As shown by the @grep@ example in the\ntutorial above, when one in a series of concatenated 'Inum's fails,\nyou often want to keep going without losing the state of the 'Iter'.\nThe enumerator package does not appear to support this distinction.\nThe iteratee package might, but it is not clear how to implement the\niteratee equivalent of the @grep@ example above.\n\nBy contrast, iterIO's 'Inum' mechanism was designed to be intuitive.\nIf you wrap a pipeline of 'Inum's in an 'inumCatch' statement, then\nyou will catch exactly the errors thrown by those 'Inum's, not those\nthrown by pipeline stages outside the scope of the 'inumCatch' call.\n\nIt is because of this unified error handling mechanism that examples\nsuch as the HTTP server above can be guaranteed not to leak resources.\n\n* /Parser combinators for LL(*) grammars/\n\nIterIO's \"Data.IterIO.Parse\" module supports parsing of iteratee input\nusing combinators similar to those found in parsec.  However, parsec\nsupports only LL(1) grammars, and can lead to confusing failures--for\ninstance the parser @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ would fail\non input @\\\"for\\\"@.  IterIO, by contrast, supports full LL(*) parsing,\nmeaning a parser can look arbitrarily far ahead before failing.\n\nLL(*) parsers are generally disfavored because of their potential to\nconsume arbitrarily large amounts of memory to remember input for\nbacktracking.  However, iterIO offers two mechanisms that mitigate the\nproblem.\n\nFirst, because 'Iter's are constructed in such a way as to\ndifferentiate requests for more input from execution of monadic\nactions, it is possible to run multiple parsers in parallel.  Consider\na hypothetical parser such as the following, designed to recognize the\ninput format and parse either XML or JSON data:\n\n@\n  parser :: 'Iter' 'L.ByteString' m Value\n  parser = ('string' \\\"\\<!DOCTYPE\\\" >> parseXml)\n           \\<|\\> ('char' \\'{\\' >> parseJson)\n@\n\n@\\<|\\>@ is an infix synonym for the iterIO function 'multiParse',\nwhich attempts to run two parsers concurrently on input as it arrives.\nBecause 'string' and 'char' are both pure parser combinators with no\nmonadic side effects, it is possible to run them both concurrently\nwithout fear that the second rule--if it fails--will nonetheless have\nproduced side effects.  In fact, at least one of the 'string' or the\n'char' action will fail almost immediately, likely on the first chunk\nof data.  After one of the two has signaled a parse error, there is no\nlonger any need to store input for backtracking.  Note this works even\nif the subsequent functions @parseXml@ and @parseJson@ have monadic\nside effects, because 'multiParse' doesn't need to invoke those\nmonadic actions to determine that one of the two parsers has failed.\n\nA second way to avoid large amounts of storage for backtracking is to\nuse iterIO's '\\/' operator, which is an infix synonym for 'ifNoParse'.\nThe formulation @iter '\\/' no $ yes@ splits a parser into three\ncomponents.  @iter@ is executed with backtracking enabled.  If it\nsucceeds, then the saved data is discarded, @iter@'s result is fed to\nthe function @yes@, and any further failures will not cause input to\nbe rewound.  If, on the other hand, @iter@ fails, then input is\nrewound and @no@ is executed.  The '\\/' operator is very convenient\nfor long folds whose individual elements do not consume a lot of\ninput.  For example, to parse and sum a list of numbers (given a\nparser @number@ that skips spaces then parses one number), you might\ndo something like this:\n\n> parseAndSumIntegerList :: Iter String IO Int\n> parseAndSumIntegerList = loop 0\n>     where loop n = number \\/ return n $ \\n' -> loop (n + n')\n\nRegardless of the length of the list of numbers being parsed,\n@sumNumbers@ only ever needs to backtrack over the input consumed by a\nsingle iteration of @number@, which is likely a small amount of extra\nmemory to keep around.\n\nIf you do want an LL(1) parser combinator library, iterIO supports\nseamless integration with the attoparsec package.  The function 'atto'\nin \"Data.IterIO.Atto\" turns an attoparsec @Parser@ into an 'Iter'\nmonad, treating an attoparsec failure as an 'Iter' exception that can\nbe handled in the usual way with 'ifParse' or 'multiParse', or just\ncaught with 'catchI'.  (Attoparsec has the additional advantage of\nsolving the annoying @string \\\"foo\\\" \\<|\\> string \\\"for\\\"@ issue by\nspecial-casing @string@ to have more lookahead.)\n\nPreliminary testing suggests that attoparsec can be about three times\nfaster than \"Data.IterIO.Parse\" on parse-intensive workloads.  The\nlimitation is that attoparsec parsers must be pure.  A good compromise\nmay be to use IterIO for coarse-grained parsing, and attoparsec for\nmore complex data structures.  For example, you might want to use\niterIO's parsing of HTTP multipart/form-data (so as to be able to pipe\nfiles to disk in constant space), but for fields with JSON data, use\n'atto' to pipe the contents to the excellent attoparsec-based aeson\npackage.\n\n-}",
    AnnBlockComment "{- $Tutorial\n\n #tutorial#\n\n\nThe iterIO library performs IO by hooking up sources of data, called\n/enumerators/, to data sinks, called /iteratees/, in a manner\nreminiscent of Unix command pipelines.  Compared to lazy IO, the\nenumerator/iteratee paradigm provides better error handing,\nreferential transparency (which should, after all, be one of the big\nadvantages of Haskell), and equally convenient composition of protocol\nlayers and parsers without worrying about IO chunk boundaries.\n\nEnumerators, implemented by the type 'Onum' (short for\n/outer enumerator/, for reasons that will become clear below), are so\ncalled because they enumerate all data elements (e.g., bytes or\npackets) in some source such as a file or socket.  Hence, an\nenumerator should be viewed as a /source/ outputting chunks of data\nwhose type is a @'Monoid'@.  (Actually, the input type must be of\nclass 'ChunkData', which is a @'Monoid'@ that additionally has a\nmethod @'null'@ to test whether a piece of data is equal to\n'mempty'.)\n\nIteratees, implemented by the type 'Iter', should be viewed as /sinks/\nconsuming data.  When executing IO, the library /iterates/ over all\ndata elements output by the source, using an iteratee to produce a\nresult.  The source may output data in chunks whose boundaries do not\ncoincide with logical message units; iteratees handle this\ntransparently, simplifying programming.\n\nHere is a simple example:\n\n@\n    -- Return the first line of a file\n    headFile :: FilePath -> IO String\n    headFile path = 'enumFile' path '|$' 'lineI'\n@\n\n'enumFile' enumerates the contents of a file.  'lineI' returns a line\nof input (discarding the newline).  '|$' is the /pipe apply/ operator\nthat applies an 'Onum' to an 'Iter', returning the result of the\n'Iter'--in this case the first line of the file named @path@.\n\nAn `Iter`'s main purpose may not be to produce a result.  Some 'Iter's\nare primarily useful for their side effects.  For example, 'stdoutI'\nwrites data to standard output; 'handleI' similarly writes output to\nan arbitrary file handle.  Thus, the following function copies the\ncontents of a file to standard output:\n\n@\n    -- Copy file to standard output\n    catFile :: FilePath -> IO ()\n    catFile path = 'enumFile'' path '|$' 'stdoutI'\n@\n\n'enumFile'' is like 'enumFile' above, but type restricted to data in\nthe lazy @'ByteString'@ format, which is more efficient than plain\n'String's.  ('enumFile' supports multiple types, but in this example\nthere is not enough information for Haskell to choose one of them, so\nwe must use 'enumFile'' or use @::@ to specify a type explicitly.)\nOnce again, '|$' is used to execute the IO actions, but, this time,\nthe return value is just @()@; the interesting action lies in the side\neffects of writing data to standard output while iterating over the\ninput with 'stdoutI'.\n\nThe real power of the iteratee abstraction lies in the fact that\n'Iter's are monadic computations.  One 'Iter' may invoke another to\nmake use of the first one's results.  Here is an example of a function\nthat returns the first two lines of a file:\n\n@\n    -- | Return first two lines of file\n    head2File :: FilePath -> IO (String, String)\n    head2File path = 'enumFile' path '|$' lines2I\n@\n\n@\n    -- | Iter that returns next two lines as a pair\n    lines2I :: (Monad m) => 'Iter' String m (String, String)\n    lines2I = do\n      line1 <- 'lineI'\n      line2 <- 'lineI'\n      return (line1, line2)\n@\n\nThis example illustrates several points.  First, consider the type of\nthe @lines2I@ function:  @'Iter' String m (String, String)@.  The\n'Iter' type constructor takes three type arguments.  The first,\n'String' in this case, specifies the type of input expected by the\niteratee.  The last type, @(String, String)@ in this case, specifies\nthe result type of the iteratee.  Finally, the middle type, @m@, is a\nmonad, because @'Iter' t@ (for a given input type @t@) is a monad\ntransformer (i.e., it is an instance of the 'MonadTrans' class).  In\nthis case, when @head2File@ invokes @lines2I@, @m@ will be @IO@,\nbecause @head2File@ is returning a result in the @IO@ monad.  However,\n@lines2I@ would work equally well with any other monad.\n\nNext, notice the functioning of @'Iter' String m@ as a monad.  The\ntype of 'lineI' in the above example is @'Iter' String m String@.  The\n@lines2I@ function executes 'lineI' twice using monadic @do@ syntax to\nbind the results to @line1@ and @line2@.  The monadic bind operator\nhides the details of IO chunk boundaries.  If, for instance, 'lineI'\nneeds more input because a newline character has not yet been read,\n'lineI' returns to the containing enumerator asking for more data.  If\nthe first 'lineI' receives more than a line of input, it simply passes\nthe residual input to the next invocation of 'lineI'.  Both of these\nactions are hidden by the syntax, making most code much easier to read\nand write.\n\nThat explains the iteratee type 'Iter'.  The enumerator type, 'Onum',\nhas the same three type arguments.  Thus, the type of 'enumFile', as\ninstantiated in the above examples, is @'enumFile' :: 'Onum' String IO\na@.  Most 'Onum' types are polymorphic in the last argument, so as to\nbe able to return whatever type the 'Iter' is returning.  (In fact,\n'enumFile' is polymorphic in the first two arguments, too, so as to\nwork with multiple @String@-like types and any monad in the\n@'MonadIO'@ class.)\n\nHere is an example of an 'Iter' with side effects:\n\n@\n    liftIOexampleI :: (MonadIO m) => 'Iter' String m ()\n    liftIOexampleI = do\n      line <- 'lineI'\n      'liftIO' $ putStrLn $ \\\"First line is: \\\" ++ line\n      next <- 'takeI' 40\n      'liftIO' $ putStrLn $ \\\"And the next 40 bytes are: \\\" ++ next\n@\n\nUnlike @lines2I@, @liftIOexampleI@ does not return any interesting\nresult, but it uses the @'liftIO'@ monad transformer method to output\nthe first line of the file, followed by the next 40 bytes.  The\n'takeI' iteratee returns a 'String' (or @ByteString@) with exactly the\nrequested number of characters or bytes, unless an EOF (end-of-file)\nis encountered.\n\nOf course, the real power of command pipelines is that you can hook\nmultiple commands together.  For instance, say you want to know how\nmany words in the system dictionary files contain a double k and start\nwith a lower-case letter.  You could run a command like this:\n\n>    cat /usr/share/dict/words /usr/share/dict/extra.words >        | grep kk | grep '^[a-z]' | wc -l\n\n\nLet's see how to do something equivalent with iteratees, starting with\nthe @wc -l@ command, which counts lines.  Here is an equivalent iteratee:\n\n@\n    lineCountI :: (Monad m) => 'Iter' String m Int\n    lineCountI = count 0\n        where count n = do\n                line <- 'safeLineI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nThe 'safeLineI' function is like 'lineI', but returns a @'Maybe'\n'String'@ (or @'Maybe' 'ByteString'@) which is 'Nothing' upon an EOF\ncondition.  ('lineI' throws an exception on EOF.)\n\nWhat about the @grep@ command?  @grep@ sits in the middle of a\npipeline, so it acts both as a data sink and as a data source.\nThis is why we call such a pipeline stage an\n/iteratee-enumerator/, or 'Inum'.  Before defining our @grep@\nequivalent, since multiple pipeline stages are going to be considering\nthe file one line at a time, let's first build an 'Inum' to separate\ninput into lines:\n\n@\n    import Data.ByteString as S\n    import Data.ByteString.Char8 as S8\n@\n\n@\n    -- | Break input into lines of type S.ByteString, as this type\n    -- works most conveniently with regular expressions.  (Otherwise,\n    -- we would prefer lazy ByteStrings.)\n    inumToLines :: (Monad m) => 'Inum' S.ByteString [S.ByteString] m a\n    inumToLines = 'mkInum' $ do\n                    line <- 'lineI'\n                    return [line]\n@\n\n'Inum' takes four type arguments, compared to only three for 'Onum'.\nThat's because an 'Inum' is acting as both an iteratee and an\nenumerator; it needn't be processing the same type of data in both\nroles.  In the above example, when acting as an iteratee,\n@inumToLines@ consumes data of type @S.ByteString@ (the first type\nargument), accepting one long stream of unstructured bytes.  However,\nas an enumerator, @inumToLines@ produces output of type\n@[S.ByteString]@ (the second type argument), a /list/ of strings, one\nper line of the file.  In general the type @'Inum' tIn tOut m a@ is an\niteratee-enumerator taking input type @tIn@, producing output type\n@tOut@, and feeding the output to an iteratee of type @'Iter' tOut m\na@.\n\nIn fact, an 'Onum' is just a special kind of 'Inum' with the void\ninput type @()@.  The type @'Onum' t m a@ is just a synonym for\n@'Inum' () t m a@.  Most operations on 'Inum's can be used with\n'Onum's as well, since an 'Onum' /is/ an 'Inum'.  The converse is not\ntrue, however.  For example, the '|$' operator requires an 'Onum', as\nit wouldn't know what data to feed to an arbitrary 'Inum'.  (If you\nneed it, however, there is a function @run@, hidden by this module but\nexported by \"Data.IterIO.Iter\", that executes an iteratee computation\nof arbitrary input type by feeding EOF as input.)\n\nIteratee-enumerators are generally constructed using either 'mkInum'\nor `mkInumM`, and by convention most 'Inum's have names starting\n\\\"@inum@...\\\", except that 'Onum' names start \\\"@enum@...\\\".  'mkInum'\ntakes an argument of type @'Iter' tIn m tOut@ that consumes input of\ntype @tIn@ to produce output of type @tOut@.  (For @inumToLines@,\n@tIn@ is @S.ByteString@ and @tOut@ is @[S.ByteString]@).  This is fine\nfor simple stateless translation functions, but sometimes one would\nlike to keep state and use more complex logic in an 'Inum'.  For that,\nthe 'mkInumM' function creates an 'Inum' out of a computation in a\ndedicated 'InumM' monad.  See the \"Data.IterIO.Inum\" documentation for\nmore information on 'mkInumM'.  In @inumToLines@, we do not need to\nkeep state.  We are happy just to let 'lineI' throw an exception on\nEOF, which `mkInum` will catch and handle gracefully.\n\nThrowing an EOF exception--either implicitly by executing another\n'Iter', or explicitly with 'throwEOFI'--is one of the standard ways to\nexit an 'Inum' created by 'mkInum'.  The other way is to return empty\ninput.\n\nWe similarly define an 'Inum' to filter out lines not matching a\nregular expression (using the \"Text.Regex.Posix.ByteString\" library),\nand a simple 'Inum' to count list elements (since @lineCountI ::\n'Iter' String m Int@ has input data type @String@, while after\n@inumToLines@ we need an 'Iter' with input data type\n@[S.ByteString]@).\n\n@\n    inumGrep :: (Monad m) => String -> 'Inum' [S.ByteString] [S.ByteString] m a\n    inumGrep re = `mkInum` $ do\n      line <- 'headI'\n      if line =~ packedRe then return [line] else return []\n        where\n          packedRe = S8.pack re\n@\n\n@\n    lengthI :: (Monad m) => 'Iter' [t] m Int\n    lengthI = count 0\n        where count n = do\n                line <- 'safeHeadI'\n                case line of\n                  Just _  -> count (n+1)\n                  Nothing -> return n\n@\n\nNow we are almost ready to assemble all the pieces.  But recall that\nthe '|$' operator applies one 'Onum' to one 'Iter', yet now we have\ntwo 'Onum's (because we want to look through two files), and three\n'Inum's that we want to compose into a pipeline.  The library\nsupports two types of composition for pipeline stages:\n/concatenation/ and /fusing/.\n\nTwo 'Inum's (or 'Onum's) of the same type can be /concatenated/ with\nthe 'cat' function, producing a new data source that enumerates all of\nthe data in the first 'Inum' followed by all of the data in the\nsecond.\n\nThere are two /fusing/ operators.  The left-associative '|.' operator\nfuses two 'Inum's, provided the output type of the first is the input\ntype of the second.  (Mnemonic: it produces a pipeline stage that is\nopen on the right hand side, as it still needs to be applied to an\niteratee with '|$'.)  The right-associative '.|' operator fuses an\n'Inum' to an 'Iter', producing a new 'Iter'.\n\nThe fusing operators bind more tightly than the infix concatenation\nfunctions, which in turn bind more tightly than '|$'.  (Concatenation\noperators can also be used through prefix function application, which\nbinds most tightly.)  Hence, putting it all together, we produce the\nfollowing Haskell equivalent to the above Unix pipeline:\n\n@\n    grepCount :: IO Int\n    grepCount = 'enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines\n                    ``cat`` 'enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines\n                '|$' inumGrep \\\"kk\\\"\n                        '.|' inumGrep \\\"^[a-z]\\\"\n                        '.|' lengthI\n@\n\nOne often has a choice as to whether to fuse an 'Inum' to the\n'Onum', or to the 'Iter'.  For example, @grepCount@ could\nalternatively have been implemented as:\n\n@\n    grepCount' :: IO Int\n    grepCount' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\" '|.' inumToLines)\n                         ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\" '|.' inumToLines)\n                    '|.' inumGrep \\\"kk\\\"\n                    '|.' inumGrep \\\"^[a-z]\\\"\n                 '|$' lengthI\n@\n\nIn this case, the two are essentially equivalent.  However, for error\nhandling purposes, one should fuse together pipeline stages in which\nerrors have similar consequences.  Often an 'Inum' or 'Onum' failure\nis less serious than an 'Iter' failure.  For example, in the above\nexample, if 'enumFile' fails because one of the files does not exist,\nwe might want to continue processing lines from the next file.\nConversely, if @lengthI@ fails or one of the @inumGrep@ stages fails\n(most likely because the regular expression is illegal), there is not\nmuch point in continuing the program.  This is why the first example\nfused @inumGrep@ to @lengthI@, though this won't matter until we\nactually handle errors (see below).\n\nAnother alternative would have been to swap the order of concatenation\nand fusing:\n\n@\n    grepCount'' :: IO Int\n    grepCount'' = 'cat' ('enumFile' \\\"\\/usr\\/share\\/dict\\/words\\\")\n                           ('enumFile' \\\"\\/usr\\/share\\/dict\\/extra.words\\\")\n                      '|.' inumToLines\n                  '|$' inumGrep \\\"kk\\\"\n                      '.|' inumGrep \\\"^[a-z]\\\"\n                      '.|' lengthI\n@\n\nThis last version changes the semantics of the counting slightly.\nWith @grepCount''@, if the first file has an incomplete last line,\nthis line will be merged with the first line of the second file, which\nis probably not what you want.  (For instance, if the incomplete last\nline of the first file starts with a capital letter, then the first\nline of the second file will not be counted even if it starts with a\nlower-case letter and contains two \\\"k\\\"s.)\n\nOne limitation of all the @grepCount@ variants shown so far is that if\nthe first file does not exist, the whole operation aborts.  This\nmight or might not be reasonable when counting lines, but in other\ncontexts we may want to resume after failure.  Suppose we want to\nimplement a function like the Unix @grep@ command that searches for a\nstring in a bunch of files and prints all matching lines.  If opening\nor reading a file produces an error, the function should print the\nerror message and continue on with the next file.\n\nError handling is provided by the 'catchI' and 'inumCatch' functions,\nwhich are roughly equivalent to the standard library @'catch'@\nfunction.  There is also a 'throwI' function analogous to @'throwIO'@\nin the standard library.  Because @'catch'@ only works in the IO\nmonad, 'catchI' and 'inumCatch' work by propagating synchronous\nexceptions through the 'Iter' monad.  @'liftIO'@ transforms IO errors\ninto such synchronous exceptions.  Unfortunately, there is no way to\nhandle asynchronous exceptions such as those that arise in lazily\nevaluated pure code (e.g., divide by zero) or those thrown by another\nthread using @'throwTo'@.  Fortunately, for our @grep@ example, we\nonly need to catch IO errors.\n\nHere is the @grep@ code.  We will analyze it below.\n\n@\n    grep :: String -> [FilePath] -> IO ()\n    grep re files\n        | null files = 'enumStdin' '|.' inumToLines '|$' inumGrep re '.|' linesOutI\n        | otherwise  = foldr1 'cat' (map enumLines files) '|$' inumGrep re '.|' linesOutI\n        where\n          enumLines file = 'inumCatch' ('enumFile' file '|.' inumToLines) handler\n          handler :: 'IOError'\n                  -> 'IterR' () IO ('IterR' [S.ByteString] IO a)\n                  -> 'Iter' () IO ('IterR' [S.ByteString] IO a)\n          handler e result = do\n            liftIO (hPutStrLn stderr $ show e)\n            'resumeI' result\n          linesOutI = do\n            mline <- 'safeHeadI'\n            case mline of\n              Just line -> do liftIO $ S.putStrLn line\n                              linesOutI\n              Nothing -> return ()\n@\n\nThere are two cases.  If the list of files to search is null, @grep@\nsimply reads from standard input, in which case there is only one\ninput stream and we do not care about resuming.  In the second case,\nwe use @'foldr1' 'cat'@ to concatenate a list of 'Onum's.  Each 'Onum'\nis generated by the function @enumLines@, which fuses 'enumFile' to\nour previously defined @inumToLines@, but also wraps the exception\nhandler function @handler@ around the enumerator using 'inumCatch'.\n\nNote that unlike @catch@, 'inumCatch' expects an exception handler to\nhave /two/ arguments.  The first argument, @e@ in this example, is the\nexception itself.  As with @catch@, the type of @e@ determines which\nexceptions are caught, which is why we must either specify an explicit\ntype signature for @handler@ or somewhere specify @e@'s type\nexplicitly, for instance with:\n\n>          ...\n>            liftIO (hPutStrLn stderr $ show (e :: IOError))\n>          ...\n\nNote that 'IOError' doesn't expose a type constructor, but for\nexception types that do, it often suffices to define the function with\nthe exception constructor, as:\n\n>          handler e@(SomeException _) result = do ...\n\nThe second argument to @handler@, @result@, is the failed state of the\niteratee, which contains more information than just the exception.  In\nthe case of an 'Inum' failure, it contains the state of the 'Iter'\nthat the 'Inum' was feeding when it failed.  The type of 'result' is\n'IterR'--which is the type returned by 'Iter's when they are fed\nchunks of data.  'IterR' takes the same three type arguments as\n'Iter'.  The function 'resumeI' extracts and returns an @'Iter'\n[S.ByteString] IO a@ from this failed result.  Thus, the next\nenumerator in a concatenated series can continue feeding it input.\nIf, instead of resuming, you want to re-throw the error, it suffices\nto re-execute the failed result with @'reRunIter'@.  For instance,\nsuppose we want to continue executing @grep@ when a named file does\nnot exist, but if some other error happens, we want to re-throw the\nexception to abort the whole program.  This could be achieved as\nfollows:\n\n>          handler e result = do\n>            if isDoesNotExistError e\n>              then do liftIO (hPutStrLn stderr $ show e)\n>                      resumeI result\n>              else reRunIter result\n\nBecause printing an exception is so common, there is a function\n'verboseResumeI' that prints exceptions before resuming (also\nprefixing the program name).  Thus, we can simplify the above function\nto:\n\n>          handler e result = if isDoesNotExistError e\n>                               then verboseResumeI result\n>                               else reRunIter result\n\nThese last two @handler@ functions also do away with the need for an\nexplicit type signature, because the function @'isDoesNotExistError'@\nhas argument type 'IOError', constraining the type of @e@ to the type\nof exceptions we want to catch.\n\n-}",
    AnnBlockComment "{- $Overview\n\n   At a high level, an iteratee is a data sink that is fed chunks of\n   data.  It may return a useful result, or its utility may lie in\n   monadic side-effects, such as storing received data to a file.\n   Iteratees are represented by the type @'Iter' t m a@.  Here @t@ is\n   the type of data that the iteratee receives as input.  (@t@ must be\n   an instance of 'ChunkData', such as 'String' or lazy @ByteString@.)\n   @m@ is the 'Monad' in which the iteratee runs--for instance 'IO'\n   (or an instance of 'MonadIO') for the iteratee to perform IO.  @a@\n   is the type that the iteratee will return when it has consumed\n   enough input to produce a result.\n\n   An enumerator is a data source that feeds data chunks to an\n   iteratee.  Enumerators are also iteratees.  We use the type @'Inum'\n   tIn tOut m a@ to represent these /iteratee-enumerators/.  As an\n   iteratee, an 'Inum' sinks data of some input type, generally\n   designated @tIn@.  As an enumerator, the 'Inum' feeds data of a\n   potentially different type, @tOut@, to another iteratee.  Thus, the\n   'Inum' can be viewed as transcoding data from type @tIn@ to type\n   @tOut@ for consumption by another iteratee.\n\n   'Inum's are generally constructed using the functions @'mkInum'@\n   and @'mkInumM'@ in module \"Data.IterIO.Inum\".  The first function\n   uses a simple @'Iter' tIn m tOut@ to translate between input type\n   @tIn@ and output type @tOut@.  The second function, @'mkInumM'@,\n   allows construction of more complex 'Inum's.\n\n   An important special kind of 'Inum' is an /outer enumerator/,\n   which is just an 'Inum' with the void input type @()@.  Outer\n   enumerators are sources of data.  Rather than transcode input\n   data, they produce data from monadic actions (or from pure data\n   in the case of 'inumPure').  The type 'Onum' represents outer\n   enumerators and is a synonym for 'Inum' with an input type of\n   @()@.\n\n   To execute iteratee-based IO, you must apply an 'Onum' to an\n   'Iter' with the '|$' (\\\"pipe apply\\\") binary operator.\n\n   An important property of enumerators and iteratees is that they can\n   be /fused/.  The '|.' (\\\"fuse leftward\\\") operator fuses two\n   'Inum's together (provided the output type of the first is the\n   input type of the second), yielding a new 'Inum' that transcodes\n   from the input type of the first to the output type of the second.\n   Similarly, the '.|' (\\\"fuse rightward\\\") operator fuses an 'Inum'\n   to an 'Iter', yielding a new 'Iter' with a potentially different\n   input type.\n\n   Enumerators of the same type can also be /concatenated/, using\n   the 'cat' function.  @enum1 ``cat`` enum2@ produces an enumerator\n   whose effect is to feed first @enum1@'s data then @enum2@'s data\n   to an 'Iter'.\n-}",
    AnnBlockComment "{- |\n\nThis is the main module to import for the IterIO package.  It\nre-exports several other modules and mostly consists of\ndocumentation--first a high-level overview of the iteratee model, then\na more detailed tutorial, finally a discussion of the differences from\nother iteratee packages and acknowledgments.\n\nSee the \"Data.IterIO.Iter\", \"Data.IterIO.Inum\", and\n\"Data.IterIO.ListLike\" modules for more detailed documentation of data\nstructures and functions.  In addition, \"Data.IterIO.Trans\" (also\nre-exported by this module) supplies functions that help you invoke\nmonad transformers from the mtl library from within the 'Iter' monad.\n\nSeveral other potentially useful modules in the package are not\nexported by default:\n\n * \"Data.IterIO.Parse\" includes parsec-like parsing combinators for\n   iteratee input.\n\n * \"Data.IterIO.Zlib\" provides zlib and gzip format compression and\n   decompression.\n\n * \"Data.IterIO.SSL\" provides support for SSL.\n\n * \"Data.IterIO.Http\" provides support for parsing and formatting\n   HTTP, including handling form and file uploads (which can be\n   processed in constant space).  This may be useful in conjunction\n   with \"Data.IterIO.HttpRoute\", which provides simple request routing\n   support for web servers.\n\n * \"Data.IterIO.Atto\" provides support for running attoparsec parsers\n   on iteratee input (see\n   <http://hackage.haskell.org/package/attoparsec/>).\n\n * \"Data.IterIO.Extra\" provides debugging functions, as well as a\n   loopback iteratee that can be used to test a protocol\n   implementation against itself.\n\n-}",
    AnnBlockComment "{-# LANGUAGE Safe #-}",
    AnnBlockComment "{-# LANGUAGE CPP #-}"])])