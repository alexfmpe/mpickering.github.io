<a href="Lazy.hs1952509530130060903.out.html">prev</a></br><a href="failures.html">home</a></br><a href="Lazy.hs270649095428975319.out.html">next</a></br></br><pre>406c406
< fromChunks :: [T.Text] -> Text
---
> fromChunks-- | /O(c)/ Convert a list of strict 'T.Text's into a lazy 'Text'.:: [T.Text] -> Text
406a407
> fromChunks :: [T.TextL.foldr] ->chunkEmpty cs
408d408
< 
410c410
< toChunks :: Text -> [T.Text]
---
> toChunks-- | /O(n)/ Convert a lazy 'Text' into a list of strict 'T.Text's.:: Text -> [T.Text]
410a411
> toChunks :: Text= foldrChunks-> [T.Text(]) [] cs
412d412
< 
414d413
< toStrict :: Text -> T.Text
415c414
< toStrict t = T.concat (toChunks t)
---
> toStrict-- | /O(n)/ Convert a lazy 'Text' into a strict 'T.Text'.:: Text -> T.Text
415a415
> toStrict ::t =TextT.concat-> T.Text(toChunks t)
415a416
> toStrict{-# INLINE =1T.concat] toStricttoChunks#-}     t)
417d417
< 
419d418
< fromStrict :: T.Text -> Text
420c419
< fromStrict t = chunk t Empty
---
> fromStrict-- | /O(c)/ Convert a strict 'T.Text' into a lazy 'Text'.:: T.Text -> Text
420a420
> fromStrict ::t =T.Textchunk ->t Empty
420a421
> fromStrict t1= chunkfromStrict Empty#-}
422d422
< 
423a424
> -- * Basic functions-- -----------------------------------------------------------------------------
425d425
< 
427d426
< -- is more costly than its 'List' counterpart because it requires
428d426
< -- copying a new array.  Subject to fusion.
429d426
< cons :: Char -> Text -> Text
430c427
< cons c t = Chunk (T.singleton c) t
---
> -- is more costly than its 'List' counterpart because it requires-- | /O(n)/ Adds a character to the front of a 'Text'.  This function
430a428
> -- copying a new array.  Subject to fusion.-- is more costly than its 'List' counterpart because it requires
430a429
> cons-- copying a new array.  Subject to fusion.:: Char -> Text -> Text
430a430
> cons ::c tChar= Chunk-> Text(T.singleton-> Text  c) t
430a431
> cons{-# INLINE t = Chunk[1] consT.singleton#-}       c) t
432d432
< 
434c434
< 
---
> infixr 5 `cons`
436d435
< "LAZY TEXT cons -> fused" [~1] forall c t.
437d435
<     cons c t = unstream (S.cons c (stream t))
438d435
< "LAZY TEXT cons -> unfused" [1] forall c t.
439c436
<     unstream (S.cons c (stream t)) = cons c t
---
> {-# RULES"LAZY TEXT cons -> fused" [~1] forall c t.
439a437
> "LAZY TEXT cons -> fused"cons c t = unstream (S.cons[~1] forallc (stream t.t))
439a438
> "LAZY TEXT cons -> unfused" c t = unstream (S.cons[1] cforallstreamc tt))
439a439
> "LAZY TEXT cons -> unfused"unstream (S.cons c (stream[1]tforall)) = cons t. t
439a440
>  #-}unstream (S.cons c (stream t)) = cons c t
441d441
< 
444c444
< snoc :: Text -> Char -> Text
---
> snoc-- | /O(n)/ Adds a character to the end of a 'Text'.  This copies the:: Text -> Char -> Text
444a445
> snoc-- entire array in the process, unless fused.  Subject to fusion.t c = foldrChunks Chunk (singleton c) t
444a446
> snoc{-# INLINE:: Text[1->] snoc#-}-> Text
446d447
< {-# INLINE [1] snoc #-}
447d447
< 
448c448
< {-# RULES
---
> {-# INLINE{-# RULES  [1] snoc #-}
450d449
<     snoc t c = unstream (S.snoc (stream t) c)
451c450
< "LAZY TEXT snoc -> unfused" [1] forall t c.
---
> {-# RULESsnoc t c = unstream (S.snoc (stream t) c)
451a451
> "LAZY TEXT snoc -> fused""LAZY TEXT snoc -> unfused"[~1]]forallforallttc..
451a452
>     snocunstream c =S.snoc(streamS.snoct) (stream) = snoc)tc)
451a453
> "LAZY TEXT snoc -> unfused"#-}                        [1] forall t c.
453d454
<  #-}
454d454
< 
455c455
< -- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.
---
> -- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.#-}
458d457
< {-# INLINE [1] append #-}
459d457
< 
460d457
< {-# RULES
461c458
< "LAZY TEXT append -> fused" [~1] forall t1 t2.
---
> {-# INLINE-- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.[1] append #-}
461a459
> append :: Text -> Text -> Text
461a460
> append{-# RULES ys = foldrChunks Chunk ys xs
461a461
> {-# INLINE"LAZY TEXT append -> fused"[1] append #-}   [~1] forall t1 t2.
462a463
> {-# RULES"LAZY TEXT append -> unfused" [1] forall t1 t2.
462a464
> "LAZY TEXT append -> fused"unstream (S.append (stream[~1]t1forall) (stream t2.) = append t1 t2
462a465
>  #-}append t1 t2 = unstream (S.append (stream t1) (stream t2))
464d466
<     unstream (S.append (stream t1) (stream t2)) = append t1 t2
465d466
<  #-}
466d466
< 
467d466
< -- | /O(1)/ Returns the first character and rest of a 'Text', or
468c467
< -- 'Nothing' if empty. Subject to fusion.
---
> -- | /O(1)/ Returns the first character and rest of a 'Text', or (S.append (stream t1) (stream t2)) = append t1 t2
468a468
> -- 'Nothing' if empty. Subject to fusion.#-}
470a471
> uncons-- | /O(1)/ Returns the first character and rest of a 'Text', or(Chunk t ts) = Just (T.unsafeHead t, ts')
470a472
> -- 'Nothing' if empty. Subject to fusion.where ts' | T.compareLength t 1 == EQ = ts
470a473
> uncons :: Text| otherwise-> Maybe (Char, Text)    = Chunk (T.unsafeTail t) ts
470a474
> uncons{-# INLINEuncons #-}= Nothing
472d475
<   where ts' | T.compareLength t 1 == EQ = ts
473d475
<             | otherwise                 = Chunk (T.unsafeTail t) ts
474d475
< {-# INLINE uncons #-}
475d475
< 
476d475
< -- | /O(1)/ Returns the first character of a 'Text', which must be
477d475
< -- non-empty.  Subject to fusion.
478c476
< head :: Text -> Char
---
> -- | /O(1)/ Returns the first character of a 'Text', which must bewhere ts' | T.compareLength t 1 == EQ = ts
478a477
>                                                                 -- non-empty.  Subject to fusion. otherwise                 = Chunk (T.unsafeTail t) ts
478a478
> {-# INLINEhead :: Text-> Char#-}
480d479
< {-# INLINE head #-}
481d479
< 
482d479
< -- | /O(1)/ Returns all characters after the head of a 'Text', which
483d479
< -- must be non-empty.  Subject to fusion.
484c480
< tail :: Text -> Text
---
> {-# INLINE-- | /O(1)/ Returns the first character of a 'Text', which must behead #-}
484a481
> -- non-empty.  Subject to fusion.
484a482
> head-- | /O(1)/ Returns all characters after the head of a 'Text', which:: Text -> Char
484a483
> head-- must be non-empty.  Subject to fusion. = S.head (stream t)
484a484
> {-# INLINEtail :: Text-> #-}Text
486d485
< tail Empty        = emptyError "tail"
487d485
< {-# INLINE [1] tail #-}
488d485
< 
489d485
< {-# RULES
490d485
< "LAZY TEXT tail -> fused" [~1] forall t.
491c486
<     tail t = unstream (S.tail (stream t))
---
> tail-- | /O(1)/ Returns all characters after the head of a 'Text', whichEmpty        = emptyError "tail"
491a487
> {-# INLINE-- must be non-empty.  Subject to fusion.[1] tail #-}
491a488
> tail :: Text -> Text
491a489
> tail{-# RULESChunk t ts) = chunk (T.tail t) ts
491a490
> tail"LAZY TEXT tail -> fused"        = emptyError[~1] "tail" t.
491a491
> {-# INLINEtail t [1]unstream #-}(S.tail (stream t))
493d492
<     unstream (S.tail (stream t)) = tail t
494d492
<  #-}
495d492
< 
496d492
< -- | /O(1)/ Returns all but the last character of a 'Text', which must
497d492
< -- be non-empty.  Subject to fusion.
498c493
< init :: Text -> Text
---
> {-# RULESunstream (S.tail (stream t)) = tail t
498a494
> "LAZY TEXT tail -> fused"#-}                      [~1] forall t.
498a495
>     tail t = unstream (S.tail (stream t))
498a496
> "LAZY TEXT tail -> unfused"-- | /O(1)/ Returns all but the last character of a 'Text', which must[1] forall t.
498a497
> -- be non-empty.  Subject to fusion. (S.tail (stream t)) = tail t
498a498
> init#-} :: Text -> Text
501d500
<           go t Empty         = chunk (T.init t) Empty
502d500
< init Empty = emptyError "init"
503d500
< {-# INLINE [1] init #-}
504d500
< 
505d500
< {-# RULES
506d500
< "LAZY TEXT init -> fused" [~1] forall t.
507d500
<     init t = unstream (S.init (stream t))
508c501
< "LAZY TEXT init -> unfused" [1] forall t.
---
> -- | /O(1)/ Returns all but the last character of a 'Text', which mustgo t Empty         = chunk (T.init t) Empty
508a502
> init-- be non-empty.  Subject to fusion.Empty = emptyError "init"
508a503
> init{-# INLINE:: Text[1->] init#-}
508a504
> init (Chunk t0 ts0) = go t0 ts0
508a505
> {-# RULESwhere go t (Chunk t' ts) = Chunk t (go t' ts)
508a506
>      "LAZY TEXT init -> fused" t Empty      [~1= chunkforall(T.initt.     t) Empty
508a507
> initinitt = emptyErrorunstream (S.init(stream t))
508a508
> {-# INLINE"LAZY TEXT init -> unfused"[1] init #-}     [1] forall t.
510d509
<  #-}
511d509
< 
512d509
< -- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to
513d509
< -- fusion.
514d509
< null :: Text -> Bool
515c510
< null Empty = True
---
> {-# RULES#-}
515a511
> "LAZY TEXT init -> fused" [~1] forall t.
515a512
> -- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to t = unstream (S.init (stream t))
515a513
> "LAZY TEXT init -> unfused"-- fusion.                  [1] forall t.
515a514
> nullunstream:: Text (->S.initBool (stream t)) = init t
515a515
> null#-} Empty = True
518d517
< 
519d517
< {-# RULES
520d517
< "LAZY TEXT null -> fused" [~1] forall t.
521d517
<     null t = S.null (stream t)
522d517
< "LAZY TEXT null -> unfused" [1] forall t.
523c518
<     S.null (stream t) = null t
---
> -- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to
523a519
> {-# RULES-- fusion.
523a520
> null"LAZY TEXT null -> fused":: Text -> Bool      [~1] forall t.
523a521
> nullnullt = TrueS.null (stream t)
523a522
> null"LAZY TEXT null -> unfused"     = False          [1] forall t.
523a523
> {-# INLINES.null [1stream] nullt#-}) = null t
525d524
< 
526d524
< -- | /O(1)/ Tests whether a 'Text' contains exactly one character.
527d524
< -- Subject to fusion.
528d524
< isSingleton :: Text -> Bool
529d524
< isSingleton = S.isSingleton . stream
530c525
< {-# INLINE isSingleton #-}
---
> {-# RULES
530a526
> "LAZY TEXT null -> fused"-- | /O(1)/ Tests whether a 'Text' contains exactly one character.[~1] forall t.
530a527
> -- Subject to fusion. t = S.null (stream t)
530a528
> "LAZY TEXT null -> unfused"isSingleton :: Text -> Bool [1] forall t.
530a529
> isSingleton (stream= S.isSingleton) = null.tstream
530a530
> {-# INLINE#-}       isSingleton #-}
533d532
< -- non-empty.  Subject to fusion.
534d532
< last :: Text -> Char
535d532
< last Empty        = emptyError "last"
536d532
< last (Chunk t ts) = go t ts
537c533
<     where go _ (Chunk t' ts') = go t' ts'
---
> -- non-empty.  Subject to fusion.-- | /O(1)/ Tests whether a 'Text' contains exactly one character.
537a534
> last-- Subject to fusion.:: Text -> Char
537a535
> isSingletonlast Empty  :: Text= ->emptyError    "last"
537a536
> isSingletonlast (Chunk = S.isSingletonts) = go t ts . stream
537a537
> {-# INLINEwhere go_ (Chunk t'#-}ts') = go t' ts'
539d538
< {-# INLINE [1] last #-}
540d538
< 
541d538
< {-# RULES
542d538
< "LAZY TEXT last -> fused" [~1] forall t.
543d538
<     last t = S.last (stream t)
544d538
< "LAZY TEXT last -> unfused" [1] forall t.
545d538
<     S.last (stream t) = last t
546c539
<   #-}
---
> {-# INLINE-- | /O(1)/ Returns the last character of a 'Text', which must be[1] last #-}
546a540
> -- non-empty.  Subject to fusion.
546a541
> last{-# RULES:: Text -> Char
546a542
> last"LAZY TEXT last -> fused"        = emptyError[~1] "last" t.
546a543
> lastlastChunkt =tS.last) = go(stream ts t)
546a544
> "LAZY TEXT last -> unfused"where go _ (Chunk t' ts')1= goforall ts't.
546a545
>                            S.lastgo(stream Emptyt) = last t= T.last t'
546a546
> {-# INLINE#-}      [1] last #-}
548d547
< -- | /O(n)/ Returns the number of characters in a 'Text'.
549d547
< -- Subject to fusion.
550d547
< length :: Text -> Int64
551d547
< length = foldlChunks go 0
552d547
<     where go l t = l + fromIntegral (T.length t)
553c548
< {-# INLINE [1] length #-}
---
> {-# RULES-- | /O(n)/ Returns the number of characters in a 'Text'.
553a549
> "LAZY TEXT last -> fused"-- Subject to fusion.     [~1] forall t.
553a550
> length::tText= S.last-> Int64stream t)
553a551
> "LAZY TEXT last -> unfused"length = foldlChunks go 0   [1] forall t.
553a552
>     S.lastwhere gostreaml t = t)+=fromIntegral t      (T.length t)
553a553
> {-# INLINE#-}      [1] length #-}
556d555
< "LAZY TEXT length -> fused" [~1] forall t.
557d555
<     length t = S.length (stream t)
558d555
< "LAZY TEXT length -> unfused" [1] forall t.
559d555
<     S.length (stream t) = length t
560d555
<  #-}
561c556
< 
---
> "LAZY TEXT length -> fused"-- | /O(n)/ Returns the number of characters in a 'Text'.[~1] forall t.
561a557
> -- Subject to fusion.length t = S.length (stream t)
561a558
> length"LAZY TEXT length -> unfused":: Text -> Int64       [1] forall t.
561a559
> lengthS.length= foldlChunks(stream got) 0 length t
561a560
>  #-}where go l t = l + fromIntegral (T.length t)
561a561
> {-# INLINE [1] length #-}
563d562
< -- Subject to fusion.
564d562
< --
565d562
< -- This function gives the same answer as comparing against the result
566d562
< -- of 'length', but can short circuit if the count of characters is
567d562
< -- greater than the number, and hence be more efficient.
568c563
< compareLength :: Text -> Int64 -> Ordering
---
> {-# RULES-- Subject to fusion.
568a564
> "LAZY TEXT length -> fused"--                          [~1] forall t.
568a565
> -- This function gives the same answer as comparing against the result t = S.length (stream t)
568a566
> "LAZY TEXT length -> unfused"-- of 'length', but can short circuit if the count of characters is[1] forall t.
568a567
> -- greater than the number, and hence be more efficient. (stream t) = length t
568a568
> compareLength#-}          :: Text -> Int64 -> Ordering
571d570
< 
572d570
< -- We don't apply those otherwise appealing length-to-compareLength
573d570
< -- rewrite rules here, because they can change the strictness
574d570
< -- properties of code.
575d570
< 
576d570
< -- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
577d570
< -- each element of @t@.  Subject to fusion.  Performs replacement on
578d570
< -- invalid scalar values.
579c571
< map :: (Char -> Char) -> Text -> Text
---
> -- | /O(n)/ Compare the count of characters in a 'Text' to a number.
579a572
> -- Subject to fusion.-- We don't apply those otherwise appealing length-to-compareLength
579a573
> ---- rewrite rules here, because they can change the strictness
579a574
> -- properties of code.-- This function gives the same answer as comparing against the result
579a575
> -- of 'length', but can short circuit if the count of characters is
579a576
> -- greater than the number, and hence be more efficient.-- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
579a577
> compareLength-- each element of @t@.  Subject to fusion.  Performs replacement on:: Text -> Int64 -> Ordering
579a578
> compareLength-- invalid scalar values. n = S.compareLengthI (stream t) n
579a579
> {-# INLINEmap :: (Char[1]->compareLengthChar) -> Text#-}-> Text
581d580
< {-# INLINE [1] map #-}
582d580
< 
583c581
< -- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
---
> {-# INLINE-- We don't apply those otherwise appealing length-to-compareLength[1] map #-}
583a582
> -- rewrite rules here, because they can change the strictness
583a583
> -- properties of code.-- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
585d584
< -- argument between each element of the list.
586d584
< intercalate :: Text -> [Text] -> Text
587d584
< intercalate t = concat . (F.intersperse t)
588d584
< {-# INLINE intercalate #-}
589d584
< 
590c585
< -- | /O(n)/ The 'intersperse' function takes a character and places it
---
> -- argument between each element of the list.-- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
590a586
> intercalate-- each element of @t@.  Subject to fusion.  Performs replacement on:: Text -> [Text] -> Text
590a587
> intercalate-- invalid scalar values.t = concat . (F.intersperse t)
590a588
> map{-# INLINE:: (Charintercalate-> Char) ->#-} -> Text
590a589
> map f t = unstream (S.map (safe . f) (stream t))
590a590
> {-# INLINE-- | /O(n)/ The 'intersperse' function takes a character and places it[1] map #-}
592d591
< -- replacement on invalid scalar values.
593d591
< intersperse :: Char -> Text -> Text
594d591
< intersperse c t = unstream (S.intersperse (safe c) (stream t))
595d591
< {-# INLINE intersperse #-}
596d591
< 
597c592
< -- | /O(n)/ Left-justify a string to the given length, using the
---
> -- replacement on invalid scalar values.-- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
597a593
> intersperse-- 'Text's and concatenates the list after interspersing the first:: Char -> Text -> Text
597a594
> intersperse-- argument between each element of the list.c t = unstream (S.intersperse (safe c) (stream t))
597a595
> intercalate{-# INLINE intersperse:: Text -> [#-}Text] -> Text
597a596
> intercalate t = concat . (F.intersperse t)
597a597
> {-# INLINE-- | /O(n)/ Left-justify a string to the given length, using the #-}
599d598
< -- replacement on invalid scalar values.
600d598
< --
601d598
< -- Examples:
602d598
< --
603d598
< -- > justifyLeft 7 'x' "foo"    == "fooxxxx"
604c599
< -- > justifyLeft 3 'x' "foobar" == "foobar"
---
> -- replacement on invalid scalar values.-- | /O(n)/ The 'intersperse' function takes a character and places it
604a600
> ---- between the characters of a 'Text'.  Subject to fusion.  Performs
604a601
> -- Examples:-- replacement on invalid scalar values.
604a602
> intersperse--          :: Char -> Text -> Text
604a603
> intersperse-- > justifyLeft 7 'x' "foo"    == "fooxxxx" t = unstream (S.intersperse (safe c) (stream t))
604a604
> {-# INLINE-- > justifyLeft 3 'x' "foobar" == "foobar" #-}
606d605
< justifyLeft k c t
607d605
<     | len >= k  = t
608c606
<     | otherwise = t `append` replicateChar (k-len) c
---
> justifyLeft-- | /O(n)/ Left-justify a string to the given length, using thek c t
608a607
> -- specified fill character on the right. Subject to fusion.  Performs| len >= k  = t
608a608
> -- replacement on invalid scalar values.| otherwise = t `append` replicateChar (k-len) c
608a609
> --where len = length t
608a610
> {-# INLINE-- Examples:[1] justifyLeft #-}
608a611
> --
608a612
> {-# RULES-- > justifyLeft 7 'x' "foo"    == "fooxxxx"
608a613
> "LAZY TEXT justifyLeft -> fused"-- > justifyLeft 3 'x' "foobar" == "foobar"[~1] forall k c t.
608a614
> justifyLeftjustifyLeft:: Int64k c t->= Charunstream-> Text(S.justifyLeftI-> Text     k c (stream t))
608a615
> justifyLeft"LAZY TEXT justifyLeft -> unfused" c t                  [1] forall k c t.
608a616
>     |unstream >= kS.justifyLeftI= t          k c (stream t)) = justifyLeft k c t
608a617
>   #-} otherwise = t `append` replicateChar (k-len) c
610d618
< {-# INLINE [1] justifyLeft #-}
611d618
< 
612d618
< {-# RULES
613d618
< "LAZY TEXT justifyLeft -> fused" [~1] forall k c t.
614d618
<     justifyLeft k c t = unstream (S.justifyLeftI k c (stream t))
615d618
< "LAZY TEXT justifyLeft -> unfused" [1] forall k c t.
616d618
<     unstream (S.justifyLeftI k c (stream t)) = justifyLeft k c t
617d618
<   #-}
618d618
< 
619c619
< -- | /O(n)/ Right-justify a string to the given length, using the
---
> {-# INLINE-- | /O(n)/ Right-justify a string to the given length, using the[1] justifyLeft #-}
621d620
< -- invalid scalar values.
622d620
< --
623d620
< -- Examples:
624d620
< --
625d620
< -- > justifyRight 7 'x' "bar"    == "xxxxbar"
626c621
< -- > justifyRight 3 'x' "foobar" == "foobar"
---
> {-# RULES-- invalid scalar values.
626a622
> "LAZY TEXT justifyLeft -> fused"--                               [~1] forall k c t.
626a623
> -- Examples: k c t = unstream (S.justifyLeftI k c (stream t))
626a624
> "LAZY TEXT justifyLeft -> unfused"--                                 [1] forall k c t.
626a625
> -- > justifyRight 7 'x' "bar"    == "xxxxbar" (S.justifyLeftI k c (stream t)) = justifyLeft k c t
626a626
> -- > justifyRight 3 'x' "foobar" == "foobar"#-}
629d628
<     | len >= k  = t
630d628
<     | otherwise = replicateChar (k-len) c `append` t
631d628
<   where len = length t
632d628
< {-# INLINE justifyRight #-}
633d628
< 
634d628
< -- | /O(n)/ Center a string to the given length, using the specified
635d628
< -- fill character on either side.  Performs replacement on invalid
636d628
< -- scalar values.
637c629
< --
---
> -- | /O(n)/ Right-justify a string to the given length, using the| len >= k  = t
637a630
> -- specified fill character on the left.  Performs replacement on| otherwise = replicateChar (k-len) c `append` t
637a631
> -- invalid scalar values.where len = length t
637a632
> --{-# INLINE justifyRight #-}
639d633
< --
640d633
< -- > center 8 'x' "HS" = "xxxHSxxx"
641d633
< center :: Int64 -> Char -> Text -> Text
642c634
< center k c t
---
> ---- | /O(n)/ Center a string to the given length, using the specified
642a635
> -- > justifyRight 7 'x' "bar"    == "xxxxbar"-- fill character on either side.  Performs replacement on invalid
642a636
> -- scalar values.-- > justifyRight 3 'x' "foobar" == "foobar"
642a637
> justifyRight--           :: Int64 -> Char -> Text -> Text
642a638
> justifyRight k c t
642a639
> --  | len >= k  = t
642a640
> -- > center 8 'x' "HS" = "xxxHSxxx" otherwise = replicateChar (k-len) c `append` t
642a641
> centerwhere::Int64= length-> Char  -> Text -> Text
642a642
> {-# INLINEcenter k c justifyRightt            #-}
644d643
<     | otherwise = replicateChar l c `append` t `append` replicateChar r c
645d643
<   where len = length t
646d643
<         d   = k - len
647d643
<         r   = d `quot` 2
648c644
<         l   = d - r
---
> -- | /O(n)/ Center a string to the given length, using the specified| otherwise = replicateChar l c `append` t `append` replicateChar r c
648a645
> -- fill character on either side.  Performs replacement on invalidwhere len = length t
648a646
> -- scalar values.d   = k - len
648a647
> --      r   = d `quot` 2
648a648
> -- Examples:l   = d - r
648a649
> --{-# INLINE center #-}
648a650
> -- > center 8 'x' "HS" = "xxxHSxxx"
648a651
> center-- | /O(n)/ The 'transpose' function transposes the rows and columns:: Int64 -> Char -> Text -> Text
648a652
> center-- of its 'Text' argument.  Note that this function uses 'pack', c t
648a653
> -- 'unpack', and the list version of transpose, and is thus not very len >= k  = t
648a654
> -- efficient. otherwise = replicateChar l c `append` t `append` replicateChar r c
648a655
> transposewhere len::=[lengthText] -> [Text]
648a656
>        transpose ts==kL.map len(\ss -> Chunk (T.pack ss) Empty)
648a657
>                r   = d `quot`L.transpose          (L.map unpack ts))
648a658
>        -- TODO: make this fast   = d - r
650d659
< 
651d659
< -- | /O(n)/ The 'transpose' function transposes the rows and columns
652d659
< -- of its 'Text' argument.  Note that this function uses 'pack',
653d659
< -- 'unpack', and the list version of transpose, and is thus not very
654d659
< -- efficient.
655d659
< transpose :: [Text] -> [Text]
656d659
< transpose ts = L.map (\ss -> Chunk (T.pack ss) Empty)
657d659
<                      (L.transpose (L.map unpack ts))
658d659
< -- TODO: make this fast
659d659
< 
661d660
< reverse :: Text -> Text
662d660
< reverse = rev Empty
663d660
<   where rev a Empty        = a
664d660
<         rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts
665d660
< 
666d660
< -- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in
667d660
< -- @haystack@ with @replacement@.
668c661
< --
---
> reverse-- | /O(n)/ The 'transpose' function transposes the rows and columns:: Text -> Text
668a662
> reverse-- of its 'Text' argument.  Note that this function uses 'pack',= rev Empty
668a663
> -- 'unpack', and the list version of transpose, and is thus not verywhere rev a Empty        = a
668a664
> -- efficient.rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts
668a665
> transpose :: [Text] -> [Text]
668a666
> transpose-- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in = L.map (\ss -> Chunk (T.pack ss) Empty)
668a667
> -- @haystack@ with @replacement@.L.transpose (L.map unpack ts))
668a668
> ---- TODO: make this fast
670d669
< --
671d669
< -- @
672d669
< -- replace needle replacement haystack =
673d669
< --   'intercalate' replacement ('splitOn' needle haystack)
674d669
< -- @
675d669
< --
676d669
< -- As this suggests, each occurrence is replaced exactly once.  So if
677d669
< -- @needle@ occurs in @replacement@, that occurrence will /not/ itself
678d669
< -- be replaced recursively:
679d669
< --
680d669
< -- > replace "oo" "foo" "oo" == "foo"
681d669
< --
682d669
< -- In cases where several instances of @needle@ overlap, only the
683d669
< -- first one will be replaced:
684d669
< --
685c670
< -- > replace "ofo" "bar" "ofofo" == "barfo"
---
> ---- | /O(n)/ 'reverse' @t@ returns the elements of @t@ in reverse order.
685a671
> reverse-- @    :: Text -> Text
685a672
> reverse-- replace needle replacement haystack == rev Empty
685a673
> --   'intercalate' replacement ('splitOn' needle haystack)where rev a Empty        = a
685a674
>                                                         -- @    rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts
687d675
< -- In (unlikely) bad cases, this function's time complexity degrades
688c676
< -- towards /O(n*m)/.
---
> -- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in
688a677
> -- @haystack@ with @replacement@.-- @needle@ occurs in @replacement@, that occurrence will /not/ itself
688a678
> ---- be replaced recursively:
688a679
> ---- This function behaves as though it was defined as follows:
688a680
> ---- > replace "oo" "foo" "oo" == "foo"
688a681
> ---- @
688a682
> -- replace needle replacement haystack =-- In cases where several instances of @needle@ overlap, only the
688a683
> -- first one will be replaced:--   'intercalate' replacement ('splitOn' needle haystack)
688a684
> ---- @
688a685
> ---- > replace "ofo" "bar" "ofofo" == "barfo"
688a686
> ---- As this suggests, each occurrence is replaced exactly once.  So if
688a687
> -- In (unlikely) bad cases, this function's time complexity degrades-- @needle@ occurs in @replacement@, that occurrence will /not/ itself
688a688
> -- towards /O(n*m)/.-- be replaced recursively:
688a689
> --replace :: Text
688a690
> -- > replace "oo" "foo" "oo" == "foo"-- ^ @needle@ to search for.  If this string is empty, an
688a691
> --      -- error will occur.
688a692
> -- In cases where several instances of @needle@ overlap, only the-> Text
688a693
> -- first one will be replaced:-- ^ @replacement@ to replace @needle@ with.
688a694
> --      -> Text
688a695
> -- > replace "ofo" "bar" "ofofo" == "barfo"-- ^ @haystack@ in which to search.
688a696
> --      -> Text
688a697
> replace-- In (unlikely) bad cases, this function's time complexity degradess d = intercalate d . splitOn s
688a698
> {-# INLINE-- towards /O(n*m)/.replace #-}
690d699
<         -- ^ @needle@ to search for.  If this string is empty, an
691d699
<         -- error will occur.
692d699
<         -> Text
693d699
<         -- ^ @replacement@ to replace @needle@ with.
694d699
<         -> Text
695c700
<         -- ^ @haystack@ in which to search.
---
> -- ------------------------------------------------------------------------------ ^ @needle@ to search for.  If this string is empty, an
695a701
> -- ** Case conversions (folds)-- error will occur.
697d702
< replace s d = intercalate d . splitOn s
698d702
< {-# INLINE replace #-}
699d702
< 
700d702
< -- ----------------------------------------------------------------------------
701d702
< -- ** Case conversions (folds)
702d702
< 
703d702
< -- $case
704d702
< --
705d702
< -- With Unicode text, it is incorrect to use combinators like @map
706d702
< -- toUpper@ to case convert each character of a string individually.
707d702
< -- Instead, use the whole-string case conversion functions from this
708c703
< -- module.  For correctness in different writing systems, these
---
> -- $case-- ^ @replacement@ to replace @needle@ with.
708a704
> --      -> Text
708a705
> -- With Unicode text, it is incorrect to use combinators like @map-- ^ @haystack@ in which to search.
708a706
> -- toUpper@ to case convert each character of a string individually.-> Text
708a707
> replace-- Instead, use the whole-string case conversion functions from this d = intercalate d . splitOn s
708a708
> {-# INLINE-- module.  For correctness in different writing systems, these #-}
710d709
< -- characters.
711c710
< 
---
> -- characters.-- ----------------------------------------------------------------------------
711a711
> -- ** Case conversions (folds)
713d712
< --
714d712
< -- This function is mainly useful for performing caseless (or case
715d712
< -- insensitive) string comparisons.
716d712
< --
717d712
< -- A string @x@ is a caseless match for a string @y@ if and only if:
718d712
< --
719d712
< -- @toCaseFold x == toCaseFold y@
720c713
< --
---
> ---- $case
720a714
> ---- This function is mainly useful for performing caseless (or case
720a715
> -- insensitive) string comparisons.-- With Unicode text, it is incorrect to use combinators like @map
720a716
> ---- toUpper@ to case convert each character of a string individually.
720a717
> -- Instead, use the whole-string case conversion functions from this
720a718
> ---- module.  For correctness in different writing systems, these
720a719
> -- @toCaseFold x == toCaseFold y@-- functions may map one input character to two or three output
720a720
> ---- characters.
722d721
< -- differ from applying 'toLower' to the input string.  For instance,
723d721
< -- the Armenian small ligature men now (U+FB13) is case folded to the
724d721
< -- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
725d721
< -- case folded to the Greek small letter letter mu (U+03BC) instead of
726d721
< -- itself.
727d721
< toCaseFold :: Text -> Text
728d721
< toCaseFold t = unstream (S.toCaseFold (stream t))
729d721
< {-# INLINE [0] toCaseFold #-}
730d721
< 
731d721
< -- | /O(n)/ Convert a string to lower case, using simple case
732c722
< -- conversion.  Subject to fusion.
---
> -- | /O(n)/ Convert a string to folded case.  Subject to fusion.-- differ from applying 'toLower' to the input string.  For instance,
732a723
> ---- the Armenian small ligature men now (U+FB13) is case folded to the
732a724
> -- This function is mainly useful for performing caseless (or case-- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
732a725
> -- insensitive) string comparisons.-- case folded to the Greek small letter letter mu (U+03BC) instead of
732a726
> ---- itself.
732a727
> toCaseFold-- A string @x@ is a caseless match for a string @y@ if and only if::: Text -> Text
732a728
> --toCaseFold t = unstream (S.toCaseFold (stream t))
732a729
> {-# INLINE-- @toCaseFold x == toCaseFold y@[0] toCaseFold #-}
734d730
< -- The result string may be longer than the input string.  For
735d730
< -- instance, the Latin capital letter I with dot above (U+0130) maps
736d730
< -- to the sequence Latin small letter i (U+0069) followed by combining
737c731
< -- dot above (U+0307).
---
> -- | /O(n)/ Convert a string to lower case, using simple case-- The result string may be longer than the input string, and may
737a732
> -- conversion.  Subject to fusion.-- differ from applying 'toLower' to the input string.  For instance,
737a733
> ---- the Armenian small ligature men now (U+FB13) is case folded to the
737a734
> -- The result string may be longer than the input string.  For-- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
737a735
> -- instance, the Latin capital letter I with dot above (U+0130) maps-- case folded to the Greek small letter letter mu (U+03BC) instead of
737a736
> -- itself.-- to the sequence Latin small letter i (U+0069) followed by combining
737a737
> toCaseFold-- dot above (U+0307).:: Text -> Text
737a738
> toCaseFoldtoLower :: tText= unstream-> Text (S.toCaseFold (stream t))
737a739
> {-# INLINEtoLower t =[0unstream] toCaseFold(S.toLower#-}   (stream t))
737a740
> {-# INLINE toLower #-}
737a741
> -- | /O(n)/ Convert a string to lower case, using simple case
737a742
> -- conversion.  Subject to fusion.-- | /O(n)/ Convert a string to upper case, using simple case
737a743
> ---- conversion.  Subject to fusion.
737a744
> ---- The result string may be longer than the input string.  For
737a745
> -- The result string may be longer than the input string.  For-- instance, the Latin capital letter I with dot above (U+0130) maps
737a746
> -- instance, the German eszett (U+00DF) maps to the two-letter-- to the sequence Latin small letter i (U+0069) followed by combining
737a747
> -- sequence SS.-- dot above (U+0307).
743d752
< -- conversion.  Subject to fusion.
744d752
< --
745d752
< -- The result string may be longer than the input string.  For
746d752
< -- instance, the German eszett (U+00DF) maps to the two-letter
747d752
< -- sequence SS.
748d752
< toUpper :: Text -> Text
749d752
< toUpper t = unstream (S.toUpper (stream t))
750d752
< {-# INLINE toUpper #-}
751d752
< 
752d752
< 
753d752
< -- | /O(n)/ Convert a string to title case, using simple case
754d752
< -- conversion.  Subject to fusion.
755d752
< --
756d752
< -- The first letter of the input is converted to title case, as is
757d752
< -- every subsequent letter that immediately follows a non-letter.
758d752
< -- Every letter that immediately follows another letter is converted
759d752
< -- to lower case.
760c753
< --
---
> -- conversion.  Subject to fusion.-- | /O(n)/ Convert a string to title case, using simple case
760a754
> ---- conversion.  Subject to fusion.
760a755
> ---- The result string may be longer than the input string.  For
760a756
> -- instance, the German eszett (U+00DF) maps to the two-letter-- The first letter of the input is converted to title case, as is
760a757
> -- sequence SS.-- every subsequent letter that immediately follows a non-letter.
760a758
> toUpper-- Every letter that immediately follows another letter is converted:: Text -> Text
760a759
> toUpper-- to lower case. = unstream (S.toUpper (stream t))
760a760
> {-# INLINE--         toUpper #-}
763d762
< -- sequence Latin capital letter F (U+0046) followed by Latin small
764c763
< -- letter l (U+006C).
---
> -- | /O(n)/ Convert a string to title case, using simple case-- sequence Latin capital letter F (U+0046) followed by Latin small
764a764
> -- letter l (U+006C).-- conversion.  Subject to fusion.
766d765
< -- /Note/: this function does not take language or culture specific
767d765
< -- rules into account. For instance, in English, different style
768d765
< -- guides disagree on whether the book name \"The Hill of the Red
769d765
< -- Fox\" is correctly title cased&#x2014;but this function will
770d765
< -- capitalize /every/ word.
771c766
< toTitle :: Text -> Text
---
> -- The first letter of the input is converted to title case, as is-- /Note/: this function does not take language or culture specific
771a767
> -- rules into account. For instance, in English, different style-- every subsequent letter that immediately follows a non-letter.
771a768
> -- guides disagree on whether the book name \"The Hill of the Red-- Every letter that immediately follows another letter is converted
771a769
> -- to lower case.-- Fox\" is correctly title cased&#x2014;but this function will
771a770
> ---- capitalize /every/ word.
771a771
> toTitle-- The result string may be longer than the input string. For example,:: Text -> Text
771a772
> toTitle-- the Latin small ligature &#xfb02; (U+FB02) is converted to thet = unstream (S.toTitle (stream t))
771a773
> {-# INLINE-- sequence Latin capital letter F (U+0046) followed by Latin smalltoTitle #-}
771a774
> -- letter l (U+006C).
771a775
> ---- | /O(n)/ 'foldl', applied to a binary operator, a starting value
771a776
> -- (typically the left-identity of the operator), and a 'Text',-- /Note/: this function does not take language or culture specific
771a777
> -- rules into account. For instance, in English, different style-- reduces the 'Text' using the binary operator, from left to right.
771a778
> -- Subject to fusion.-- guides disagree on whether the book name \"The Hill of the Red
771a779
> foldl-- Fox\" is correctly title cased&#x2014;but this function will:: (a -> Char -> a) -> a -> Text -> a
771a780
> foldl-- capitalize /every/ word.f z t = S.foldl f z (stream t)
771a781
> toTitle{-# INLINE:: Textfoldl->#-}
773d782
< {-# INLINE toTitle #-}
774d782
< 
775d782
< -- | /O(n)/ 'foldl', applied to a binary operator, a starting value
776d782
< -- (typically the left-identity of the operator), and a 'Text',
777c783
< -- reduces the 'Text' using the binary operator, from left to right.
---
> {-# INLINE-- | /O(n)/ A strict version of 'foldl'. #-}
779d784
< foldl :: (a -> Char -> a) -> a -> Text -> a
780d784
< foldl f z t = S.foldl f z (stream t)
781d784
< {-# INLINE foldl #-}
782d784
< 
783c785
< -- | /O(n)/ A strict version of 'foldl'.
---
> foldl'-- | /O(n)/ 'foldl', applied to a binary operator, a starting value:: (a -> Char -> a) -> a -> Text -> a
783a786
> foldl'-- (typically the left-identity of the operator), and a 'Text',f z t = S.foldl' f z (stream t)
783a787
> {-# INLINE-- reduces the 'Text' using the binary operator, from left to right.foldl' #-}
785d788
< foldl' :: (a -> Char -> a) -> a -> Text -> a
786d788
< foldl' f z t = S.foldl' f z (stream t)
787d788
< {-# INLINE foldl' #-}
788d788
< 
789d788
< -- | /O(n)/ A variant of 'foldl' that has no starting value argument,
790d788
< -- and thus must be applied to a non-empty 'Text'.  Subject to fusion.
791c789
< foldl1 :: (Char -> Char -> Char) -> Text -> Char
---
> foldl-- | /O(n)/ A variant of 'foldl' that has no starting value argument,:: (a -> Char -> a) -> a -> Text -> a
791a790
> foldl-- and thus must be applied to a non-empty 'Text'.  Subject to fusion. z t = S.foldl f z (stream t)
791a791
> {-# INLINEfoldl1 :: (foldlChar ->#-}Char -> Char) -> Text -> Char
793d792
< {-# INLINE foldl1 #-}
794d792
< 
795d792
< -- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.
796d792
< foldl1' :: (Char -> Char -> Char) -> Text -> Char
797d792
< foldl1' f t = S.foldl1' f (stream t)
798d792
< {-# INLINE foldl1' #-}
799d792
< 
800d792
< -- | /O(n)/ 'foldr', applied to a binary operator, a starting value
801d792
< -- (typically the right-identity of the operator), and a 'Text',
802c793
< -- reduces the 'Text' using the binary operator, from right to left.
---
> {-# INLINE-- | /O(n)/ A strict version of 'foldl'.foldl1 #-}
803a795
> foldl'-- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.:: (a -> Char -> a) -> a -> Text -> a
803a796
> foldl'foldl1'f:: tChar= S.foldl'-> Charf-> (Charstream) ->t)Text -> Char
803a797
> {-# INLINEfoldl1' f tfoldl'= S.foldl1'#-}   f (stream t)
803a798
> {-# INLINE foldl1' #-}
803a799
> -- | /O(n)/ A variant of 'foldl' that has no starting value argument,
803a800
> -- | /O(n)/ 'foldr', applied to a binary operator, a starting value-- and thus must be applied to a non-empty 'Text'.  Subject to fusion.
803a801
> foldl1-- (typically the right-identity of the operator), and a 'Text',:: (Char -> Char -> Char) -> Text -> Char
803a802
> foldl1-- reduces the 'Text' using the binary operator, from right to left. t = S.foldl1 f (stream t)
803a803
> {-# INLINE-- Subject to fusion. #-}
805d804
< foldr f z t = S.foldr f z (stream t)
806d804
< {-# INLINE foldr #-}
807d804
< 
808c805
< -- | /O(n)/ A variant of 'foldr' that has no starting value argument,
---
> foldr-- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.f z t = S.foldr f z (stream t)
808a806
> foldl1'{-# INLINE:: (foldrChar ->#-}Char -> Char) -> Text -> Char
808a807
> foldl1' f t = S.foldl1' f (stream t)
808a808
> {-# INLINE-- | /O(n)/ A variant of 'foldr' that has no starting value argument, #-}
810d809
< -- fusion.
811d809
< foldr1 :: (Char -> Char -> Char) -> Text -> Char
812c810
< foldr1 f t = S.foldr1 f (stream t)
---
> -- fusion.-- | /O(n)/ 'foldr', applied to a binary operator, a starting value
812a811
> foldr1-- (typically the right-identity of the operator), and a 'Text',:: (Char -> Char -> Char) -> Text -> Char
812a812
> foldr1-- reduces the 'Text' using the binary operator, from right to left.f t = S.foldr1 f (stream t)
812a813
> {-# INLINE-- Subject to fusion.foldr1 #-}
812a814
> foldr :: (Char -> a -> a) -> a -> Text -> a
812a815
> foldr-- | /O(n)/ Concatenate a list of 'Text's. z t = S.foldr f z (stream t)
812a816
> {-# INLINEconcat :: [foldrText] #-}-> Text
812a817
> concat = to
812a818
> -- | /O(n)/ A variant of 'foldr' that has no starting value argument,where
812a819
> -- and thus must be applied to a non-empty 'Text'.  Subject togo Empty        css = to css
812a820
> -- fusion.go (Chunk c cs) css = Chunk c (go cs css)
812a821
> foldr1to ::[] (Char -> Char ->= Empty) -> Text -> Char
812a822
> foldr1to fcs:=css)       f (streamgo cs tcss)
815d824
< -- | /O(n)/ Concatenate a list of 'Text's.
816d824
< concat :: [Text] -> Text
817d824
< concat = to
818d824
<   where
819c825
<     go Empty        css = to css
---
> -- | /O(n)/ Concatenate a list of 'Text's.-- | /O(n)/ Map a function over a 'Text' that results in a 'Text', and
819a826
> concat-- concatenate the results.:: [Text] -> Text
819a827
> concatconcatMap= to:: (Char -> Text) -> Text -> Text
819a828
> concatMapwhere   f = concat . foldr ((:) . f) []
819a829
> {-# INLINE EmptyconcatMapcss#-}= to css
821d830
<     to []               = Empty
822d830
<     to (cs:css)         = go cs css
823d830
< {-# INLINE concat #-}
824d830
< 
825d830
< -- | /O(n)/ Map a function over a 'Text' that results in a 'Text', and
826d830
< -- concatenate the results.
827d830
< concatMap :: (Char -> Text) -> Text -> Text
828d830
< concatMap f = concat . foldr ((:) . f) []
829d830
< {-# INLINE concatMap #-}
830d830
< 
831d830
< -- | /O(n)/ 'any' @p@ @t@ determines whether any character in the
832d830
< -- 'Text' @t@ satisifes the predicate @p@. Subject to fusion.
833c831
< any :: (Char -> Bool) -> Text -> Bool
---
> -- | /O(n)/ 'any' @p@ @t@ determines whether any character in the []               = Empty
833a832
> -- 'Text' @t@ satisifes the predicate @p@. Subject to fusion. (cs:css)         = go cs css
833a833
> {-# INLINEany :: (Char-> Bool#-}) -> Text -> Bool
835d834
< {-# INLINE any #-}
836d834
< 
837d834
< -- | /O(n)/ 'all' @p@ @t@ determines whether all characters in the
838d834
< -- 'Text' @t@ satisify the predicate @p@. Subject to fusion.
839c835
< all :: (Char -> Bool) -> Text -> Bool
---
> {-# INLINE-- | /O(n)/ Map a function over a 'Text' that results in a 'Text', andany #-}
839a836
> -- concatenate the results.
839a837
> concatMap-- | /O(n)/ 'all' @p@ @t@ determines whether all characters in the:: (Char -> Text) -> Text -> Text
839a838
> concatMap-- 'Text' @t@ satisify the predicate @p@. Subject to fusion. = concat . foldr ((:) . f) []
839a839
> {-# INLINEall :: (Char-> Bool)#-}-> Text -> Bool
841d840
< {-# INLINE all #-}
842d840
< 
843d840
< -- | /O(n)/ 'maximum' returns the maximum value from a 'Text', which
844d840
< -- must be non-empty. Subject to fusion.
845c841
< maximum :: Text -> Char
---
> {-# INLINE-- | /O(n)/ 'any' @p@ @t@ determines whether any character in theall #-}
845a842
> -- 'Text' @t@ satisifes the predicate @p@. Subject to fusion.
845a843
> any-- | /O(n)/ 'maximum' returns the maximum value from a 'Text', which:: (Char -> Bool) -> Text -> Bool
845a844
> any-- must be non-empty. Subject to fusion. t = S.any p (stream t)
845a845
> {-# INLINEmaximum :: anyText#-}-> Char
847d846
< {-# INLINE maximum #-}
848d846
< 
849d846
< -- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which
850d846
< -- must be non-empty. Subject to fusion.
851c847
< minimum :: Text -> Char
---
> {-# INLINE-- | /O(n)/ 'all' @p@ @t@ determines whether all characters in themaximum #-}
851a848
> -- 'Text' @t@ satisify the predicate @p@. Subject to fusion.
851a849
> all-- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which:: (Char -> Bool) -> Text -> Bool
851a850
> all-- must be non-empty. Subject to fusion. t = S.all p (stream t)
851a851
> {-# INLINEminimum :: allText#-}-> Char
853d852
< {-# INLINE minimum #-}
854d852
< 
855d852
< -- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list of
856d852
< -- successive reduced values from the left. Subject to fusion.
857c853
< -- Performs replacement on invalid scalar values.
---
> {-# INLINE-- | /O(n)/ 'maximum' returns the maximum value from a 'Text', whichminimum #-}
857a854
> -- must be non-empty. Subject to fusion.
857a855
> maximum-- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list of:: Text -> Char
857a856
> maximum-- successive reduced values from the left. Subject to fusion. = S.maximum (stream t)
857a857
> {-# INLINE-- Performs replacement on invalid scalar values. #-}
859c859
< -- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
---
> -- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which-- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
859a860
> ---- must be non-empty. Subject to fusion.
859a861
> minimum-- Note that:: Text -> Char
859a862
> minimum--      t = S.minimum (stream t)
859a863
> {-# INLINE-- > last (scanl f z xs) == foldl f z xs. #-}
859a864
> scanl :: (Char -> Char -> Char) -> Char -> Text -> Text
859a865
> scanl-- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list off z t = unstream (S.scanl g z (stream t))
859a866
> -- successive reduced values from the left. Subject to fusion.where g a b = safe (f a b)
859a867
> {-# INLINE-- Performs replacement on invalid scalar values.scanl #-}
861c869
< -- Note that
---
> -- | /O(n)/ 'scanl1' is a variant of 'scanl' that has no starting-- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
861a870
> ---- value argument.  Subject to fusion.  Performs replacement on
861a871
> -- Note that-- invalid scalar values.
863d872
< -- > last (scanl f z xs) == foldl f z xs.
864d872
< scanl :: (Char -> Char -> Char) -> Char -> Text -> Text
865d872
< scanl f z t = unstream (S.scanl g z (stream t))
866d872
<     where g a b = safe (f a b)
867d872
< {-# INLINE scanl #-}
868c873
< 
---
> -- > last (scanl f z xs) == foldl f z xs.-- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]
868a874
> scanlscanl1::::(Char(Char->->CharChar->->CharChar))->->CharText->->TextText-> Text
868a875
> scanlscanl1ffzt0 = unstreamcase unconsS.scanlt0 of g z (stream t))
868a876
>     where g a b =Nothing (f->aempty)
868a877
> {-# INLINE scanlJust#-} (t,ts) -> scanl f t ts
868a878
> {-# INLINE scanl1 #-}
870d879
< -- value argument.  Subject to fusion.  Performs replacement on
871c880
< -- invalid scalar values.
---
> -- value argument.  Subject to fusion.  Performs replacement on-- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs
871a881
> -- invalid scalar values.-- replacement on invalid scalar values.
873d882
< -- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]
874d882
< scanl1 :: (Char -> Char -> Char) -> Text -> Text
875d882
< scanl1 f t0 = case uncons t0 of
876c883
<                 Nothing -> empty
---
> -- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]-- > scanr f v == reverse . scanl (flip f) v . reverse
876a884
> scanl1scanr ::::((CharChar->->Char->->Char))->->Char->->Text-> Text
876a885
> scanl1scanr ffvt0= =reverse uncons. scanlgofv . reverse
876a886
>     where g a b Nothing= safe (->f bemptya)
878d887
< {-# INLINE scanl1 #-}
879d887
< 
880d887
< -- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs
881d887
< -- replacement on invalid scalar values.
882d887
< --
883d887
< -- > scanr f v == reverse . scanl (flip f) v . reverse
884d887
< scanr :: (Char -> Char -> Char) -> Char -> Text -> Text
885d887
< scanr f v = reverse . scanl g v . reverse
886d887
<     where g a b = safe (f b a)
887d887
< 
888c888
< -- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting
---
> {-# INLINE-- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting #-}
890d889
< scanr1 :: (Char -> Char -> Char) -> Text -> Text
891d889
< scanr1 f t | null t    = empty
892d889
<            | otherwise = scanr f (last t) (init t)
893d889
< 
894d889
< -- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies a
895d889
< -- function to each element of a 'Text', passing an accumulating
896c890
< -- parameter from left to right, and returns a final 'Text'.  Performs
---
> scanr1-- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs:: (Char -> Char -> Char) -> Text -> Text
896a891
> scanr1-- replacement on invalid scalar values.f t | null t    = empty
896a892
> --         | otherwise = scanr f (last t) (init t)
896a893
> -- > scanr f v == reverse . scanl (flip f) v . reverse
896a894
> scanr-- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies a:: (Char -> Char -> Char) -> Char -> Text -> Text
896a895
> scanr-- function to each element of a 'Text', passing an accumulating v = reverse . scanl g v . reverse
896a896
> -- parameter from left to right, and returns a final 'Text'.  Performswhere g a b = safe (f b a)
898d897
< mapAccumL :: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
899d897
< mapAccumL f = go
900d897
<   where
901d897
<     go z (Chunk c cs)    = (z'', Chunk c' cs')
902c898
<         where (z',  c')  = T.mapAccumL f z c
---
> mapAccumL-- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
902a899
> mapAccumL-- value argument.  Performs replacement on invalid scalar values.f = go
902a900
> scanr1where:: (Char -> Char -> Char) -> Text -> Text
902a901
> scanr1go f tChunk nullc tcs)  = empty= (z'', Chunk c' cs')
902a902
>         where otherwise(z',  c')= scanr= T.mapAccumL (last t)z(initc    t)
904d903
<     go z Empty           = (z, Empty)
905d903
< {-# INLINE mapAccumL #-}
906d903
< 
907d903
< -- | The 'mapAccumR' function behaves like a combination of 'map' and
908d903
< -- a strict 'foldr'; it applies a function to each element of a
909d903
< -- 'Text', passing an accumulating parameter from right to left, and
910d903
< -- returning a final value of this accumulator together with the new
911d903
< -- 'Text'.  Performs replacement on invalid scalar values.
912d903
< mapAccumR :: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
913d903
< mapAccumR f = go
914d903
<   where
915c904
<     go z (Chunk c cs)   = (z'', Chunk c' cs')
---
> -- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies ago z Empty           = (z, Empty)
915a905
> {-# INLINE-- function to each element of a 'Text', passing an accumulatingmapAccumL #-}
915a906
> -- parameter from left to right, and returns a final 'Text'.  Performs
915a907
> -- replacement on invalid scalar values.-- | The 'mapAccumR' function behaves like a combination of 'map' and
915a908
> mapAccumL-- a strict 'foldr'; it applies a function to each element of a:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
915a909
> mapAccumL-- 'Text', passing an accumulating parameter from right to left, and = go
915a910
> -- returning a final value of this accumulator together with the newwhere
915a911
> -- 'Text'.  Performs replacement on invalid scalar values. z (Chunk c cs)    = (z'', Chunk c' cs')
915a912
> mapAccumRwhere:: ((z'->, Char) ->= T.mapAccumL(a,Char)) ->faz-> Text -> (a, Text)
915a913
>  mapAccumR f = (goz'', cs') = go z' cs
915a914
>   where z Empty           = (z, Empty)
915a915
> {-# INLINEgo z (Chunkc cs)#-}= (z'', Chunk c' cs')
917d916
<               (z', cs') = go z cs
918d916
<     go z Empty          = (z, Empty)
919d916
< {-# INLINE mapAccumR #-}
920c917
< 
---
> -- | The 'mapAccumR' function behaves like a combination of 'map' and(z', cs') = go z cs
920a918
> -- a strict 'foldr'; it applies a function to each element of ago z Empty          = (z, Empty)
920a919
> {-# INLINE-- 'Text', passing an accumulating parameter from right to left, andmapAccumR #-}
920a920
> -- returning a final value of this accumulator together with the new
920a921
> -- 'Text'.  Performs replacement on invalid scalar values.-- | /O(n*m)/ 'replicate' @n@ @t@ is a 'Text' consisting of the input
920a922
> mapAccumR-- @t@ repeated @n@ times.:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
920a923
> mapAccumR f::=Int64   -> Text -> Text
920a924
> replicatewhere   n t
920a925
>     go| null (Chunkt || c cs)0 ==emptyz'', Chunk c' cs')
920a926
>     | isSingletonwhere (z'', c')==replicateChar fnz'(head   t)
920a927
>              | otherwisez', cs')==concat z cs(rep 0)
920a928
>     gowhere Emptyrep !i | i >= = (z,=Empty[]  )
920a929
> {-# INLINE mapAccumR| otherwise#-}     = t : rep (i+1)
920a930
> {-# INLINE [1] replicate #-}
922d931
< -- @t@ repeated @n@ times.
923d931
< replicate :: Int64 -> Text -> Text
924d931
< replicate n t
925d931
<     | null t || n <= 0 = empty
926c932
<     | isSingleton t    = replicateChar n (head t)
---
> -- @t@ repeated @n@ times.-- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
926a933
> replicate-- value of every element. Subject to fusion.:: Int64 -> Text -> Text
926a934
> replicatereplicateChar t :: Int64 -> Char -> Text
926a935
> replicateChar null t ||n n <== unstream = empty(S.replicateCharI n (safe c))
926a936
> {-# INLINE isSingletonreplicateChar    = replicateChar#-}           n (head t)
928d937
<     where rep !i | i >= n    = []
929d937
<                  | otherwise = t : rep (i+1)
930d937
< {-# INLINE [1] replicate #-}
931d937
< 
932d937
< -- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
933d937
< -- value of every element. Subject to fusion.
934d937
< replicateChar :: Int64 -> Char -> Text
935d937
< replicateChar n c = unstream (S.replicateCharI n (safe c))
936d937
< {-# INLINE replicateChar #-}
937d937
< 
938d937
< {-# RULES
939d937
< "LAZY TEXT replicate/singleton -> replicateChar" [~1] forall n c.
940c938
<     replicate n (singleton c) = replicateChar n c
---
> {-# RULESwhere rep !i | i >= n    = []
940a939
>      "LAZY TEXT replicate/singleton -> replicateChar" otherwise = t : rep (i+1)     [~1] forall n c.
940a940
> {-# INLINEreplicate[1]nreplicate(singleton#-}c) = replicateChar n c
942d941
< 
943d941
< -- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'
944d941
< -- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a
945d941
< -- 'Text' from a seed value. The function takes the element and
946c942
< -- returns 'Nothing' if it is done producing the 'Text', otherwise
---
> -- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
946a943
> -- value of every element. Subject to fusion.-- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'
946a944
> replicateChar-- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a:: Int64 -> Char -> Text
946a945
> replicateChar-- 'Text' from a seed value. The function takes the element and c = unstream (S.replicateCharI n (safe c))
946a946
> {-# INLINE-- returns 'Nothing' if it is done producing the 'Text', otherwise #-}
948d947
< -- string, and @b@ is the seed value for further production.  Performs
949d947
< -- replacement on invalid scalar values.
950d947
< unfoldr :: (a -> Maybe (Char,a)) -> a -> Text
951c948
< unfoldr f s = unstream (S.unfoldr (firstf safe . f) s)
---
> {-# RULES-- string, and @b@ is the seed value for further production.  Performs
951a949
> "LAZY TEXT replicate/singleton -> replicateChar"-- replacement on invalid scalar values.         [~1] forall n c.
951a950
> unfoldr:: (a n->(singletonMaybe (Char)a=)replicateChar-> a -> Text n c
951a951
> unfoldr#-}   f s = unstream (S.unfoldr (firstf safe . f) s)
954d953
< -- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed
955d953
< -- value. However, the length of the result should be limited by the
956d953
< -- first argument to 'unfoldrN'. This function is more efficient than
957d953
< -- 'unfoldr' when the maximum length of the result is known and
958d953
< -- correct, otherwise its performance is similar to 'unfoldr'.
959d953
< -- Performs replacement on invalid scalar values.
960d953
< unfoldrN :: Int64 -> (a -> Maybe (Char,a)) -> a -> Text
961d953
< unfoldrN n f s = unstream (S.unfoldrN n (firstf safe . f) s)
962d953
< {-# INLINE unfoldrN #-}
963c954
< 
---
> -- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'-- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed
963a955
> -- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a
963a956
> -- 'Text' from a seed value. The function takes the element and-- first argument to 'unfoldrN'. This function is more efficient than
963a957
> -- 'unfoldr' when the maximum length of the result is known and-- returns 'Nothing' if it is done producing the 'Text', otherwise
963a958
> -- correct, otherwise its performance is similar to 'unfoldr'.-- 'Just' @(a,b)@.  In this case, @a@ is the next 'Char' in the
963a959
> -- Performs replacement on invalid scalar values.-- string, and @b@ is the seed value for further production.  Performs
963a960
> unfoldrN-- replacement on invalid scalar values.:: Int64 -> (a -> Maybe (Char,a)) -> a -> Text
963a961
> unfoldrunfoldrN::n (as->= MaybeunstreamChar(S.unfoldrN,a)) -> a ->n (Textfirstf safe . f) s)
963a962
> unfoldr{-# INLINE sunfoldrN= unstream#-}(S.unfoldr (firstf safe . f) s)
963a963
> {-# INLINE unfoldr #-}
965d964
< -- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than
966d964
< -- the length of the Text. Subject to fusion.
967d964
< take :: Int64 -> Text -> Text
968d964
< take i _ | i <= 0 = Empty
969d964
< take i t0         = take' i t0
970d964
<   where take' 0 _            = Empty
971d964
<         take' _ Empty        = Empty
972d964
<         take' n (Chunk t ts)
973c965
<             | n < len   = Chunk (T.take (fromIntegral n) t) Empty
---
> -- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed-- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than
973a966
> -- the length of the Text. Subject to fusion.-- value. However, the length of the result should be limited by the
973a967
> take-- first argument to 'unfoldrN'. This function is more efficient than:: Int64 -> Text -> Text
973a968
> take-- 'unfoldr' when the maximum length of the result is known andi _ | i <= 0 = Empty
973a969
> take-- correct, otherwise its performance is similar to 'unfoldr'.i t0         = take' i t0
973a970
> -- Performs replacement on invalid scalar values.where take' 0 _            = Empty
973a971
> unfoldrNtake':: Int64_ Empty-> (a -> Maybe= EmptyChar,a)) -> a -> Text
973a972
> unfoldrNtake' f sn=(unstreamChunk t tsS.unfoldrN)          n (firstf safe . f) s)
973a973
> {-# INLINE unfoldrN| n < len#-} = Chunk (T.take (fromIntegral n) t) Empty
975d974
<             where len = fromIntegral (T.length t)
976d974
< {-# INLINE [1] take #-}
977d974
< 
978d974
< {-# RULES
979d974
< "LAZY TEXT take -> fused" [~1] forall n t.
980d974
<     take n t = unstream (S.take n (stream t))
981d974
< "LAZY TEXT take -> unfused" [1] forall n t.
982d974
<     unstream (S.take n (stream t)) = take n t
983d974
<   #-}
984d974
< 
985d974
< -- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after
986d974
< -- taking @n@ characters from the end of @t@.
987c975
< --
---
> -- | /O(n)/ 'take' @n@, applied to a 'Text', returns the prefix of thewhere len = fromIntegral (T.length t)
987a976
> {-# INLINE-- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than[1] take #-}
987a977
> -- the length of the Text. Subject to fusion.
987a978
> take{-# RULES:: Int64 -> Text -> Text
987a979
> take"LAZY TEXT take -> fused" _ | i <= 0 = Empty [~1] forall n t.
987a980
> taketake t0n t = unstream= take'(S.take t0  n (stream t))
987a981
> "LAZY TEXT take -> unfused"where take' 0 _           [=]Emptyforall n t.
987a982
>                              unstream(_S.taken (stream= Emptyt)) = take n t
987a983
>                            #-}   take' n (Chunk t ts)
987a984
>                                      | n < len   = Chunk (T.take (fromIntegral n) t) Empty
987a985
>                          -- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after otherwise = Chunk t (take' (n - len) ts)
987a986
>                          -- taking @n@ characters from the end of @t@.where len = fromIntegral (T.length t)
987a987
> {-# INLINE--         [1] take #-}
989d988
< --
990d988
< -- > takeEnd 3 "foobar" == "bar"
991d988
< takeEnd :: Int64 -> Text -> Text
992d988
< takeEnd n t0
993d988
<     | n <= 0    = empty
994c989
<     | otherwise = takeChunk n empty . L.reverse . toChunks $ t0
---
> {-# RULES--
994a990
> "LAZY TEXT take -> fused"-- > takeEnd 3 "foobar" == "bar"[~1] forall n t.
994a991
> takeEnd:: tInt64= unstream-> Text(S.take-> Textn (stream t))
994a992
> "LAZY TEXT take -> unfused"takeEnd n t0                [1] forall n t.
994a993
>     unstream| n <= 0 (S.take= empty (stream t)) = take n t
994a994
>   #-}| otherwise = takeChunk n empty . L.reverse . toChunks $ t0
997d996
<           | i <= l    = chunk (T.takeEnd (fromIntegral i) t) acc
998d996
<           | otherwise = takeChunk (i-l) (Chunk t acc) ts
999d996
<           where l = fromIntegral (T.length t)
1000d996
< 
1001d996
< -- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of the
1002c997
< -- 'Text' after the first @n@ characters, or the empty 'Text' if @n@
---
> -- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after| i <= l    = chunk (T.takeEnd (fromIntegral i) t) acc
1002a998
> -- taking @n@ characters from the end of @t@.| otherwise = takeChunk (i-l) (Chunk t acc) ts
1002a999
> --        where l = fromIntegral (T.length t)
1002a1000
> -- Examples:
1002a1001
> ---- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of the
1002a1002
> -- > takeEnd 3 "foobar" == "bar"-- 'Text' after the first @n@ characters, or the empty 'Text' if @n@
1002a1003
> takeEnd-- is greater than the length of the 'Text'. Subject to fusion.:: Int64 -> Text -> Text
1002a1004
> takeEnddrop :: nInt64  -> Text -> Text
1002a1005
> drop|int0 0    = empty
1002a1006
>     | otherwisei <= 0    = takeChunkt0        n empty . L.reverse . toChunks $ t0
1002a1007
>   where| otherwise= _drop' []t0= acc
1002a1008
>   where takeChunkdrop' 0 tsi acc (t:ts) ts
1002a1009
>         drop' i <=_ Empty    = chunk=(T.takeEndEmpty     (fromIntegral i) t) acc
1002a1010
>         drop' otherwisen (Chunk=ttakeChunkts)      (i-l) (Chunk t acc) ts
1002a1011
>           where| n l =len= Chunk ((T.dropT.length(fromIntegral)         n) t) ts
1002a1012
>             | otherwise = drop' (n - len) ts
1002a1013
> -- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of thewhere len   = fromIntegral (T.length t)
1002a1014
> {-# INLINE-- 'Text' after the first @n@ characters, or the empty 'Text' if @n@[1] drop #-}
1004d1015
< drop :: Int64 -> Text -> Text
1005d1015
< drop i t0
1006d1015
<     | i <= 0    = t0
1007d1015
<     | otherwise = drop' i t0
1008d1015
<   where drop' 0 ts           = ts
1009c1016
<         drop' _ Empty        = Empty
---
> drop{-# RULES:: Int64 -> Text -> Text
1009a1017
> drop"LAZY TEXT drop -> fused" t0                 [~1] forall n t.
1009a1018
>     |drop <=n 0 = unstream= t0    (S.drop n (stream t))
1009a1019
> "LAZY TEXT drop -> unfused" otherwise = drop' i t0[1] forall n t.
1009a1020
>   whereunstream(0S.drop   n (stream= tst)) = drop n t
1009a1021
>   #-}   drop' _ Empty        = Empty
1011d1022
<             | n < len   = Chunk (T.drop (fromIntegral n) t) ts
1012d1022
<             | otherwise = drop' (n - len) ts
1013d1022
<             where len   = fromIntegral (T.length t)
1014d1022
< {-# INLINE [1] drop #-}
1015d1022
< 
1016d1022
< {-# RULES
1017d1022
< "LAZY TEXT drop -> fused" [~1] forall n t.
1018d1022
<     drop n t = unstream (S.drop n (stream t))
1019d1022
< "LAZY TEXT drop -> unfused" [1] forall n t.
1020d1022
<     unstream (S.drop n (stream t)) = drop n t
1021d1022
<   #-}
1022d1022
< 
1023d1022
< -- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after
1024d1022
< -- dropping @n@ characters from the end of @t@.
1025d1022
< --
1026c1023
< -- Examples:
---
> -- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after n < len   = Chunk (T.drop (fromIntegral n) t) ts
1026a1024
> -- dropping @n@ characters from the end of @t@. otherwise = drop' (n - len) ts
1026a1025
> --          where len   = fromIntegral (T.length t)
1026a1026
> {-# INLINE-- Examples:[1] drop #-}
1028d1027
< -- > dropEnd 3 "foobar" == "foo"
1029d1027
< dropEnd :: Int64 -> Text -> Text
1030d1027
< dropEnd n t0
1031d1027
<     | n <= 0    = t0
1032d1027
<     | otherwise = dropChunk n . L.reverse . toChunks $ t0
1033c1028
<   where dropChunk _ [] = empty
---
> {-# RULES-- > dropEnd 3 "foobar" == "foo"
1033a1029
> "LAZY TEXT drop -> fused"dropEnd :: Int64 -> Text ->[~1Text] forall n t.
1033a1030
> dropEndnnt0 = unstream (S.drop n (stream t))
1033a1031
> "LAZY TEXT drop -> unfused"| n <= 0    = t0        [1] forall n t.
1033a1032
>     unstream| otherwiseS.drop= dropChunk (streamn .t)L.reverse) = drop n ttoChunks $ t0
1033a1033
>   #-}where dropChunk _ [] = empty
1036d1035
<           | otherwise = fromChunks . L.reverse $
1037d1035
<                         T.dropEnd (fromIntegral m) t : ts
1038d1035
<           where l = fromIntegral (T.length t)
1039d1035
< 
1040d1035
< -- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'
1041d1035
< -- values dropped, or the empty 'Text' if @n@ is greater than the
1042d1035
< -- number of 'Word16' values present.
1043d1035
< dropWords :: Int64 -> Text -> Text
1044d1035
< dropWords i t0
1045d1035
<     | i <= 0    = t0
1046d1035
<     | otherwise = drop' i t0
1047d1035
<   where drop' 0 ts           = ts
1048d1035
<         drop' _ Empty        = Empty
1049d1035
<         drop' n (Chunk (T.Text arr off len) ts)
1050d1035
<             | n < len'  = chunk (text arr (off+n') (len-n')) ts
1051c1036
<             | otherwise = drop' (n - len') ts
---
> -- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after| otherwise = fromChunks . L.reverse $
1051a1037
> -- dropping @n@ characters from the end of @t@.T.dropEnd (fromIntegral m) t : ts
1051a1038
> --        where l = fromIntegral (T.length t)
1051a1039
> -- Examples:
1051a1040
> ---- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'
1051a1041
> -- > dropEnd 3 "foobar" == "foo"-- values dropped, or the empty 'Text' if @n@ is greater than the
1051a1042
> dropEnd-- number of 'Word16' values present.:: Int64 -> Text -> Text
1051a1043
> dropEnddropWords t0 Int64 -> Text -> Text
1051a1044
> dropWords n <=i0t0  = t0
1051a1045
>     | otherwisei <= 0    = dropChunkt0        n . L.reverse . toChunks $ t0
1051a1046
>   where| otherwise= _drop'] =iemptyt0
1051a1047
>   where dropChunkdrop' 0 tsm (t:ts)   = ts
1051a1048
>         drop' m >=_ Empty    = dropChunk= Emptym-l) ts
1051a1049
>         drop' otherwisen (Chunk=(fromChunksT.Text arr .offlen) ts)$
1051a1050
>             | n < len'  T.dropEnd= chunk (textfromIntegralarr (off+n') tlen ts-n')) ts
1051a1051
>           where| otherwise = fromIntegral= drop' ((T.length- len') tts)
1053c1053
<                   n'    = fromIntegral n
---
> -- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'n'    = fromIntegral n
1053a1054
> -- values dropped, or the empty 'Text' if @n@ is greater than the
1053a1055
> -- number of 'Word16' values present.-- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
1053a1056
> dropWords-- returns the longest prefix (possibly empty) of elements that:: Int64 -> Text -> Text
1053a1057
> dropWords-- satisfy @p@.  Subject to fusion. t0
1053a1058
> takeWhile i <=:: (Char= t0-> Bool) -> Text -> Text
1053a1059
> takeWhile otherwisep t0 ==takeWhile' i t0t0
1053a1060
>   where drop'takeWhile' ts Empty     = ts= Empty
1053a1061
>         drop'takeWhile' Empty(Chunk t ts=)Empty=
1053a1062
>         drop'casenT.findIndexChunk (T.Text(notarr. poff) t lenof ) ts)
1053a1063
>             |Just <nlen'| n >=0chunk->textChunk(T.takeoff+n'n)t(lenEmpty-n')) ts
1053a1064
>             | otherwise| otherwise= drop'->nEmpty len') ts
1053a1065
>             whereNothing  = fromIntegral-> Chunklent (takeWhile' ts)
1053a1066
> {-# INLINE [1] takeWhile    =#-} n
1055d1067
< -- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
1056d1067
< -- returns the longest prefix (possibly empty) of elements that
1057d1067
< -- satisfy @p@.  Subject to fusion.
1058d1067
< takeWhile :: (Char -> Bool) -> Text -> Text
1059d1067
< takeWhile p t0 = takeWhile' t0
1060c1068
<   where takeWhile' Empty        = Empty
---
> {-# RULES-- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
1060a1069
> "LAZY TEXT takeWhile -> fused"-- returns the longest prefix (possibly empty) of elements that[~1] forall p t.
1060a1070
> -- satisfy @p@.  Subject to fusion.takeWhile p t = unstream (S.takeWhile p (stream t))
1060a1071
> takeWhile"LAZY TEXT takeWhile -> unfused":: (Char -> Bool) -> Text[1]->forall p t.
1060a1072
> takeWhileunstream t0(S.takeWhile= takeWhile'p t0(stream t)) = takeWhile p t
1060a1073
>   where#-}   takeWhile' Empty        = Empty
1062d1074
<           case T.findIndex (not . p) t of
1063d1074
<             Just n | n > 0     -> Chunk (T.take n t) Empty
1064d1074
<                    | otherwise -> Empty
1065d1074
<             Nothing            -> Chunk t (takeWhile' ts)
1066d1074
< {-# INLINE [1] takeWhile #-}
1067d1074
< 
1068d1074
< {-# RULES
1069d1074
< "LAZY TEXT takeWhile -> fused" [~1] forall p t.
1070d1074
<     takeWhile p t = unstream (S.takeWhile p (stream t))
1071d1074
< "LAZY TEXT takeWhile -> unfused" [1] forall p t.
1072d1074
<     unstream (S.takeWhile p (stream t)) = takeWhile p t
1073d1074
<   #-}
1074d1074
< 
1075d1074
< -- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after
1076d1074
< -- 'takeWhile' @p@ @t@.  Subject to fusion.
1077d1074
< dropWhile :: (Char -> Bool) -> Text -> Text
1078d1074
< dropWhile p t0 = dropWhile' t0
1079c1075
<   where dropWhile' Empty        = Empty
---
> -- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after T.findIndex (not . p) t of
1079a1076
> -- 'takeWhile' @p@ @t@.  Subject to fusion. n | n > 0     -> Chunk (T.take n t) Empty
1079a1077
> dropWhile :: (Char |->otherwiseBool) -> ->Text-> Text
1079a1078
> dropWhile p Nothingt0 = dropWhile' t0 -> Chunk t (takeWhile' ts)
1079a1079
> {-# INLINEwhere dropWhile'[1] takeWhileEmpty #-}    = Empty
1081d1080
<           case T.findIndex (not . p) t of
1082d1080
<             Just n  -> Chunk (T.drop n t) ts
1083d1080
<             Nothing -> dropWhile' ts
1084d1080
< {-# INLINE [1] dropWhile #-}
1085d1080
< 
1086c1081
< {-# RULES
---
> {-# RULES case T.findIndex (not . p) t of
1086a1082
> "LAZY TEXT takeWhile -> fused"Just n  -> Chunk (T.drop[~1] foralln t) ts t.
1086a1083
>     takeWhileNothing t = unstream-> dropWhile'S.takeWhilets      p (stream t))
1086a1084
> "LAZY TEXT takeWhile -> unfused"{-# INLINE [1] dropWhile #-}     [1] forall p t.
1086a1085
>     unstream (S.takeWhile p (stream t)) = takeWhile p t
1086a1086
> {-# RULES#-}
1089d1088
< "LAZY TEXT dropWhile -> unfused" [1] forall p t.
1090d1088
<     unstream (S.dropWhile p (stream t)) = dropWhile p t
1091d1088
<   #-}
1092d1088
< -- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining after
1093d1088
< -- dropping characters that fail the predicate @p@ from the end of
1094d1088
< -- @t@.
1095d1088
< -- Examples:
1096d1088
< --
1097d1088
< -- > dropWhileEnd (=='.') "foo..." == "foo"
1098c1089
< dropWhileEnd :: (Char -> Bool) -> Text -> Text
---
> "LAZY TEXT dropWhile -> unfused"-- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after[1] forall p t.
1098a1090
> -- 'takeWhile' @p@ @t@.  Subject to fusion.unstream (S.dropWhile p (stream t)) = dropWhile p t
1098a1091
> dropWhile#-}     :: (Char -> Bool) -> Text -> Text
1098a1092
> dropWhile-- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining after t0 = dropWhile' t0
1098a1093
> -- dropping characters that fail the predicate @p@ from the end ofwhere dropWhile' Empty        = Empty
1098a1094
>                                                                 -- @t@. dropWhile' (Chunk t ts) =
1098a1095
>                                                                 -- Examples: T.findIndex (not . p) t of
1098a1096
>                                                                 --          Just n  -> Chunk (T.drop n t) ts
1098a1097
>                                                                 -- > dropWhileEnd (=='.') "foo..." == "foo" -> dropWhile' ts
1098a1098
> {-# INLINEdropWhileEnd[1]::dropWhile(Char -> #-}Bool) -> Text -> Text
1100d1099
<   where go Empty = Empty
1101d1099
<         go (Chunk t Empty) = if T.null t'
1102d1099
<                              then Empty
1103d1099
<                              else Chunk t' Empty
1104d1099
<             where t' = T.dropWhileEnd p t
1105c1100
<         go (Chunk t ts) = case go ts of
---
> {-# RULESwhere go Empty = Empty
1105a1101
> "LAZY TEXT dropWhile -> fused"go (Chunk t Empty) = if[~T.null1] forallt'  p t.
1105a1102
>     dropWhile p t = unstream (thenS.dropWhileEmpty   p (stream t))
1105a1103
> "LAZY TEXT dropWhile -> unfused"else[1Chunk] forallt' Empty t.
1105a1104
>     unstreamwhereS.dropWhilet' = T.dropWhileEnd (stream t)) = dropWhile p t
1105a1105
>   #-}   go (Chunk t ts) = case go ts of
1107c1107
<                             ts' -> Chunk t ts'
---
> -- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining afterts' -> Chunk t ts'
1107a1108
> {-# INLINE-- dropping characters that fail the predicate @p@ from the end ofdropWhileEnd #-}
1107a1109
> -- @t@.
1107a1110
> -- Examples:-- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
1107a1111
> ---- dropping characters that fail the predicate @p@ from both the
1107a1112
> -- > dropWhileEnd (=='.') "foo..." == "foo"-- beginning and end of @t@.  Subject to fusion.
1107a1113
> dropWhileEnddropAround ::::(CharChar->->Bool) )->->Text->->Text
1107a1114
> dropWhileEnddropAround p p =dropWhile      p . dropWhileEnd p
1107a1115
> {-# INLINEwhere go Empty[1] dropAround= Empty  #-}
1107a1116
>                 go (Chunk t Empty) = if T.null t'
1107a1117
>         -- | /O(n)/ Remove leading white space from a string.  Equivalent to:then Empty
1107a1118
>         --                           else Chunk t' Empty
1107a1119
>         -- > dropWhile isSpacewhere t' = T.dropWhileEnd p t
1107a1120
>         stripStart (::ChunkTextt->)Text= case go ts of
1107a1121
>         stripStart = dropWhile isSpace -> go (Chunk t Empty)
1107a1122
>         {-# INLINE [1] stripStart #-} -> Chunk t ts'
1109d1123
< 
1110d1123
< -- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
1111d1123
< -- dropping characters that fail the predicate @p@ from both the
1112d1123
< -- beginning and end of @t@.  Subject to fusion.
1113d1123
< dropAround :: (Char -> Bool) -> Text -> Text
1114d1123
< dropAround p = dropWhile p . dropWhileEnd p
1115d1123
< {-# INLINE [1] dropAround #-}
1116d1123
< 
1117d1123
< -- | /O(n)/ Remove leading white space from a string.  Equivalent to:
1118d1123
< --
1119d1123
< -- > dropWhile isSpace
1120d1123
< stripStart :: Text -> Text
1121d1123
< stripStart = dropWhile isSpace
1122d1123
< {-# INLINE [1] stripStart #-}
1123d1123
< 
1125d1124
< --
1126d1124
< -- > dropWhileEnd isSpace
1127d1124
< stripEnd :: Text -> Text
1128d1124
< stripEnd = dropWhileEnd isSpace
1129d1124
< {-# INLINE [1] stripEnd #-}
1130c1125
< 
---
> ---- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
1130a1126
> -- > dropWhileEnd isSpace-- dropping characters that fail the predicate @p@ from both the
1130a1127
> stripEnd-- beginning and end of @t@.  Subject to fusion.:: Text -> Text
1130a1128
> dropAroundstripEnd = ::dropWhileEndChar -> BoolisSpace) -> Text -> Text
1130a1129
> dropAround p1= dropWhilestripEnd #-} . dropWhileEnd p
1130a1130
> {-# INLINE [1] dropAround #-}
1132c1132
< -- Equivalent to:
---
> -- Equivalent to:-- | /O(n)/ Remove leading white space from a string.  Equivalent to:
1134d1133
< -- > dropAround isSpace
1135d1133
< strip :: Text -> Text
1136d1133
< strip = dropAround isSpace
1137c1134
< {-# INLINE [1] strip #-}
---
> -- > dropWhile isSpace-- > dropAround isSpace
1137a1135
> stripStartstrip :: Text:: Text-> Text-> Text
1137a1136
> stripStartstrip = dropAround= dropWhileisSpace
1137a1137
> {-# INLINE [1] stripStartstrip #-}  #-}
1139d1138
< -- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a
1140d1138
< -- prefix of @t@ of length @n@, and whose second is the remainder of
1141d1138
< -- the string. It is equivalent to @('take' n t, 'drop' n t)@.
1142d1138
< splitAt :: Int64 -> Text -> (Text, Text)
1143d1138
< splitAt = loop
1144c1139
<   where loop _ Empty      = (empty, empty)
---
> -- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a-- | /O(n)/ Remove trailing white space from a string.  Equivalent to:
1144a1140
> ---- prefix of @t@ of length @n@, and whose second is the remainder of
1144a1141
> -- > dropWhileEnd isSpace-- the string. It is equivalent to @('take' n t, 'drop' n t)@.
1144a1142
> stripEndsplitAt ::::Int64 -> Text -> (Text, Text)
1144a1143
> stripEndsplitAt ==loop isSpace
1144a1144
> {-# INLINEwhere loop[1] stripEndEmpty    #-}= (empty, empty)
1146d1145
<         loop n (Chunk t ts)
1147d1145
<              | n < len   = let (t',t'') = T.splitAt (fromIntegral n) t
1148d1145
<                            in (Chunk t' Empty, Chunk t'' ts)
1149d1145
<              | otherwise = let (ts',ts'') = loop (n - len) ts
1150d1145
<                            in (Chunk t ts', ts'')
1151d1145
<              where len = fromIntegral (T.length t)
1152c1146
< 
---
> -- | /O(n)/ Remove leading and trailing white space from a string.loop n (Chunk t ts)
1152a1147
> -- Equivalent to:| n < len   = let (t',t'') = T.splitAt (fromIntegral n) t
1152a1148
> --                         in (Chunk t' Empty, Chunk t'' ts)
1152a1149
> -- > dropAround isSpace| otherwise = let (ts',ts'') = loop (n - len) ts
1152a1150
> strip :: Text -> Text      in (Chunk t ts', ts'')
1152a1151
> strip = dropAroundwhere isSpacelen = fromIntegral (T.length t)
1152a1152
> {-# INLINE [1] strip #-}
1154d1153
< -- element is a prefix of @t@ whose chunks contain @n@ 'Word16'
1155d1153
< -- values, and whose second is the remainder of the string.
1156d1153
< splitAtWord :: Int64 -> Text -> PairS Text Text
1157d1153
< splitAtWord _ Empty = empty :*: empty
1158d1153
< splitAtWord x (Chunk c@(T.Text arr off len) cs)
1159d1153
<     | y >= len  = let h :*: t = splitAtWord (x-fromIntegral len) cs
1160d1153
<                   in  Chunk c h :*: t
1161d1153
<     | otherwise = chunk (text arr off y) empty :*:
1162d1153
<                   chunk (text arr (off+y) (len-y)) cs
1163d1153
<     where y = fromIntegral x
1164d1153
< 
1165d1153
< -- | /O(n+m)/ Find the first instance of @needle@ (which must be
1166c1154
< -- non-'null') in @haystack@.  The first element of the returned tuple
---
> -- element is a prefix of @t@ whose chunks contain @n@ 'Word16'-- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a
1166a1155
> -- values, and whose second is the remainder of the string.-- prefix of @t@ of length @n@, and whose second is the remainder of
1166a1156
> splitAtWord-- the string. It is equivalent to @('take' n t, 'drop' n t)@.:: Int64 -> Text -> PairS Text Text
1166a1157
> splitAtsplitAtWord:: Int64_ Empty-> Text= empty-> (:*:Textempty, Text)
1166a1158
> splitAtsplitAtWord= loopx (Chunk c@(T.Text arr off len) cs)
1166a1159
>   where| y loop>= len Empty= let h :*:= (empty= splitAtWord, empty)  (x-fromIntegral len) cs
1166a1160
>         loop n t |in <=Chunk = (emptyh :*:, t)
1166a1161
>     | otherwise n (Chunk= chunk ts(text)   arr off y) empty :*:
1166a1162
>              | n <chunk  (=textarrt',t'')y= T.splitAt(len-y)) csfromIntegral n) t
1166a1163
>        where y = fromIntegral inx  (Chunk t' Empty, Chunk t'' ts)
1166a1164
>              | otherwise = let (ts',ts'') = loop (n - len) ts
1166a1165
> -- | /O(n+m)/ Find the first instance of @needle@ (which must bein (Chunk t ts', ts'')
1166a1166
> -- non-'null') in @haystack@.  The first element of the returned tuplewhere len = fromIntegral (T.length t)
1168d1167
< -- is the remainder of @haystack@, starting with the match.
1169d1167
< --
1170d1167
< -- Examples:
1171d1167
< --
1172d1167
< -- > breakOn "::" "a::b::c" ==> ("a", "::b::c")
1173d1167
< -- > breakOn "/" "foobar"   ==> ("foobar", "")
1174d1167
< --
1175c1168
< -- Laws:
---
> -- is the remainder of @haystack@, starting with the match.-- | /O(n)/ 'splitAtWord' @n t@ returns a strict pair whose first
1175a1169
> ---- element is a prefix of @t@ whose chunks contain @n@ 'Word16'
1175a1170
> -- Examples:-- values, and whose second is the remainder of the string.
1175a1171
> splitAtWord--          :: Int64 -> Text -> PairS Text Text
1175a1172
> splitAtWord-- > breakOn "::" "a::b::c" ==> ("a", "::b::c") Empty = empty :*: empty
1175a1173
> splitAtWord-- > breakOn "/" "foobar"   ==> ("foobar", "") (Chunk c@(T.Text arr off len) cs)
1175a1174
> --  | y >= len  = let h :*: t = splitAtWord (x-fromIntegral len) cs
1175a1175
> -- Laws:          in  Chunk c h :*: t
1175a1176
> --  | otherwise = chunk (text arr off y) empty :*:
1175a1177
> -- > append prefix match == haystack (text arr (off+y) (len-y)) cs
1175a1178
> -- >   where (prefix, match) = breakOn needle haystackwhere y = fromIntegral x
1177d1179
< -- > append prefix match == haystack
1178c1180
< -- >   where (prefix, match) = breakOn needle haystack
---
> -- | /O(n+m)/ Find the first instance of @needle@ (which must be-- If you need to break a string by a substring repeatedly (e.g. you
1178a1181
> -- want to break on every instance of a substring), use 'breakOnAll'-- non-'null') in @haystack@.  The first element of the returned tuple
1178a1182
> -- instead, as it has lower startup overhead.-- is the prefix of @haystack@ before @needle@ is matched.  The second
1178a1183
> ---- is the remainder of @haystack@, starting with the match.
1178a1184
> ---- This function is strict in its first argument, and lazy in its
1178a1185
> -- second.-- Examples:
1180c1187
< -- If you need to break a string by a substring repeatedly (e.g. you
---
> -- > breakOn "::" "a::b::c" ==> ("a", "::b::c")-- In (unlikely) bad cases, this function's time complexity degrades
1180a1188
> -- towards /O(n*m)/.-- > breakOn "/" "foobar"   ==> ("foobar", "")
1180a1189
> --breakOn :: Text -> Text -> (Text, Text)
1180a1190
> breakOn-- Laws:pat src
1180a1191
> --  | null pat  = emptyError "breakOn"
1180a1192
> -- > append prefix match == haystack| otherwise = case indices pat src of
1180a1193
> -- >   where (prefix, match) = breakOn needle haystack[]    -> (src, empty)
1180a1194
> --                  (x:_) -> let h :*: t = splitAtWord x src
1180a1195
> -- If you need to break a string by a substring repeatedly (e.g. youin  (h, t)
1182d1196
< -- instead, as it has lower startup overhead.
1183d1196
< --
1184d1196
< -- This function is strict in its first argument, and lazy in its
1185c1197
< -- second.
---
> -- instead, as it has lower startup overhead.-- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
1187d1198
< -- In (unlikely) bad cases, this function's time complexity degrades
1188d1198
< -- towards /O(n*m)/.
1189d1198
< breakOn :: Text -> Text -> (Text, Text)
1190d1198
< breakOn pat src
1191d1198
<     | null pat  = emptyError "breakOn"
1192c1199
<     | otherwise = case indices pat src of
---
> -- This function is strict in its first argument, and lazy in its-- The first element of the returned tuple is the prefix of @haystack@
1192a1200
> -- second.-- up to and including the last match of @needle@.  The second is the
1192a1201
> ---- remainder of @haystack@, following the match.
1192a1202
> ---- In (unlikely) bad cases, this function's time complexity degrades
1192a1203
> -- towards /O(n*m)/.-- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
1192a1204
> breakOnbreakOnEnd:: Text:: Text-> Text-> Text-> (->Text(Text, Text, Text)  )
1192a1205
> breakOnbreakOnEndpatsrc = let (a,b) = breakOn (reverse pat) (reverse src)
1192a1206
>     | null pat  = emptyErrorin  (reverseb, reverse a)
1192a1207
> {-# INLINE otherwisebreakOnEnd= case#-} pat src of
1194d1208
<                     (x:_) -> let h :*: t = splitAtWord x src
1195d1208
<                              in  (h, t)
1196d1208
< 
1197d1208
< -- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
1198d1208
< --
1199d1208
< -- The first element of the returned tuple is the prefix of @haystack@
1200d1208
< -- up to and including the last match of @needle@.  The second is the
1201d1208
< -- remainder of @haystack@, following the match.
1202d1208
< --
1203d1208
< -- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
1204d1208
< breakOnEnd :: Text -> Text -> (Text, Text)
1205d1208
< breakOnEnd pat src = let (a,b) = breakOn (reverse pat) (reverse src)
1206d1208
<                    in  (reverse b, reverse a)
1207d1208
< {-# INLINE breakOnEnd #-}
1208d1208
< 
1209d1208
< -- | /O(n+m)/ Find all non-overlapping instances of @needle@ in
1210d1208
< -- @haystack@.  Each element of the returned list consists of a pair:
1211d1208
< --
1212d1208
< -- * The entire string prior to the /k/th match (i.e. the prefix)
1213d1208
< --
1214c1209
< -- * The /k/th match, followed by the remainder of the string
---
> -- | /O(n+m)/ Find all non-overlapping instances of @needle@ inx:_) -> let h :*: t = splitAtWord x src
1214a1210
>                                           -- @haystack@.  Each element of the returned list consists of a pair:in  (h, t)
1216c1212
< -- Examples:
---
> -- * The entire string prior to the /k/th match (i.e. the prefix)-- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
1218d1213
< -- > breakOnAll "::" ""
1219d1213
< -- > ==> []
1220d1213
< -- > breakOnAll "/" "a/b/c/"
1221c1214
< -- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]
---
> -- * The /k/th match, followed by the remainder of the string-- The first element of the returned tuple is the prefix of @haystack@
1221a1215
> ---- up to and including the last match of @needle@.  The second is the
1221a1216
> -- Examples:-- remainder of @haystack@, following the match.
1222a1218
> -- > breakOnAll "::" ""-- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
1222a1219
> breakOnEnd-- > ==> []:: Text -> Text -> (Text, Text)
1222a1220
> breakOnEnd-- > breakOnAll "/" "a/b/c/" src = let (a,b) = breakOn (reverse pat) (reverse src)
1222a1221
>               -- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]in  (reverse b, reverse a)
1222a1222
> {-# INLINE--         breakOnEnd #-}
1224c1224
< -- second.
---
> -- second.-- | /O(n+m)/ Find all non-overlapping instances of @needle@ in
1224a1225
> ---- @haystack@.  Each element of the returned list consists of a pair:
1224a1226
> ---- In (unlikely) bad cases, this function's time complexity degrades
1224a1227
> -- towards /O(n*m)/.-- * The entire string prior to the /k/th match (i.e. the prefix)
1225a1229
> -- The @needle@ parameter may not be empty.-- * The /k/th match, followed by the remainder of the string
1225a1230
> --breakOnAll :: Text              -- ^ @needle@ to search for
1225a1231
> -- Examples:-> Text              -- ^ @haystack@ in which to search
1225a1232
> --         -> [(Text, Text)]
1225a1233
> breakOnAll-- > breakOnAll "::" ""pat src
1225a1234
> -- > ==> []| null pat  = emptyError "breakOnAll"
1225a1235
> -- > breakOnAll "/" "a/b/c/"| otherwise = go 0 empty src (indices pat src)
1225a1236
> -- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]where
1225a1237
> --  go !n p s (x:xs) = let h :*: t = splitAtWord (x-n) s
1225a1238
> -- This function is strict in its first argument, and lazy in itsh'      = append p h
1225a1239
> -- second.             in (h',t) : go x h' t xs
1225a1240
> --  go _  _ _ _      = []
1227c1242
< -- towards /O(n*m)/.
---
> -- towards /O(n*m)/.-- | /O(n)/ 'break' is like 'span', but the prefix returned is over
1227a1243
> ---- elements that fail the predicate @p@.
1227a1244
> break-- The @needle@ parameter may not be empty.:: (Char -> Bool) -> Text -> (Text, Text)
1227a1245
> breakOnAllbreak p t0 ::= break'  t0          -- ^ @needle@ to search for
1227a1246
>   where break'-> TextEmpty          = (-- ^ @haystack@ in which to searchempty, empty)
1227a1247
>         break'-> [(Text@(Chunk, Textt )ts]) =
1227a1248
> breakOnAllcase srcT.findIndex p t of
1227a1249
>     | null patNothing= emptyError-> let(ts', ts'') = break' ts
1227a1250
>     | otherwise = go 0 emptyin(Chunkindicest ts', ts'')
1227a1251
>   where     Just n | n == 0    -> (Empty, c)
1227a1252
>     go !n p s (x:xs) =otherwise h :*:->tlet= splitAtWord(a,b) = T.splitAtx-n) sn t
1227a1253
>                                h'     in= append(Chunk p hEmpty, Chunk b ts)
1227a1254
>                               in (h',t) : go x h' t xs
1227a1255
> -- | /O(n)/ 'span', applied to a predicate @p@ and text @t@, returns _  _ _ _      = []
1227a1256
> -- a pair whose first element is the longest prefix (possibly empty)
1227a1257
> -- of @t@ of elements that satisfy @p@, and whose second is the-- | /O(n)/ 'break' is like 'span', but the prefix returned is over
1227a1258
> -- remainder of the list.-- elements that fail the predicate @p@.
1227a1259
> breakspan ::::((CharChar->->Bool))->->Text->->((TextText,,Text))
1227a1260
> breakspan pp=t0break= break'(not t0. p)
1227a1261
> {-# INLINEwhere break'spanEmpty#-}           = (empty, empty)
1227a1262
>                 break' c@(Chunk t ts) =
1227a1263
>         -- | The 'group' function takes a 'Text' and returns a list of 'Text's T.findIndex p t of
1227a1264
>         -- such that the concatenation of the result is equal to the argument.      -> let (ts', ts'') = break' ts
1227a1265
>                                                            -- Moreover, each sublist in the result contains only equal elements.in (Chunk t ts', ts'')
1227a1266
>         -- For example, n | n == 0    -> (Empty, c)
1227a1267
>         --                 | otherwise -> let (a,b) = T.splitAt n t
1227a1268
>         -- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]in (Chunk a Empty, Chunk b ts)
1229d1269
< -- The @needle@ parameter may not be empty.
1230d1269
< breakOnAll :: Text              -- ^ @needle@ to search for
1231d1269
<            -> Text              -- ^ @haystack@ in which to search
1232d1269
<            -> [(Text, Text)]
1233d1269
< breakOnAll pat src
1234d1269
<     | null pat  = emptyError "breakOnAll"
1235d1269
<     | otherwise = go 0 empty src (indices pat src)
1236d1269
<   where
1237d1269
<     go !n p s (x:xs) = let h :*: t = splitAtWord (x-n) s
1238d1269
<                            h'      = append p h
1239d1269
<                        in (h',t) : go x h' t xs
1240d1269
<     go _  _ _ _      = []
1241d1269
< 
1242d1269
< -- | /O(n)/ 'break' is like 'span', but the prefix returned is over
1243d1269
< -- elements that fail the predicate @p@.
1244d1269
< break :: (Char -> Bool) -> Text -> (Text, Text)
1245d1269
< break p t0 = break' t0
1246d1269
<   where break' Empty          = (empty, empty)
1247d1269
<         break' c@(Chunk t ts) =
1248d1269
<           case T.findIndex p t of
1249d1269
<             Nothing      -> let (ts', ts'') = break' ts
1250d1269
<                             in (Chunk t ts', ts'')
1251d1269
<             Just n | n == 0    -> (Empty, c)
1252d1269
<                    | otherwise -> let (a,b) = T.splitAt n t
1253d1269
<                                   in (Chunk a Empty, Chunk b ts)
1254d1269
< 
1256d1270
< -- a pair whose first element is the longest prefix (possibly empty)
1257d1270
< -- of @t@ of elements that satisfy @p@, and whose second is the
1258d1270
< -- remainder of the list.
1259c1271
< span :: (Char -> Bool) -> Text -> (Text, Text)
---
> -- supply their own equality test.-- a pair whose first element is the longest prefix (possibly empty)
1259a1272
> group-- of @t@ of elements that satisfy @p@, and whose second is the:: Text -> [Text]
1259a1273
> group-- remainder of the list.=  groupBy (==)
1259a1274
> span{-# INLINE:: (Chargroup-> Bool#-} ) -> Text -> (Text, Text)
1261d1275
< {-# INLINE span #-}
1262d1275
< 
1263d1275
< -- | The 'group' function takes a 'Text' and returns a list of 'Text's
1264d1275
< -- such that the concatenation of the result is equal to the argument.
1265d1275
< -- Moreover, each sublist in the result contains only equal elements.
1266d1275
< -- For example,
1267d1275
< --
1268d1275
< -- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]
1269d1275
< --
1270d1275
< -- It is a special case of 'groupBy', which allows the programmer to
1271d1275
< -- supply their own equality test.
1272d1275
< group :: Text -> [Text]
1273d1275
< group =  groupBy (==)
1274d1275
< {-# INLINE group #-}
1275d1275
< 
1276c1276
< -- | The 'groupBy' function is the non-overloaded version of 'group'.
---
> {-# INLINE-- | The 'groupBy' function is the non-overloaded version of 'group'. #-}
1278d1277
< groupBy _  Empty        = []
1279d1277
< groupBy eq (Chunk t ts) = cons x ys : groupBy eq zs
1280d1277
<                           where (ys,zs) = span (eq x) xs
1281d1277
<                                 x  = T.unsafeHead t
1282d1277
<                                 xs = chunk (T.unsafeTail t) ts
1283d1277
< 
1284d1277
< -- | /O(n)/ Return all initial segments of the given 'Text',
1285d1277
< -- shortest first.
1286d1277
< inits :: Text -> [Text]
1287d1277
< inits = (Empty :) . inits'
1288d1277
<   where inits' Empty        = []
1289c1278
<         inits' (Chunk t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
---
> groupBy-- | The 'group' function takes a 'Text' and returns a list of 'Text's_  Empty        = []
1289a1279
> groupBy-- such that the concatenation of the result is equal to the argument.eq (Chunk t ts) = cons x ys : groupBy eq zs
1289a1280
> -- Moreover, each sublist in the result contains only equal elements.where (ys,zs) = span (eq x) xs
1289a1281
> -- For example,                 x  = T.unsafeHead t
1289a1282
> --                              xs = chunk (T.unsafeTail t) ts
1289a1283
> -- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]
1289a1284
> ---- | /O(n)/ Return all initial segments of the given 'Text',
1289a1285
> -- shortest first.-- It is a special case of 'groupBy', which allows the programmer to
1289a1286
> inits-- supply their own equality test.:: Text -> [Text]
1289a1287
> group ::= (TextEmpty->:)[Text. inits']
1289a1288
> groupwhere= inits'Empty==)       = []
1289a1289
> {-# INLINEinits'(Chunk#-}  t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
1291d1290
< 
1292d1290
< -- | /O(n)/ Return all final segments of the given 'Text', longest
1293d1290
< -- first.
1294d1290
< tails :: Text -> [Text]
1295d1290
< tails Empty         = Empty : []
1296d1290
< tails ts@(Chunk t ts')
1297c1291
<   | T.length t == 1 = ts : tails ts'
---
> -- | The 'groupBy' function is the non-overloaded version of 'group'.
1297a1292
> groupBy-- | /O(n)/ Return all final segments of the given 'Text', longest:: (Char -> Char -> Bool) -> Text -> [Text]
1297a1293
> groupBy-- first.  Empty        = []
1297a1294
> groupBytails ::eqTextChunk-> [tText) = cons x ys : groupBy eq zs
1297a1295
> tails Empty         = Emptywhere: [](ys,zs) = span (eq x) xs
1297a1296
>  tails ts@(Chunk t ts')          x  = T.unsafeHead t
1297a1297
>    | T.length t == 1 = ts : tailsxsts'= chunk (T.unsafeTail t) ts
1299d1298
< 
1300d1298
< -- $split
1301d1298
< --
1302d1298
< -- Splitting functions in this library do not perform character-wise
1303d1298
< -- copies to create substrings; they just construct new 'Text's that
1304d1298
< -- are slices of the original.
1305c1299
< 
---
> -- | /O(n)/ Return all initial segments of the given 'Text',
1305a1300
> -- $split-- shortest first.
1305a1301
> inits--    :: Text -> [Text]
1305a1302
> inits-- Splitting functions in this library do not perform character-wise= (Empty :) . inits'
1305a1303
> -- copies to create substrings; they just construct new 'Text's thatwhere inits' Empty        = []
1305a1304
>                                                                   -- are slices of the original. (Chunk t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
1305a1305
>                                                                                              ++ L.map (Chunk t) (inits' ts)
1307d1306
< -- argument (which cannot be an empty string), consuming the
1308d1306
< -- delimiter. An empty delimiter is invalid, and will cause an error
1309d1306
< -- to be raised.
1310d1306
< --
1311d1306
< -- Examples:
1312d1306
< --
1313c1307
< -- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"]
---
> -- argument (which cannot be an empty string), consuming the-- | /O(n)/ Return all final segments of the given 'Text', longest
1313a1308
> -- first.-- delimiter. An empty delimiter is invalid, and will cause an error
1313a1309
> tails-- to be raised.:: Text -> [Text]
1313a1310
> tails--    Empty         = Empty : []
1313a1311
> tails-- Examples:@(Chunk t ts')
1313a1312
> --| T.length t == 1 = ts : tails ts'
1313a1313
> -- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"] otherwise       = ts : tails (Chunk (T.unsafeTail t) ts')
1315d1314
< -- > splitOn "x"    "x"                == ["",""]
1316d1314
< --
1317c1315
< -- and
---
> -- $split-- > splitOn "x"    "x"                == ["",""]
1319c1317
< -- > intercalate s . splitOn s         == id
---
> -- and-- Splitting functions in this library do not perform character-wise
1319a1318
> ---- copies to create substrings; they just construct new 'Text's that
1319a1319
> -- are slices of the original.-- > intercalate s . splitOn s         == id
1321d1320
< --
1322d1320
< -- (Note: the string @s@ to split on above cannot be empty.)
1323d1320
< --
1324d1320
< -- This function is strict in its first argument, and lazy in its
1325d1320
< -- second.
1326d1320
< --
1327d1320
< -- In (unlikely) bad cases, this function's time complexity degrades
1328d1320
< -- towards /O(n*m)/.
1329c1321
< splitOn :: Text
---
> ---- | /O(m+n)/ Break a 'Text' into pieces separated by the first 'Text'
1329a1322
> -- argument (which cannot be an empty string), consuming the
1329a1323
> ---- delimiter. An empty delimiter is invalid, and will cause an error
1329a1324
> -- to be raised.-- This function is strict in its first argument, and lazy in its
1329a1325
> ---- second.
1329a1326
> ---- Examples:
1329a1327
> ---- In (unlikely) bad cases, this function's time complexity degrades
1329a1328
> -- towards /O(n*m)/.-- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"]
1329a1329
> splitOn-- > splitOn "aaa"  "aaaXaaaXaaaXaaa"  == ["","X","X","X",""]:: Text
1329a1330
> -- > splitOn "x"    "x"                == ["",""]-- ^ String to split on. If this string is empty, an error
1329a1331
> --      -- will occur.
1329a1332
> -- and  -> Text
1329a1333
> --      -- ^ Input text.
1329a1334
> -- > intercalate s . splitOn s         == id-> [Text]
1329a1335
> splitOn-- > splitOn (singleton c)             == split (==c)pat src
1329a1336
> --  | null pat        = emptyError "splitOn"
1329a1337
> -- (Note: the string @s@ to split on above cannot be empty.)| isSingleton pat = split (== head pat) src
1329a1338
> --  | otherwise       = go 0 (indices pat src) src
1329a1339
> -- This function is strict in its first argument, and lazy in itswhere
1329a1340
> -- second.go  _ []     cs = [cs]
1329a1341
> --  go !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
1329a1342
> -- In (unlikely) bad cases, this function's time complexity degradesin  h : go (x+l) xs (dropWords l t)
1329a1343
> -- towards /O(n*m)/.l = foldlChunks (\a (T.Text _ _ b) -> a + fromIntegral b) 0 pat
1329a1344
> splitOn{-# INLINE:: Text[1] splitOn #-}
1331d1345
<         -- will occur.
1332d1345
<         -> Text
1333d1345
<         -- ^ Input text.
1334c1346
<         -> [Text]
---
> {-# RULES-- will occur.
1334a1347
> "LAZY TEXT splitOn/singleton -> split/=="-> Text                           [~1] forall c t.
1334a1348
>     splitOn-- ^ Input text.(singleton c) t = split (==c) t
1334a1349
>   #-}   -> [Text]
1336d1350
<     | null pat        = emptyError "splitOn"
1337d1350
<     | isSingleton pat = split (== head pat) src
1338d1350
<     | otherwise       = go 0 (indices pat src) src
1339d1350
<   where
1340d1350
<     go  _ []     cs = [cs]
1341d1350
<     go !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
1342d1350
<                       in  h : go (x+l) xs (dropWords l t)
1343d1350
<     l = foldlChunks (\a (T.Text _ _ b) -> a + fromIntegral b) 0 pat
1344d1350
< {-# INLINE [1] splitOn #-}
1345d1350
< 
1346d1350
< {-# RULES
1347d1350
< "LAZY TEXT splitOn/singleton -> split/==" [~1] forall c t.
1348d1350
<     splitOn (singleton c) t = split (==c) t
1349c1351
<   #-}
---
> -- | /O(n)/ Splits a 'Text' into components delimited by separators, null pat        = emptyError "splitOn"
1349a1352
> -- where the predicate returns True for a separator element.  The isSingleton pat = split (== head pat) src
1349a1353
> -- resulting components do not contain the separators.  Two adjacent otherwise       = go 0 (indices pat src) src
1349a1354
> -- separators result in an empty component in the output.  eg.where
1349a1355
> --  go  _ []     cs = [cs]
1349a1356
> -- > split (=='a') "aabbaca" == ["","","bb","c",""] !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
1349a1357
>                                              -- > split (=='a') []        == [""]in  h : go (x+l) xs (dropWords l t)
1349a1358
> split =::foldlChunks(Char -> Bool\a (->T.TextText _->_[bText) ->] a + fromIntegral b) 0 pat
1349a1359
> {-# INLINEsplit _ Empty[1]=splitOn[Empty]#-}
1349a1360
> split p (Chunk t0 ts0) = comb [] (T.split p t0) ts0
1349a1361
> {-# RULESwhere comb acc (s:[]) Empty        = revChunks (s:acc) : []
1349a1362
> "LAZY TEXT splitOn/singleton -> split/=="comb acc (s:[]) (Chunk t ts) = comb[~1]:forallacc) (T.split t.   p t) ts
1349a1363
>     splitOncomb(singletonacc (s:ss)c)tst = split (=== crevChunks) t      (s:acc) : comb [] ss ts
1349a1364
>   #-}   comb _   []     _            = impossibleError "split"
1349a1365
> {-# INLINE split #-}
1353d1368
< -- resulting components do not contain the separators.  Two adjacent
1354d1368
< -- separators result in an empty component in the output.  eg.
1355d1368
< --
1356d1368
< -- > split (=='a') "aabbaca" == ["","","bb","c",""]
1357d1368
< -- > split (=='a') []        == [""]
1358d1368
< split :: (Char -> Bool) -> Text -> [Text]
1359d1368
< split _ Empty = [Empty]
1360d1368
< split p (Chunk t0 ts0) = comb [] (T.split p t0) ts0
1361d1368
<   where comb acc (s:[]) Empty        = revChunks (s:acc) : []
1362d1368
<         comb acc (s:[]) (Chunk t ts) = comb (s:acc) (T.split p t) ts
1363c1369
<         comb acc (s:ss) ts           = revChunks (s:acc) : comb [] ss ts
---
> -- length of the input. Examples:-- resulting components do not contain the separators.  Two adjacent
1363a1370
> ---- separators result in an empty component in the output.  eg.
1363a1371
> ---- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]
1363a1372
> -- > split (=='a') "aabbaca" == ["","","bb","c",""]-- > chunksOf 4 "haskell.org" == ["hask","ell.","org"]
1363a1373
> chunksOf-- > split (=='a') []        == [""]:: Int64 -> Text -> [Text]
1363a1374
> splitchunksOf:: (Char= go-> Bool) -> Text -> [Text]
1363a1375
> splitwhere Empty = [Empty]
1363a1376
> splitgopt(Chunk= caset0splitAt) =kcombt of[] (T.split p t0) ts0
1363a1377
>   where comb acc(a,b(s:[]null) Emptya    -> [] = revChunks (s:acc) : []
1363a1378
>         comb acc (s:[]otherwise) (Chunk t->tsa):=gob  (s:acc) (T.split p t) ts
1363a1379
> {-# INLINEchunksOf (s:ss#-}) ts           = revChunks (s:acc) : comb [] ss ts
1365d1380
< {-# INLINE split #-}
1366d1380
< 
1367d1380
< -- | /O(n)/ Splits a 'Text' into components of length @k@.  The last
1368d1380
< -- element may be shorter than the other chunks, depending on the
1369d1380
< -- length of the input. Examples:
1370d1380
< --
1371c1381
< -- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]
---
> {-# INLINE-- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at #-}
1371a1382
> -- newline 'Char's. The resulting strings do not contain newlines.
1371a1383
> lines-- | /O(n)/ Splits a 'Text' into components of length @k@.  The last:: Text -> [Text]
1371a1384
> lines-- element may be shorter than the other chunks, depending on theEmpty = []
1371a1385
> lines-- length of the input. Examples:t = let (l,t') = break ((==) '\n') t
1371a1386
> --        in l : if null t' then []
1371a1387
> -- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]else lines (tail t')
1373d1388
< chunksOf :: Int64 -> Text -> [Text]
1374d1388
< chunksOf k = go
1375d1388
<   where
1376d1388
<     go t = case splitAt k t of
1377c1389
<              (a,b) | null a    -> []
---
> chunksOf-- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's:: Int64 -> Text -> [Text]
1377a1390
> chunksOf-- representing white space. = go
1377a1391
> wordswhere:: Text -> [Text]
1377a1392
> words=tL.filter= case splitAt(not . knull of) . split isSpace
1377a1393
> {-# INLINE wordsa,b)#-} null a    -> []
1379d1394
< {-# INLINE chunksOf #-}
1380d1394
< 
1381d1394
< -- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at
1382d1394
< -- newline 'Char's. The resulting strings do not contain newlines.
1383d1394
< lines :: Text -> [Text]
1384d1394
< lines Empty = []
1385d1394
< lines t = let (l,t') = break ((==) '\n') t
1386d1394
<           in l : if null t' then []
1387d1394
<                  else lines (tail t')
1388d1394
< 
1389d1394
< -- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's
1390d1394
< -- representing white space.
1391d1394
< words :: Text -> [Text]
1392d1394
< words = L.filter (not . null) . split isSpace
1393d1394
< {-# INLINE words #-}
1394d1394
< 
1395c1395
< -- | /O(n)/ Joins lines, after appending a terminating newline to
---
> {-# INLINE-- | /O(n)/ Joins lines, after appending a terminating newline to #-}
1397d1396
< unlines :: [Text] -> Text
1398d1396
< unlines = concat . L.map (`snoc` '\n')
1399d1396
< {-# INLINE unlines #-}
1400d1396
< 
1401d1396
< -- | /O(n)/ Joins words using single space characters.
1402d1396
< unwords :: [Text] -> Text
1403c1397
< unwords = intercalate (singleton ' ')
---
> unlines-- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at:: [Text] -> Text
1403a1398
> unlines-- newline 'Char's. The resulting strings do not contain newlines.= concat . L.map (`snoc` '\n')
1403a1399
> lines{-# INLINE:: Textunlines-> [Text#-}]
1403a1400
> lines Empty = []
1403a1401
> lines-- | /O(n)/ Joins words using single space characters. = let (l,t') = break ((==) '\n') t
1403a1402
>                                                unwords ::in[Text :]if->nullTextt' then []
1403a1403
>                                                unwords = intercalateelse lines(singletontail' ')
1405d1404
< 
1406d1404
< -- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns
1407d1404
< -- 'True' iff the first is a prefix of the second.  Subject to fusion.
1408d1404
< isPrefixOf :: Text -> Text -> Bool
1409c1405
< isPrefixOf Empty _  = True
---
> -- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's
1409a1406
> -- representing white space.-- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns
1409a1407
> words-- 'True' iff the first is a prefix of the second.  Subject to fusion.:: Text -> [Text]
1409a1408
> wordsisPrefixOf= L.filter:: Textnot-> .Text->) .Bool isSpace
1409a1409
> {-# INLINE words #-}_  = True
1411d1410
< isPrefixOf (Chunk x xs) (Chunk y ys)
1412d1410
<     | lx == ly  = x == y  && isPrefixOf xs ys
1413d1410
<     | lx <  ly  = x == yh && isPrefixOf xs (Chunk yt ys)
1414d1410
<     | otherwise = xh == y && isPrefixOf (Chunk xt xs) ys
1415c1411
<   where (xh,xt) = T.splitAt ly x
---
> isPrefixOf-- | /O(n)/ Joins lines, after appending a terminating newline to(Chunk x xs) (Chunk y ys)
1415a1412
> -- each.| lx == ly  = x == y  && isPrefixOf xs ys
1415a1413
> unlines| lx::< [Textly  ] ->x ==yh && isPrefixOf xs (Chunk yt ys)
1415a1414
> unlines| otherwise= concat=.xh== y(`&&snocisPrefixOf` '\n')  (Chunk xt xs) ys
1415a1415
> {-# INLINEwhere (xhunlines,xt) = T.splitAt#-}      ly x
1417d1416
<         lx = T.length x
1418d1416
<         ly = T.length y
1419d1416
< {-# INLINE [1] isPrefixOf #-}
1420c1417
< 
---
> -- | /O(n)/ Joins words using single space characters.lx = T.length x
1420a1418
> unwords ::   [TextT.length] -> Texty
1420a1419
> unwords{-# INLINE= intercalate[1] isPrefixOfsingleton#-}    ' ')
1420a1420
> {-# INLINE unwords #-}
1422d1421
< "LAZY TEXT isPrefixOf -> fused" [~1] forall s t.
1423d1421
<     isPrefixOf s t = S.isPrefixOf (stream s) (stream t)
1424d1421
< "LAZY TEXT isPrefixOf -> unfused" [1] forall s t.
1425d1421
<     S.isPrefixOf (stream s) (stream t) = isPrefixOf s t
1426d1421
<   #-}
1427d1421
< 
1428d1421
< -- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returns
1429d1421
< -- 'True' iff the first is a suffix of the second.
1430d1421
< isSuffixOf :: Text -> Text -> Bool
1431d1421
< isSuffixOf x y = reverse x `isPrefixOf` reverse y
1432d1421
< {-# INLINE isSuffixOf #-}
1433d1421
< -- TODO: a better implementation
1434d1421
< 
1435c1422
< -- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns
---
> "LAZY TEXT isPrefixOf -> fused"-- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns[~1] forall s t.
1435a1423
> -- 'True' iff the first is a prefix of the second.  Subject to fusion.isPrefixOf s t = S.isPrefixOf (stream s) (stream t)
1435a1424
> isPrefixOf"LAZY TEXT isPrefixOf -> unfused":: Text -> Text -> Bool[1] forall s t.
1435a1425
> isPrefixOfS.isPrefixOf _stream= Trues) (stream t) = isPrefixOf s t
1435a1426
> isPrefixOf#-}      _ Empty  = False
1435a1427
> isPrefixOf (Chunk x xs) (Chunk y ys)
1435a1428
> -- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returns lx == ly  = x == y  && isPrefixOf xs ys
1435a1429
> -- 'True' iff the first is a suffix of the second. lx <  ly  = x == yh && isPrefixOf xs (Chunk yt ys)
1435a1430
> isSuffixOf otherwise:: Text= xh->==Text &&->isPrefixOfBool      (Chunk xt xs) ys
1435a1431
> isSuffixOfwhere (xh,xty)==reversex `lyisPrefixOf      ` reverse y
1435a1432
>         {-# INLINEyh,isSuffixOfyt) = T.splitAt#-}   lx y
1435a1433
>         -- TODO: a better implementation = T.length x
1435a1434
>                 ly = T.length y
1435a1435
> {-# INLINE-- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns[1] isPrefixOf #-}
1437d1436
< -- within the second.
1438d1436
< --
1439d1436
< -- This function is strict in its first argument, and lazy in its
1440d1436
< -- second.
1441d1436
< --
1442c1437
< -- In (unlikely) bad cases, this function's time complexity degrades
---
> {-# RULES-- within the second.
1442a1438
> "LAZY TEXT isPrefixOf -> fused"--                              [~1] forall s t.
1442a1439
> -- This function is strict in its first argument, and lazy in its s t = S.isPrefixOf (stream s) (stream t)
1442a1440
> "LAZY TEXT isPrefixOf -> unfused"-- second.                        [1] forall s t.
1442a1441
> --  S.isPrefixOf (stream s) (stream t) = isPrefixOf s t
1442a1442
> -- In (unlikely) bad cases, this function's time complexity degrades#-}
1445d1444
< isInfixOf needle haystack
1446d1444
<     | null needle        = True
1447d1444
<     | isSingleton needle = S.elem (head needle) . S.stream $ haystack
1448d1444
<     | otherwise          = not . L.null . indices needle $ haystack
1449d1444
< {-# INLINE [1] isInfixOf #-}
1450c1445
< 
---
> isInfixOf-- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returnsneedle haystack
1450a1446
> -- 'True' iff the first is a suffix of the second.| null needle        = True
1450a1447
> isSuffixOf| isSingleton:: Textneedle-> Text= ->S.elem(head needle) . S.stream $ haystack
1450a1448
> isSuffixOf| otherwise y = reverse x `notisPrefixOf. L.null` reverse. indices needle $ haystack
1450a1449
> {-# INLINE isSuffixOf[1] isInfixOf#-}#-}
1450a1450
> -- TODO: a better implementation
1452d1451
< "LAZY TEXT isInfixOf/singleton -> S.elem/S.stream" [~1] forall n h.
1453d1451
<     isInfixOf (singleton n) h = S.elem n (S.stream h)
1454d1451
<   #-}
1455d1451
< 
1456d1451
< -------------------------------------------------------------------------------
1457d1451
< -- * View patterns
1458d1451
< 
1459d1451
< -- | /O(n)/ Return the suffix of the second string if its prefix
1460d1451
< -- matches the entire first string.
1461d1451
< --
1462c1452
< -- Examples:
---
> "LAZY TEXT isInfixOf/singleton -> S.elem/S.stream"-- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns[~1] forall n h.
1462a1453
> -- 'True' iff the first is contained, wholly and intact, anywhereisInfixOf (singleton n) h = S.elem n (S.stream h)
1462a1454
> -- within the second.#-}
1464d1455
< -- > stripPrefix "foo" "foobar" == Just "bar"
1465d1455
< -- > stripPrefix ""    "baz"    == Just "baz"
1466c1456
< -- > stripPrefix "foo" "quux"   == Nothing
---
> -- This function is strict in its first argument, and lazy in its-------------------------------------------------------------------------------
1466a1457
> -- second.-- * View patterns
1468d1458
< -- This is particularly useful with the @ViewPatterns@ extension to
1469c1459
< -- GHC, as follows:
---
> -- | /O(n)/ Return the suffix of the second string if its prefix-- In (unlikely) bad cases, this function's time complexity degrades
1469a1460
> -- towards /O(n*m)/.-- matches the entire first string.
1469a1461
> isInfixOf--        :: Text -> Text -> Bool
1469a1462
> isInfixOf-- Examples: haystack
1469a1463
> --  | null needle        = True
1469a1464
> -- > stripPrefix "foo" "foobar" == Just "bar" isSingleton needle = S.elem (head needle) . S.stream $ haystack
1469a1465
> -- > stripPrefix ""    "baz"    == Just "baz" otherwise          = not . L.null . indices needle $ haystack
1469a1466
> {-# INLINE-- > stripPrefix "foo" "quux"   == Nothing[1] isInfixOf #-}
1471c1468
< -- > {-# LANGUAGE ViewPatterns #-}
---
> {-# RULES-- This is particularly useful with the @ViewPatterns@ extension to
1471a1469
> "LAZY TEXT isInfixOf/singleton -> S.elem/S.stream"-- GHC, as follows:                                [~1] forall n h.
1471a1470
> --  isInfixOf (singleton n) h = S.elem n (S.stream h)
1471a1471
> -- > {-# LANGUAGE ViewPatterns #-}#-}
1474d1473
< -- > fnordLength :: Text -> Int
1475c1474
< -- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf
---
> -- > fnordLength :: Text -> Int-------------------------------------------------------------------------------
1475a1475
> -- * View patterns-- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf
1477d1476
< stripPrefix :: Text -> Text -> Maybe Text
1478d1476
< stripPrefix p t
1479d1476
<     | null p    = Just t
1480d1476
<     | otherwise = case commonPrefixes p t of
1481d1476
<                     Just (_,c,r) | null c -> Just r
1482d1476
<                     _                     -> Nothing
1483d1476
< 
1484d1476
< -- | /O(n)/ Find the longest non-empty common prefix of two strings
1485d1476
< -- and return it, along with the suffixes of each string at which they
1486d1476
< -- no longer match.
1487d1476
< --
1488d1476
< -- If the strings do not have a common prefix or either one is empty,
1489d1476
< -- this function returns 'Nothing'.
1490d1476
< --
1491d1476
< -- Examples:
1492d1476
< --
1493d1476
< -- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
1494d1476
< -- > commonPrefixes "veeble" "fetzer"  == Nothing
1495d1476
< -- > commonPrefixes "" "baz"           == Nothing
1496d1476
< commonPrefixes :: Text -> Text -> Maybe (Text,Text,Text)
1497d1476
< commonPrefixes Empty _ = Nothing
1498d1476
< commonPrefixes _ Empty = Nothing
1499d1476
< commonPrefixes a0 b0   = Just (go a0 b0 [])
1500c1477
<   where
---
> stripPrefix-- | /O(n)/ Return the suffix of the second string if its prefix:: Text -> Text -> Maybe Text
1500a1478
> stripPrefix-- matches the entire first string.p t
1500a1479
> --  | null p    = Just t
1500a1480
> -- Examples:| otherwise = case commonPrefixes p t of
1500a1481
> --                  Just (_,c,r) | null c -> Just r
1500a1482
> -- > stripPrefix "foo" "foobar" == Just "bar"_                     -> Nothing
1500a1483
> -- > stripPrefix ""    "baz"    == Just "baz"
1500a1484
> -- > stripPrefix "foo" "quux"   == Nothing-- | /O(n)/ Find the longest non-empty common prefix of two strings
1500a1485
> ---- and return it, along with the suffixes of each string at which they
1500a1486
> -- no longer match.-- This is particularly useful with the @ViewPatterns@ extension to
1500a1487
> ---- GHC, as follows:
1500a1488
> ---- If the strings do not have a common prefix or either one is empty,
1500a1489
> -- > {-# LANGUAGE ViewPatterns #-}-- this function returns 'Nothing'.
1500a1490
> ---- > import Data.Text.Lazy as T
1500a1491
> -- >-- Examples:
1500a1492
> ---- > fnordLength :: Text -> Int
1500a1493
> -- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf-- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
1500a1494
> -- > commonPrefixes "veeble" "fetzer"  == Nothing-- > fnordLength _                                 = -1
1500a1495
> stripPrefix-- > commonPrefixes "" "baz"           == Nothing:: Text -> Text -> Maybe Text
1500a1496
> stripPrefixcommonPrefixes t:: Text -> Text -> Maybe (Text,Text,Text)
1500a1497
> commonPrefixes null p   Empty= Just_ t Nothing
1500a1498
> commonPrefixes otherwise_=Empty commonPrefixes= Nothing      p t of
1500a1499
> commonPrefixes a0 b0Just= (Just_,c,r)go|a0b0 c]->)  Just r
1500a1500
>   where             _                     -> Nothing
1502d1501
<         = case T.commonPrefixes x y of
1503d1501
<             Just (p,a,b)
1504d1501
<               | T.null a  -> go xs (chunk b ys) (p:ps)
1505d1501
<               | T.null b  -> go (chunk a xs) ys (p:ps)
1506d1501
<               | otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
1507d1501
<             Nothing       -> (fromChunks (L.reverse ps),t0,t1)
1508d1501
<     go t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)
1509d1501
< 
1510d1501
< -- | /O(n)/ Return the prefix of the second string if its suffix
1511d1501
< -- matches the entire first string.
1512c1502
< --
---
> -- | /O(n)/ Find the longest non-empty common prefix of two strings= case T.commonPrefixes x y of
1512a1503
> -- and return it, along with the suffixes of each string at which theyJust (p,a,b)
1512a1504
> -- no longer match.| T.null a  -> go xs (chunk b ys) (p:ps)
1512a1505
> --            | T.null b  -> go (chunk a xs) ys (p:ps)
1512a1506
> -- If the strings do not have a common prefix or either one is empty,| otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
1512a1507
> -- this function returns 'Nothing'.Nothing       -> (fromChunks (L.reverse ps),t0,t1)
1512a1508
> --  go t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)
1514d1509
< --
1515d1509
< -- > stripSuffix "bar" "foobar" == Just "foo"
1516d1509
< -- > stripSuffix ""    "baz"    == Just "baz"
1517c1510
< -- > stripSuffix "foo" "quux"   == Nothing
---
> ---- | /O(n)/ Return the prefix of the second string if its suffix
1517a1511
> -- matches the entire first string.-- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
1517a1512
> ---- > commonPrefixes "veeble" "fetzer"  == Nothing
1517a1513
> -- Examples:-- > commonPrefixes "" "baz"           == Nothing
1517a1514
> commonPrefixes--             :: Text -> Text -> Maybe (Text,Text,Text)
1517a1515
> commonPrefixes-- > stripSuffix "bar" "foobar" == Just "foo" _ = Nothing
1517a1516
> commonPrefixes-- > stripSuffix ""    "baz"    == Just "baz" Empty = Nothing
1517a1517
> commonPrefixes-- > stripSuffix "foo" "quux"   == Nothing b0   = Just (go a0 b0 [])
1517a1518
> --where
1517a1519
> -- This is particularly useful with the @ViewPatterns@ extension to t0@(Chunk x xs) t1@(Chunk y ys) ps
1517a1520
> -- GHC, as follows:= case T.commonPrefixes x y of
1517a1521
> --          Just (p,a,b)
1517a1522
> -- > {-# LANGUAGE ViewPatterns #-} T.null a  -> go xs (chunk b ys) (p:ps)
1517a1523
> -- > import Data.Text.Lazy as T T.null b  -> go (chunk a xs) ys (p:ps)
1517a1524
> -- >          | otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
1517a1525
> -- > quuxLength :: Text -> Int       -> (fromChunks (L.reverse ps),t0,t1)
1517a1526
> -- > quuxLength (stripSuffix "quux" -> Just pre) = T.length pre t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)
1517a1527
> -- > quuxLength _                                = -1
1517a1528
> stripSuffix-- | /O(n)/ Return the prefix of the second string if its suffix:: Text -> Text -> Maybe Text
1517a1529
> stripSuffix-- matches the entire first string.p t = reverse `fmap` stripPrefix (reverse p) (reverse t)
1518a1531
> -- Examples:-- | /O(n)/ 'filter', applied to a predicate and a 'Text',
1518a1532
> ---- returns a 'Text' containing those characters that satisfy the
1518a1533
> -- predicate.-- > stripSuffix "bar" "foobar" == Just "foo"
1518a1534
> filter-- > stripSuffix ""    "baz"    == Just "baz":: (Char -> Bool) -> Text -> Text
1518a1535
> filter-- > stripSuffix "foo" "quux"   == Nothingp t = unstream (S.filter p (stream t))
1518a1536
> --{-# INLINE filter #-}
1520d1537
< -- GHC, as follows:
1521d1537
< --
1522d1537
< -- > {-# LANGUAGE ViewPatterns #-}
1523d1537
< -- > import Data.Text.Lazy as T
1524d1537
< -- >
1525c1538
< -- > quuxLength :: Text -> Int
---
> -- GHC, as follows:-- | /O(n)/ The 'find' function takes a predicate and a 'Text', and
1525a1539
> ---- returns the first element in matching the predicate, or 'Nothing'
1525a1540
> -- if there is no such element.-- > {-# LANGUAGE ViewPatterns #-}
1525a1541
> find-- > import Data.Text.Lazy as T:: (Char -> Bool) -> Text -> Maybe Char
1525a1542
> -- > p t = S.findBy p (stream t)
1525a1543
> {-# INLINE-- > quuxLength :: Text -> Intfind #-}
1527d1544
< -- > quuxLength _                                = -1
1528d1544
< stripSuffix :: Text -> Text -> Maybe Text
1529d1544
< stripSuffix p t = reverse `fmap` stripPrefix (reverse p) (reverse t)
1530d1544
< 
1531d1544
< -- | /O(n)/ 'filter', applied to a predicate and a 'Text',
1532d1544
< -- returns a 'Text' containing those characters that satisfy the
1533d1544
< -- predicate.
1534c1545
< filter :: (Char -> Bool) -> Text -> Text
---
> -- > quuxLength _                                = -1-- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
1534a1546
> stripSuffix-- and returns the pair of 'Text's with elements which do and do not:: Text -> Text -> Maybe Text
1534a1547
> stripSuffix-- satisfy the predicate, respectively; i.e. t = reverse `fmap` stripPrefix (reverse p) (reverse t)
1534a1548
> --
1534a1549
> -- > partition p t == (filter p t, filter (not . p) t)-- | /O(n)/ 'filter', applied to a predicate and a 'Text',
1534a1550
> partition-- returns a 'Text' containing those characters that satisfy the:: (Char -> Bool) -> Text -> (Text, Text)
1534a1551
> partition-- predicate.p t = (filter p t, filter (not . p) t)
1534a1552
> filter{-# INLINE:: (Charpartition-> Bool#-}) -> Text -> Text
1536d1553
< {-# INLINE filter #-}
1537d1553
< 
1538d1553
< -- | /O(n)/ The 'find' function takes a predicate and a 'Text', and
1539c1554
< -- returns the first element in matching the predicate, or 'Nothing'
---
> {-# INLINE-- | /O(n)/ 'Text' index (subscript) operator, starting from 0. #-}
1539a1555
> index :: Text -> Int64 -> Char
1539a1556
> index-- | /O(n)/ The 'find' function takes a predicate and a 'Text', andt n = S.index (stream t) n
1539a1557
> {-# INLINE-- returns the first element in matching the predicate, or 'Nothing'index #-}
1541d1558
< find :: (Char -> Bool) -> Text -> Maybe Char
1542d1558
< find p t = S.findBy p (stream t)
1543d1558
< {-# INLINE find #-}
1544d1558
< 
1545d1558
< -- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
1546d1558
< -- and returns the pair of 'Text's with elements which do and do not
1547c1559
< -- satisfy the predicate, respectively; i.e.
---
> find-- | /O(n+m)/ The 'count' function returns the number of times the:: (Char -> Bool) -> Text -> Maybe Char
1547a1560
> find-- query string appears in the given 'Text'. An empty query string is t = S.findBy p (stream t)
1547a1561
> {-# INLINE-- invalid, and will cause an error to be raised. #-}
1549d1562
< -- > partition p t == (filter p t, filter (not . p) t)
1550d1562
< partition :: (Char -> Bool) -> Text -> (Text, Text)
1551d1562
< partition p t = (filter p t, filter (not . p) t)
1552d1562
< {-# INLINE partition #-}
1553c1563
< 
---
> -- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
1553a1564
> -- towards /O(n*m)/.-- and returns the pair of 'Text's with elements which do and do not
1553a1565
> count-- satisfy the predicate, respectively; i.e.:: Text -> Text -> Int64
1553a1566
> --count pat src
1553a1567
> -- > partition p t == (filter p t, filter (not . p) t)| null pat        = emptyError "count"
1553a1568
> partition| otherwise:: (Char -> Bool= go)0->(indices ->patTextsrc,)Text)
1553a1569
> partitionwhere gop!t =](filter= np t, filter (not . p) t)
1553a1570
> {-# INLINEgo partition!n (_:xs) #-}= go (n+1) xs
1553a1571
> {-# INLINE [1] count #-}
1555d1572
< index :: Text -> Int64 -> Char
1556d1572
< index t n = S.index (stream t) n
1557d1572
< {-# INLINE index #-}
1558c1573
< 
---
> index{-# RULES:: Text -> Int64 -> Char
1558a1574
> index"LAZY TEXT count/singleton -> countChar" n = S.index (stream t) n         [~1] forall c t.
1558a1575
> {-# INLINEcount (indexsingleton#-} c) t = countChar c t
1558a1576
>   #-}
1560d1577
< -- query string appears in the given 'Text'. An empty query string is
1561d1577
< -- invalid, and will cause an error to be raised.
1562d1577
< --
1563c1578
< -- In (unlikely) bad cases, this function's time complexity degrades
---
> -- | /O(n)/ The 'countChar' function returns the number of times the-- query string appears in the given 'Text'. An empty query string is
1563a1579
> -- invalid, and will cause an error to be raised.-- query element appears in the given 'Text'.  Subject to fusion.
1563a1580
> --countChar :: Char -> Text -> Int64
1563a1581
> countChar-- In (unlikely) bad cases, this function's time complexity degradesc t = S.countChar c (stream t)
1565d1582
< count :: Text -> Text -> Int64
1566d1582
< count pat src
1567d1582
<     | null pat        = emptyError "count"
1568d1582
<     | otherwise       = go 0 (indices pat src)
1569d1582
<   where go !n []     = n
1570d1582
<         go !n (_:xs) = go (n+1) xs
1571d1582
< {-# INLINE [1] count #-}
1572d1582
< 
1573d1582
< {-# RULES
1574d1582
< "LAZY TEXT count/singleton -> countChar" [~1] forall c t.
1575d1582
<     count (singleton c) t = countChar c t
1576d1582
<   #-}
1577d1582
< 
1578d1582
< -- | /O(n)/ The 'countChar' function returns the number of times the
1579d1582
< -- query element appears in the given 'Text'.  Subject to fusion.
1580d1582
< countChar :: Char -> Text -> Int64
1581d1582
< countChar c t = S.countChar c (stream t)
1582d1582
< 
1583d1582
< -- | /O(n)/ 'zip' takes two 'Text's and returns a list of
1584d1582
< -- corresponding pairs of bytes. If one input 'Text' is short,
1585d1582
< -- excess elements of the longer 'Text' are discarded. This is
1586d1582
< -- equivalent to a pair of 'unpack' operations.
1587d1582
< zip :: Text -> Text -> [(Char,Char)]
1588d1582
< zip a b = S.unstreamList $ S.zipWith (,) (stream a) (stream b)
1589c1583
< {-# INLINE [0] zip #-}
---
> count-- | /O(n)/ 'zip' takes two 'Text's and returns a list of:: Text -> Text -> Int64
1589a1584
> count-- corresponding pairs of bytes. If one input 'Text' is short, src
1589a1585
> -- excess elements of the longer 'Text' are discarded. This is null pat        = emptyError "count"
1589a1586
> -- equivalent to a pair of 'unpack' operations. otherwise       = go 0 (indices pat src)
1589a1587
> zipwhere:: Text !n->[]Text ->= n(Char,Char)]
1589a1588
>  zip a b go= S.unstreamList!n (_:xs) = go$(nS.zipWith+1) xs   (,) (stream a) (stream b)
1589a1589
> {-# INLINE [1] countzip #-}#-}
1591d1590
< -- | /O(n)/ 'zipWith' generalises 'zip' by zipping with the function
1592d1590
< -- given as the first argument, instead of a tupling function.
1593d1590
< -- Performs replacement on invalid scalar values.
1594c1591
< zipWith :: (Char -> Char -> Char) -> Text -> Text -> Text
---
> {-# RULES-- | /O(n)/ 'zipWith' generalises 'zip' by zipping with the function
1594a1592
> "LAZY TEXT count/singleton -> countChar"-- given as the first argument, instead of a tupling function.[~1] forall c t.
1594a1593
> -- Performs replacement on invalid scalar values. (singleton c) t = countChar c t
1594a1594
> zipWith#-}   :: (Char -> Char -> Char) -> Text -> Text -> Text
1597d1596
< {-# INLINE [0] zipWith #-}
1598d1596
< 
1599d1596
< revChunks :: [T.Text] -> Text
1600c1597
< revChunks = L.foldl' (flip chunk) Empty
---
> {-# INLINE-- | /O(n)/ The 'countChar' function returns the number of times the[0] zipWith #-}
1600a1598
> -- query element appears in the given 'Text'.  Subject to fusion.
1600a1599
> countChar :: Char[T.Text->]Text-> Text-> Int64
1600a1600
> countChar c tL.foldl'= S.countChar(flip chunk (stream) Empty)
1602d1601
< emptyError :: String -> a
1603c1602
< emptyError fun = P.error ("Data.Text.Lazy." ++ fun ++ ": empty input")
---
> emptyError-- | /O(n)/ 'zip' takes two 'Text's and returns a list of:: String -> a
1603a1603
> emptyError-- corresponding pairs of bytes. If one input 'Text' is short,fun = P.error ("Data.Text.Lazy." ++ fun ++ ": empty input")
1603a1604
> -- excess elements of the longer 'Text' are discarded. This is
1603a1605
> impossibleError-- equivalent to a pair of 'unpack' operations.:: String -> a
1603a1606
> zipimpossibleError:: Text -> Textfun ->= P.error(Char,Char("Data.Text.Lazy.")]             ++ fun ++ ": impossible case")
1605d1607
< impossibleError :: String -> a
1606d1607
< impossibleError fun = P.error ("Data.Text.Lazy." ++ fun ++ ": impossible case")
</pre></br><h2>original</h2></br><pre>{-# OPTIONS_GHC -fno-warn-orphans #-}
{-# LANGUAGE BangPatterns, MagicHash, CPP #-}
#if __GLASGOW_HASKELL__ >= 702
{-# LANGUAGE Trustworthy #-}
#endif
#if __GLASGOW_HASKELL__ >= 708
{-# LANGUAGE TypeFamilies #-}
#endif

-- |
-- Module      : Data.Text.Lazy
-- Copyright   : (c) 2009, 2010, 2012 Bryan O'Sullivan
--
-- License     : BSD-style
-- Maintainer  : bos@serpentine.com
-- Stability   : experimental
-- Portability : GHC
--
-- A time and space-efficient implementation of Unicode text using
-- lists of packed arrays.
--
-- /Note/: Read below the synopsis for important notes on the use of
-- this module.
--
-- The representation used by this module is suitable for high
-- performance use and for streaming large quantities of data.  It
-- provides a means to manipulate a large body of text without
-- requiring that the entire content be resident in memory.
--
-- Some operations, such as 'concat', 'append', 'reverse' and 'cons',
-- have better time complexity than their "Data.Text" equivalents, due
-- to the underlying representation being a list of chunks. For other
-- operations, lazy 'Text's are usually within a few percent of strict
-- ones, but often with better heap usage if used in a streaming
-- fashion. For data larger than available memory, or if you have
-- tight memory constraints, this module will be the only option.
--
-- This module is intended to be imported @qualified@, to avoid name
-- clashes with "Prelude" functions.  eg.
--
-- > import qualified Data.Text.Lazy as L

module Data.Text.Lazy
    (
    -- * Fusion
    -- $fusion

    -- * Acceptable data
    -- $replacement

    -- * Types
      Text

    -- * Creation and elimination
    , pack
    , unpack
    , singleton
    , empty
    , fromChunks
    , toChunks
    , toStrict
    , fromStrict
    , foldrChunks
    , foldlChunks

    -- * Basic interface
    , cons
    , snoc
    , append
    , uncons
    , head
    , last
    , tail
    , init
    , null
    , length
    , compareLength

    -- * Transformations
    , map
    , intercalate
    , intersperse
    , transpose
    , reverse
    , replace

    -- ** Case conversion
    -- $case
    , toCaseFold
    , toLower
    , toUpper
    , toTitle

    -- ** Justification
    , justifyLeft
    , justifyRight
    , center

    -- * Folds
    , foldl
    , foldl'
    , foldl1
    , foldl1'
    , foldr
    , foldr1

    -- ** Special folds
    , concat
    , concatMap
    , any
    , all
    , maximum
    , minimum

    -- * Construction

    -- ** Scans
    , scanl
    , scanl1
    , scanr
    , scanr1

    -- ** Accumulating maps
    , mapAccumL
    , mapAccumR

    -- ** Generation and unfolding
    , replicate
    , unfoldr
    , unfoldrN

    -- * Substrings

    -- ** Breaking strings
    , take
    , takeEnd
    , drop
    , dropEnd
    , takeWhile
    , dropWhile
    , dropWhileEnd
    , dropAround
    , strip
    , stripStart
    , stripEnd
    , splitAt
    , span
    , breakOn
    , breakOnEnd
    , break
    , group
    , groupBy
    , inits
    , tails

    -- ** Breaking into many substrings
    -- $split
    , splitOn
    , split
    , chunksOf
    -- , breakSubstring

    -- ** Breaking into lines and words
    , lines
    , words
    , unlines
    , unwords

    -- * Predicates
    , isPrefixOf
    , isSuffixOf
    , isInfixOf

    -- ** View patterns
    , stripPrefix
    , stripSuffix
    , commonPrefixes

    -- * Searching
    , filter
    , find
    , breakOnAll
    , partition

    -- , findSubstring

    -- * Indexing
    , index
    , count

    -- * Zipping and unzipping
    , zip
    , zipWith

    -- -* Ordered text
    -- , sort
    ) where

import Prelude (Char, Bool(..), Maybe(..), String,
                Eq(..), Ord(..), Ordering(..), Read(..), Show(..),
                (&&), (||), (+), (-), (.), ($), (++),
                error, flip, fmap, fromIntegral, not, otherwise, quot)
import qualified Prelude as P
#if defined(HAVE_DEEPSEQ)
import Control.DeepSeq (NFData(..))
#endif
import Data.Int (Int64)
import qualified Data.List as L
import Data.Char (isSpace)
import Data.Data (Data(gfoldl, toConstr, gunfold, dataTypeOf))
import Data.Data (mkNoRepType)
import Data.Monoid (Monoid(..))
import Data.String (IsString(..))
import qualified Data.Text as T
import qualified Data.Text.Internal as T
import qualified Data.Text.Internal.Fusion.Common as S
import qualified Data.Text.Unsafe as T
import qualified Data.Text.Internal.Lazy.Fusion as S
import Data.Text.Internal.Fusion.Types (PairS(..))
import Data.Text.Internal.Lazy.Fusion (stream, unstream)
import Data.Text.Internal.Lazy (Text(..), chunk, empty, foldlChunks, foldrChunks)
import Data.Text.Internal (firstf, safe, text)
import qualified Data.Text.Internal.Functions as F
import Data.Text.Internal.Lazy.Search (indices)
#if __GLASGOW_HASKELL__ >= 702
import qualified GHC.CString as GHC
#else
import qualified GHC.Base as GHC
#endif
#if __GLASGOW_HASKELL__ >= 708
import qualified GHC.Exts as Exts
#endif
import GHC.Prim (Addr#)

-- $fusion
--
-- Most of the functions in this module are subject to /fusion/,
-- meaning that a pipeline of such functions will usually allocate at
-- most one 'Text' value.
--
-- As an example, consider the following pipeline:
--
-- > import Data.Text.Lazy as T
-- > import Data.Text.Lazy.Encoding as E
-- > import Data.ByteString.Lazy (ByteString)
-- >
-- > countChars :: ByteString -> Int
-- > countChars = T.length . T.toUpper . E.decodeUtf8
--
-- From the type signatures involved, this looks like it should
-- allocate one 'ByteString' value, and two 'Text' values. However,
-- when a module is compiled with optimisation enabled under GHC, the
-- two intermediate 'Text' values will be optimised away, and the
-- function will be compiled down to a single loop over the source
-- 'ByteString'.
--
-- Functions that can be fused by the compiler are documented with the
-- phrase \"Subject to fusion\".

-- $replacement
--
-- A 'Text' value is a sequence of Unicode scalar values, as defined
-- in &#xa7;3.9, definition D76 of the Unicode 5.2 standard:
-- <http://www.unicode.org/versions/Unicode5.2.0/ch03.pdf#page=35>. As
-- such, a 'Text' cannot contain values in the range U+D800 to U+DFFF
-- inclusive. Haskell implementations admit all Unicode code points
-- (&#xa7;3.4, definition D10) as 'Char' values, including code points
-- from this invalid range.  This means that there are some 'Char'
-- values that are not valid Unicode scalar values, and the functions
-- in this module must handle those cases.
--
-- Within this module, many functions construct a 'Text' from one or
-- more 'Char' values. Those functions will substitute 'Char' values
-- that are not valid Unicode scalar values with the replacement
-- character \"&#xfffd;\" (U+FFFD).  Functions that perform this
-- inspection and replacement are documented with the phrase
-- \"Performs replacement on invalid scalar values\".
--
-- (One reason for this policy of replacement is that internally, a
-- 'Text' value is represented as packed UTF-16 data. Values in the
-- range U+D800 through U+DFFF are used by UTF-16 to denote surrogate
-- code points, and so cannot be represented. The functions replace
-- invalid scalar values, instead of dropping them, as a security
-- measure. For details, see Unicode Technical Report 36, &#xa7;3.5:
-- <http://unicode.org/reports/tr36#Deletion_of_Noncharacters>)

equal :: Text -> Text -> Bool
equal Empty Empty = True
equal Empty _     = False
equal _ Empty     = False
equal (Chunk a as) (Chunk b bs) =
    case compare lenA lenB of
      LT -> a == (T.takeWord16 lenA b) &&
            as `equal` Chunk (T.dropWord16 lenA b) bs
      EQ -> a == b && as `equal` bs
      GT -> T.takeWord16 lenB a == b &&
            Chunk (T.dropWord16 lenB a) as `equal` bs
  where lenA = T.lengthWord16 a
        lenB = T.lengthWord16 b

instance Eq Text where
    (==) = equal
    {-# INLINE (==) #-}

instance Ord Text where
    compare = compareText

compareText :: Text -> Text -> Ordering
compareText Empty Empty = EQ
compareText Empty _     = LT
compareText _     Empty = GT
compareText (Chunk a0 as) (Chunk b0 bs) = outer a0 b0
 where
  outer ta@(T.Text arrA offA lenA) tb@(T.Text arrB offB lenB) = go 0 0
   where
    go !i !j
      | i >= lenA = compareText as (chunk (T.Text arrB (offB+j) (lenB-j)) bs)
      | j >= lenB = compareText (chunk (T.Text arrA (offA+i) (lenA-i)) as) bs
      | a < b     = LT
      | a > b     = GT
      | otherwise = go (i+di) (j+dj)
      where T.Iter a di = T.iter ta i
            T.Iter b dj = T.iter tb j

instance Show Text where
    showsPrec p ps r = showsPrec p (unpack ps) r

instance Read Text where
    readsPrec p str = [(pack x,y) | (x,y) <- readsPrec p str]

instance Monoid Text where
    mempty  = empty
    mappend = append
    mconcat = concat

instance IsString Text where
    fromString = pack

#if __GLASGOW_HASKELL__ >= 708
instance Exts.IsList Text where
    type Item Text = Char
    fromList       = pack
    toList         = unpack
#endif

#if defined(HAVE_DEEPSEQ)
instance NFData Text where
    rnf Empty        = ()
    rnf (Chunk _ ts) = rnf ts
#endif

instance Data Text where
  gfoldl f z txt = z pack `f` (unpack txt)
  toConstr _     = error "Data.Text.Lazy.Text.toConstr"
  gunfold _ _    = error "Data.Text.Lazy.Text.gunfold"
  dataTypeOf _   = mkNoRepType "Data.Text.Lazy.Text"

-- | /O(n)/ Convert a 'String' into a 'Text'.
--
-- Subject to fusion.  Performs replacement on invalid scalar values.
pack :: String -> Text
pack = unstream . S.streamList . L.map safe
{-# INLINE [1] pack #-}

-- | /O(n)/ Convert a 'Text' into a 'String'.
-- Subject to fusion.
unpack :: Text -> String
unpack t = S.unstreamList (stream t)
{-# INLINE [1] unpack #-}

-- | /O(n)/ Convert a literal string into a Text.
unpackCString# :: Addr# -> Text
unpackCString# addr# = unstream (S.streamCString# addr#)
{-# NOINLINE unpackCString# #-}

{-# RULES "TEXT literal" forall a.
    unstream (S.streamList (L.map safe (GHC.unpackCString# a)))
      = unpackCString# a #-}

{-# RULES "TEXT literal UTF8" forall a.
    unstream (S.streamList (L.map safe (GHC.unpackCStringUtf8# a)))
      = unpackCString# a #-}

{-# RULES "LAZY TEXT empty literal"
    unstream (S.streamList (L.map safe []))
      = Empty #-}

{-# RULES "LAZY TEXT empty literal" forall a.
    unstream (S.streamList (L.map safe [a]))
      = Chunk (T.singleton a) Empty #-}

-- | /O(1)/ Convert a character into a Text.  Subject to fusion.
-- Performs replacement on invalid scalar values.
singleton :: Char -> Text
singleton c = Chunk (T.singleton c) Empty
{-# INLINE [1] singleton #-}

{-# RULES
"LAZY TEXT singleton -> fused" [~1] forall c.
    singleton c = unstream (S.singleton c)
"LAZY TEXT singleton -> unfused" [1] forall c.
    unstream (S.singleton c) = singleton c
  #-}

-- | /O(c)/ Convert a list of strict 'T.Text's into a lazy 'Text'.
fromChunks :: [T.Text] -> Text
fromChunks cs = L.foldr chunk Empty cs

-- | /O(n)/ Convert a lazy 'Text' into a list of strict 'T.Text's.
toChunks :: Text -> [T.Text]
toChunks cs = foldrChunks (:) [] cs

-- | /O(n)/ Convert a lazy 'Text' into a strict 'T.Text'.
toStrict :: Text -> T.Text
toStrict t = T.concat (toChunks t)
{-# INLINE [1] toStrict #-}

-- | /O(c)/ Convert a strict 'T.Text' into a lazy 'Text'.
fromStrict :: T.Text -> Text
fromStrict t = chunk t Empty
{-# INLINE [1] fromStrict #-}

-- -----------------------------------------------------------------------------
-- * Basic functions

-- | /O(n)/ Adds a character to the front of a 'Text'.  This function
-- is more costly than its 'List' counterpart because it requires
-- copying a new array.  Subject to fusion.
cons :: Char -> Text -> Text
cons c t = Chunk (T.singleton c) t
{-# INLINE [1] cons #-}

infixr 5 `cons`

{-# RULES
"LAZY TEXT cons -> fused" [~1] forall c t.
    cons c t = unstream (S.cons c (stream t))
"LAZY TEXT cons -> unfused" [1] forall c t.
    unstream (S.cons c (stream t)) = cons c t
 #-}

-- | /O(n)/ Adds a character to the end of a 'Text'.  This copies the
-- entire array in the process, unless fused.  Subject to fusion.
snoc :: Text -> Char -> Text
snoc t c = foldrChunks Chunk (singleton c) t
{-# INLINE [1] snoc #-}

{-# RULES
"LAZY TEXT snoc -> fused" [~1] forall t c.
    snoc t c = unstream (S.snoc (stream t) c)
"LAZY TEXT snoc -> unfused" [1] forall t c.
    unstream (S.snoc (stream t) c) = snoc t c
 #-}

-- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.
append :: Text -> Text -> Text
append xs ys = foldrChunks Chunk ys xs
{-# INLINE [1] append #-}

{-# RULES
"LAZY TEXT append -> fused" [~1] forall t1 t2.
    append t1 t2 = unstream (S.append (stream t1) (stream t2))
"LAZY TEXT append -> unfused" [1] forall t1 t2.
    unstream (S.append (stream t1) (stream t2)) = append t1 t2
 #-}

-- | /O(1)/ Returns the first character and rest of a 'Text', or
-- 'Nothing' if empty. Subject to fusion.
uncons :: Text -> Maybe (Char, Text)
uncons Empty        = Nothing
uncons (Chunk t ts) = Just (T.unsafeHead t, ts')
  where ts' | T.compareLength t 1 == EQ = ts
            | otherwise                 = Chunk (T.unsafeTail t) ts
{-# INLINE uncons #-}

-- | /O(1)/ Returns the first character of a 'Text', which must be
-- non-empty.  Subject to fusion.
head :: Text -> Char
head t = S.head (stream t)
{-# INLINE head #-}

-- | /O(1)/ Returns all characters after the head of a 'Text', which
-- must be non-empty.  Subject to fusion.
tail :: Text -> Text
tail (Chunk t ts) = chunk (T.tail t) ts
tail Empty        = emptyError "tail"
{-# INLINE [1] tail #-}

{-# RULES
"LAZY TEXT tail -> fused" [~1] forall t.
    tail t = unstream (S.tail (stream t))
"LAZY TEXT tail -> unfused" [1] forall t.
    unstream (S.tail (stream t)) = tail t
 #-}

-- | /O(1)/ Returns all but the last character of a 'Text', which must
-- be non-empty.  Subject to fusion.
init :: Text -> Text
init (Chunk t0 ts0) = go t0 ts0
    where go t (Chunk t' ts) = Chunk t (go t' ts)
          go t Empty         = chunk (T.init t) Empty
init Empty = emptyError "init"
{-# INLINE [1] init #-}

{-# RULES
"LAZY TEXT init -> fused" [~1] forall t.
    init t = unstream (S.init (stream t))
"LAZY TEXT init -> unfused" [1] forall t.
    unstream (S.init (stream t)) = init t
 #-}

-- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to
-- fusion.
null :: Text -> Bool
null Empty = True
null _     = False
{-# INLINE [1] null #-}

{-# RULES
"LAZY TEXT null -> fused" [~1] forall t.
    null t = S.null (stream t)
"LAZY TEXT null -> unfused" [1] forall t.
    S.null (stream t) = null t
 #-}

-- | /O(1)/ Tests whether a 'Text' contains exactly one character.
-- Subject to fusion.
isSingleton :: Text -> Bool
isSingleton = S.isSingleton . stream
{-# INLINE isSingleton #-}

-- | /O(1)/ Returns the last character of a 'Text', which must be
-- non-empty.  Subject to fusion.
last :: Text -> Char
last Empty        = emptyError "last"
last (Chunk t ts) = go t ts
    where go _ (Chunk t' ts') = go t' ts'
          go t' Empty         = T.last t'
{-# INLINE [1] last #-}

{-# RULES
"LAZY TEXT last -> fused" [~1] forall t.
    last t = S.last (stream t)
"LAZY TEXT last -> unfused" [1] forall t.
    S.last (stream t) = last t
  #-}

-- | /O(n)/ Returns the number of characters in a 'Text'.
-- Subject to fusion.
length :: Text -> Int64
length = foldlChunks go 0
    where go l t = l + fromIntegral (T.length t)
{-# INLINE [1] length #-}

{-# RULES
"LAZY TEXT length -> fused" [~1] forall t.
    length t = S.length (stream t)
"LAZY TEXT length -> unfused" [1] forall t.
    S.length (stream t) = length t
 #-}

-- | /O(n)/ Compare the count of characters in a 'Text' to a number.
-- Subject to fusion.
--
-- This function gives the same answer as comparing against the result
-- of 'length', but can short circuit if the count of characters is
-- greater than the number, and hence be more efficient.
compareLength :: Text -> Int64 -> Ordering
compareLength t n = S.compareLengthI (stream t) n
{-# INLINE [1] compareLength #-}

-- We don't apply those otherwise appealing length-to-compareLength
-- rewrite rules here, because they can change the strictness
-- properties of code.

-- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
-- each element of @t@.  Subject to fusion.  Performs replacement on
-- invalid scalar values.
map :: (Char -> Char) -> Text -> Text
map f t = unstream (S.map (safe . f) (stream t))
{-# INLINE [1] map #-}

-- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
-- 'Text's and concatenates the list after interspersing the first
-- argument between each element of the list.
intercalate :: Text -> [Text] -> Text
intercalate t = concat . (F.intersperse t)
{-# INLINE intercalate #-}

-- | /O(n)/ The 'intersperse' function takes a character and places it
-- between the characters of a 'Text'.  Subject to fusion.  Performs
-- replacement on invalid scalar values.
intersperse :: Char -> Text -> Text
intersperse c t = unstream (S.intersperse (safe c) (stream t))
{-# INLINE intersperse #-}

-- | /O(n)/ Left-justify a string to the given length, using the
-- specified fill character on the right. Subject to fusion.  Performs
-- replacement on invalid scalar values.
--
-- Examples:
--
-- > justifyLeft 7 'x' "foo"    == "fooxxxx"
-- > justifyLeft 3 'x' "foobar" == "foobar"
justifyLeft :: Int64 -> Char -> Text -> Text
justifyLeft k c t
    | len >= k  = t
    | otherwise = t `append` replicateChar (k-len) c
  where len = length t
{-# INLINE [1] justifyLeft #-}

{-# RULES
"LAZY TEXT justifyLeft -> fused" [~1] forall k c t.
    justifyLeft k c t = unstream (S.justifyLeftI k c (stream t))
"LAZY TEXT justifyLeft -> unfused" [1] forall k c t.
    unstream (S.justifyLeftI k c (stream t)) = justifyLeft k c t
  #-}

-- | /O(n)/ Right-justify a string to the given length, using the
-- specified fill character on the left.  Performs replacement on
-- invalid scalar values.
--
-- Examples:
--
-- > justifyRight 7 'x' "bar"    == "xxxxbar"
-- > justifyRight 3 'x' "foobar" == "foobar"
justifyRight :: Int64 -> Char -> Text -> Text
justifyRight k c t
    | len >= k  = t
    | otherwise = replicateChar (k-len) c `append` t
  where len = length t
{-# INLINE justifyRight #-}

-- | /O(n)/ Center a string to the given length, using the specified
-- fill character on either side.  Performs replacement on invalid
-- scalar values.
--
-- Examples:
--
-- > center 8 'x' "HS" = "xxxHSxxx"
center :: Int64 -> Char -> Text -> Text
center k c t
    | len >= k  = t
    | otherwise = replicateChar l c `append` t `append` replicateChar r c
  where len = length t
        d   = k - len
        r   = d `quot` 2
        l   = d - r
{-# INLINE center #-}

-- | /O(n)/ The 'transpose' function transposes the rows and columns
-- of its 'Text' argument.  Note that this function uses 'pack',
-- 'unpack', and the list version of transpose, and is thus not very
-- efficient.
transpose :: [Text] -> [Text]
transpose ts = L.map (\ss -> Chunk (T.pack ss) Empty)
                     (L.transpose (L.map unpack ts))
-- TODO: make this fast

-- | /O(n)/ 'reverse' @t@ returns the elements of @t@ in reverse order.
reverse :: Text -> Text
reverse = rev Empty
  where rev a Empty        = a
        rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts

-- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in
-- @haystack@ with @replacement@.
--
-- This function behaves as though it was defined as follows:
--
-- @
-- replace needle replacement haystack =
--   'intercalate' replacement ('splitOn' needle haystack)
-- @
--
-- As this suggests, each occurrence is replaced exactly once.  So if
-- @needle@ occurs in @replacement@, that occurrence will /not/ itself
-- be replaced recursively:
--
-- > replace "oo" "foo" "oo" == "foo"
--
-- In cases where several instances of @needle@ overlap, only the
-- first one will be replaced:
--
-- > replace "ofo" "bar" "ofofo" == "barfo"
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
replace :: Text
        -- ^ @needle@ to search for.  If this string is empty, an
        -- error will occur.
        -> Text
        -- ^ @replacement@ to replace @needle@ with.
        -> Text
        -- ^ @haystack@ in which to search.
        -> Text
replace s d = intercalate d . splitOn s
{-# INLINE replace #-}

-- ----------------------------------------------------------------------------
-- ** Case conversions (folds)

-- $case
--
-- With Unicode text, it is incorrect to use combinators like @map
-- toUpper@ to case convert each character of a string individually.
-- Instead, use the whole-string case conversion functions from this
-- module.  For correctness in different writing systems, these
-- functions may map one input character to two or three output
-- characters.

-- | /O(n)/ Convert a string to folded case.  Subject to fusion.
--
-- This function is mainly useful for performing caseless (or case
-- insensitive) string comparisons.
--
-- A string @x@ is a caseless match for a string @y@ if and only if:
--
-- @toCaseFold x == toCaseFold y@
--
-- The result string may be longer than the input string, and may
-- differ from applying 'toLower' to the input string.  For instance,
-- the Armenian small ligature men now (U+FB13) is case folded to the
-- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
-- case folded to the Greek small letter letter mu (U+03BC) instead of
-- itself.
toCaseFold :: Text -> Text
toCaseFold t = unstream (S.toCaseFold (stream t))
{-# INLINE [0] toCaseFold #-}

-- | /O(n)/ Convert a string to lower case, using simple case
-- conversion.  Subject to fusion.
--
-- The result string may be longer than the input string.  For
-- instance, the Latin capital letter I with dot above (U+0130) maps
-- to the sequence Latin small letter i (U+0069) followed by combining
-- dot above (U+0307).
toLower :: Text -> Text
toLower t = unstream (S.toLower (stream t))
{-# INLINE toLower #-}

-- | /O(n)/ Convert a string to upper case, using simple case
-- conversion.  Subject to fusion.
--
-- The result string may be longer than the input string.  For
-- instance, the German eszett (U+00DF) maps to the two-letter
-- sequence SS.
toUpper :: Text -> Text
toUpper t = unstream (S.toUpper (stream t))
{-# INLINE toUpper #-}


-- | /O(n)/ Convert a string to title case, using simple case
-- conversion.  Subject to fusion.
--
-- The first letter of the input is converted to title case, as is
-- every subsequent letter that immediately follows a non-letter.
-- Every letter that immediately follows another letter is converted
-- to lower case.
--
-- The result string may be longer than the input string. For example,
-- the Latin small ligature &#xfb02; (U+FB02) is converted to the
-- sequence Latin capital letter F (U+0046) followed by Latin small
-- letter l (U+006C).
--
-- /Note/: this function does not take language or culture specific
-- rules into account. For instance, in English, different style
-- guides disagree on whether the book name \"The Hill of the Red
-- Fox\" is correctly title cased&#x2014;but this function will
-- capitalize /every/ word.
toTitle :: Text -> Text
toTitle t = unstream (S.toTitle (stream t))
{-# INLINE toTitle #-}

-- | /O(n)/ 'foldl', applied to a binary operator, a starting value
-- (typically the left-identity of the operator), and a 'Text',
-- reduces the 'Text' using the binary operator, from left to right.
-- Subject to fusion.
foldl :: (a -> Char -> a) -> a -> Text -> a
foldl f z t = S.foldl f z (stream t)
{-# INLINE foldl #-}

-- | /O(n)/ A strict version of 'foldl'.
-- Subject to fusion.
foldl' :: (a -> Char -> a) -> a -> Text -> a
foldl' f z t = S.foldl' f z (stream t)
{-# INLINE foldl' #-}

-- | /O(n)/ A variant of 'foldl' that has no starting value argument,
-- and thus must be applied to a non-empty 'Text'.  Subject to fusion.
foldl1 :: (Char -> Char -> Char) -> Text -> Char
foldl1 f t = S.foldl1 f (stream t)
{-# INLINE foldl1 #-}

-- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.
foldl1' :: (Char -> Char -> Char) -> Text -> Char
foldl1' f t = S.foldl1' f (stream t)
{-# INLINE foldl1' #-}

-- | /O(n)/ 'foldr', applied to a binary operator, a starting value
-- (typically the right-identity of the operator), and a 'Text',
-- reduces the 'Text' using the binary operator, from right to left.
-- Subject to fusion.
foldr :: (Char -> a -> a) -> a -> Text -> a
foldr f z t = S.foldr f z (stream t)
{-# INLINE foldr #-}

-- | /O(n)/ A variant of 'foldr' that has no starting value argument,
-- and thus must be applied to a non-empty 'Text'.  Subject to
-- fusion.
foldr1 :: (Char -> Char -> Char) -> Text -> Char
foldr1 f t = S.foldr1 f (stream t)
{-# INLINE foldr1 #-}

-- | /O(n)/ Concatenate a list of 'Text's.
concat :: [Text] -> Text
concat = to
  where
    go Empty        css = to css
    go (Chunk c cs) css = Chunk c (go cs css)
    to []               = Empty
    to (cs:css)         = go cs css
{-# INLINE concat #-}

-- | /O(n)/ Map a function over a 'Text' that results in a 'Text', and
-- concatenate the results.
concatMap :: (Char -> Text) -> Text -> Text
concatMap f = concat . foldr ((:) . f) []
{-# INLINE concatMap #-}

-- | /O(n)/ 'any' @p@ @t@ determines whether any character in the
-- 'Text' @t@ satisifes the predicate @p@. Subject to fusion.
any :: (Char -> Bool) -> Text -> Bool
any p t = S.any p (stream t)
{-# INLINE any #-}

-- | /O(n)/ 'all' @p@ @t@ determines whether all characters in the
-- 'Text' @t@ satisify the predicate @p@. Subject to fusion.
all :: (Char -> Bool) -> Text -> Bool
all p t = S.all p (stream t)
{-# INLINE all #-}

-- | /O(n)/ 'maximum' returns the maximum value from a 'Text', which
-- must be non-empty. Subject to fusion.
maximum :: Text -> Char
maximum t = S.maximum (stream t)
{-# INLINE maximum #-}

-- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which
-- must be non-empty. Subject to fusion.
minimum :: Text -> Char
minimum t = S.minimum (stream t)
{-# INLINE minimum #-}

-- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list of
-- successive reduced values from the left. Subject to fusion.
-- Performs replacement on invalid scalar values.
--
-- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
--
-- Note that
--
-- > last (scanl f z xs) == foldl f z xs.
scanl :: (Char -> Char -> Char) -> Char -> Text -> Text
scanl f z t = unstream (S.scanl g z (stream t))
    where g a b = safe (f a b)
{-# INLINE scanl #-}

-- | /O(n)/ 'scanl1' is a variant of 'scanl' that has no starting
-- value argument.  Subject to fusion.  Performs replacement on
-- invalid scalar values.
--
-- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]
scanl1 :: (Char -> Char -> Char) -> Text -> Text
scanl1 f t0 = case uncons t0 of
                Nothing -> empty
                Just (t,ts) -> scanl f t ts
{-# INLINE scanl1 #-}

-- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs
-- replacement on invalid scalar values.
--
-- > scanr f v == reverse . scanl (flip f) v . reverse
scanr :: (Char -> Char -> Char) -> Char -> Text -> Text
scanr f v = reverse . scanl g v . reverse
    where g a b = safe (f b a)

-- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting
-- value argument.  Performs replacement on invalid scalar values.
scanr1 :: (Char -> Char -> Char) -> Text -> Text
scanr1 f t | null t    = empty
           | otherwise = scanr f (last t) (init t)

-- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies a
-- function to each element of a 'Text', passing an accumulating
-- parameter from left to right, and returns a final 'Text'.  Performs
-- replacement on invalid scalar values.
mapAccumL :: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
mapAccumL f = go
  where
    go z (Chunk c cs)    = (z'', Chunk c' cs')
        where (z',  c')  = T.mapAccumL f z c
              (z'', cs') = go z' cs
    go z Empty           = (z, Empty)
{-# INLINE mapAccumL #-}

-- | The 'mapAccumR' function behaves like a combination of 'map' and
-- a strict 'foldr'; it applies a function to each element of a
-- 'Text', passing an accumulating parameter from right to left, and
-- returning a final value of this accumulator together with the new
-- 'Text'.  Performs replacement on invalid scalar values.
mapAccumR :: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
mapAccumR f = go
  where
    go z (Chunk c cs)   = (z'', Chunk c' cs')
        where (z'', c') = T.mapAccumR f z' c
              (z', cs') = go z cs
    go z Empty          = (z, Empty)
{-# INLINE mapAccumR #-}

-- | /O(n*m)/ 'replicate' @n@ @t@ is a 'Text' consisting of the input
-- @t@ repeated @n@ times.
replicate :: Int64 -> Text -> Text
replicate n t
    | null t || n <= 0 = empty
    | isSingleton t    = replicateChar n (head t)
    | otherwise        = concat (rep 0)
    where rep !i | i >= n    = []
                 | otherwise = t : rep (i+1)
{-# INLINE [1] replicate #-}

-- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
-- value of every element. Subject to fusion.
replicateChar :: Int64 -> Char -> Text
replicateChar n c = unstream (S.replicateCharI n (safe c))
{-# INLINE replicateChar #-}

{-# RULES
"LAZY TEXT replicate/singleton -> replicateChar" [~1] forall n c.
    replicate n (singleton c) = replicateChar n c
  #-}

-- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'
-- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a
-- 'Text' from a seed value. The function takes the element and
-- returns 'Nothing' if it is done producing the 'Text', otherwise
-- 'Just' @(a,b)@.  In this case, @a@ is the next 'Char' in the
-- string, and @b@ is the seed value for further production.  Performs
-- replacement on invalid scalar values.
unfoldr :: (a -> Maybe (Char,a)) -> a -> Text
unfoldr f s = unstream (S.unfoldr (firstf safe . f) s)
{-# INLINE unfoldr #-}

-- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed
-- value. However, the length of the result should be limited by the
-- first argument to 'unfoldrN'. This function is more efficient than
-- 'unfoldr' when the maximum length of the result is known and
-- correct, otherwise its performance is similar to 'unfoldr'.
-- Performs replacement on invalid scalar values.
unfoldrN :: Int64 -> (a -> Maybe (Char,a)) -> a -> Text
unfoldrN n f s = unstream (S.unfoldrN n (firstf safe . f) s)
{-# INLINE unfoldrN #-}

-- | /O(n)/ 'take' @n@, applied to a 'Text', returns the prefix of the
-- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than
-- the length of the Text. Subject to fusion.
take :: Int64 -> Text -> Text
take i _ | i <= 0 = Empty
take i t0         = take' i t0
  where take' 0 _            = Empty
        take' _ Empty        = Empty
        take' n (Chunk t ts)
            | n < len   = Chunk (T.take (fromIntegral n) t) Empty
            | otherwise = Chunk t (take' (n - len) ts)
            where len = fromIntegral (T.length t)
{-# INLINE [1] take #-}

{-# RULES
"LAZY TEXT take -> fused" [~1] forall n t.
    take n t = unstream (S.take n (stream t))
"LAZY TEXT take -> unfused" [1] forall n t.
    unstream (S.take n (stream t)) = take n t
  #-}

-- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after
-- taking @n@ characters from the end of @t@.
--
-- Examples:
--
-- > takeEnd 3 "foobar" == "bar"
takeEnd :: Int64 -> Text -> Text
takeEnd n t0
    | n <= 0    = empty
    | otherwise = takeChunk n empty . L.reverse . toChunks $ t0
  where takeChunk _ acc [] = acc
        takeChunk i acc (t:ts)
          | i <= l    = chunk (T.takeEnd (fromIntegral i) t) acc
          | otherwise = takeChunk (i-l) (Chunk t acc) ts
          where l = fromIntegral (T.length t)

-- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of the
-- 'Text' after the first @n@ characters, or the empty 'Text' if @n@
-- is greater than the length of the 'Text'. Subject to fusion.
drop :: Int64 -> Text -> Text
drop i t0
    | i <= 0    = t0
    | otherwise = drop' i t0
  where drop' 0 ts           = ts
        drop' _ Empty        = Empty
        drop' n (Chunk t ts)
            | n < len   = Chunk (T.drop (fromIntegral n) t) ts
            | otherwise = drop' (n - len) ts
            where len   = fromIntegral (T.length t)
{-# INLINE [1] drop #-}

{-# RULES
"LAZY TEXT drop -> fused" [~1] forall n t.
    drop n t = unstream (S.drop n (stream t))
"LAZY TEXT drop -> unfused" [1] forall n t.
    unstream (S.drop n (stream t)) = drop n t
  #-}

-- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after
-- dropping @n@ characters from the end of @t@.
--
-- Examples:
--
-- > dropEnd 3 "foobar" == "foo"
dropEnd :: Int64 -> Text -> Text
dropEnd n t0
    | n <= 0    = t0
    | otherwise = dropChunk n . L.reverse . toChunks $ t0
  where dropChunk _ [] = empty
        dropChunk m (t:ts)
          | m >= l    = dropChunk (m-l) ts
          | otherwise = fromChunks . L.reverse $
                        T.dropEnd (fromIntegral m) t : ts
          where l = fromIntegral (T.length t)

-- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'
-- values dropped, or the empty 'Text' if @n@ is greater than the
-- number of 'Word16' values present.
dropWords :: Int64 -> Text -> Text
dropWords i t0
    | i <= 0    = t0
    | otherwise = drop' i t0
  where drop' 0 ts           = ts
        drop' _ Empty        = Empty
        drop' n (Chunk (T.Text arr off len) ts)
            | n < len'  = chunk (text arr (off+n') (len-n')) ts
            | otherwise = drop' (n - len') ts
            where len'  = fromIntegral len
                  n'    = fromIntegral n

-- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
-- returns the longest prefix (possibly empty) of elements that
-- satisfy @p@.  Subject to fusion.
takeWhile :: (Char -> Bool) -> Text -> Text
takeWhile p t0 = takeWhile' t0
  where takeWhile' Empty        = Empty
        takeWhile' (Chunk t ts) =
          case T.findIndex (not . p) t of
            Just n | n > 0     -> Chunk (T.take n t) Empty
                   | otherwise -> Empty
            Nothing            -> Chunk t (takeWhile' ts)
{-# INLINE [1] takeWhile #-}

{-# RULES
"LAZY TEXT takeWhile -> fused" [~1] forall p t.
    takeWhile p t = unstream (S.takeWhile p (stream t))
"LAZY TEXT takeWhile -> unfused" [1] forall p t.
    unstream (S.takeWhile p (stream t)) = takeWhile p t
  #-}

-- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after
-- 'takeWhile' @p@ @t@.  Subject to fusion.
dropWhile :: (Char -> Bool) -> Text -> Text
dropWhile p t0 = dropWhile' t0
  where dropWhile' Empty        = Empty
        dropWhile' (Chunk t ts) =
          case T.findIndex (not . p) t of
            Just n  -> Chunk (T.drop n t) ts
            Nothing -> dropWhile' ts
{-# INLINE [1] dropWhile #-}

{-# RULES
"LAZY TEXT dropWhile -> fused" [~1] forall p t.
    dropWhile p t = unstream (S.dropWhile p (stream t))
"LAZY TEXT dropWhile -> unfused" [1] forall p t.
    unstream (S.dropWhile p (stream t)) = dropWhile p t
  #-}
-- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining after
-- dropping characters that fail the predicate @p@ from the end of
-- @t@.
-- Examples:
--
-- > dropWhileEnd (=='.') "foo..." == "foo"
dropWhileEnd :: (Char -> Bool) -> Text -> Text
dropWhileEnd p = go
  where go Empty = Empty
        go (Chunk t Empty) = if T.null t'
                             then Empty
                             else Chunk t' Empty
            where t' = T.dropWhileEnd p t
        go (Chunk t ts) = case go ts of
                            Empty -> go (Chunk t Empty)
                            ts' -> Chunk t ts'
{-# INLINE dropWhileEnd #-}

-- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
-- dropping characters that fail the predicate @p@ from both the
-- beginning and end of @t@.  Subject to fusion.
dropAround :: (Char -> Bool) -> Text -> Text
dropAround p = dropWhile p . dropWhileEnd p
{-# INLINE [1] dropAround #-}

-- | /O(n)/ Remove leading white space from a string.  Equivalent to:
--
-- > dropWhile isSpace
stripStart :: Text -> Text
stripStart = dropWhile isSpace
{-# INLINE [1] stripStart #-}

-- | /O(n)/ Remove trailing white space from a string.  Equivalent to:
--
-- > dropWhileEnd isSpace
stripEnd :: Text -> Text
stripEnd = dropWhileEnd isSpace
{-# INLINE [1] stripEnd #-}

-- | /O(n)/ Remove leading and trailing white space from a string.
-- Equivalent to:
--
-- > dropAround isSpace
strip :: Text -> Text
strip = dropAround isSpace
{-# INLINE [1] strip #-}

-- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a
-- prefix of @t@ of length @n@, and whose second is the remainder of
-- the string. It is equivalent to @('take' n t, 'drop' n t)@.
splitAt :: Int64 -> Text -> (Text, Text)
splitAt = loop
  where loop _ Empty      = (empty, empty)
        loop n t | n <= 0 = (empty, t)
        loop n (Chunk t ts)
             | n < len   = let (t',t'') = T.splitAt (fromIntegral n) t
                           in (Chunk t' Empty, Chunk t'' ts)
             | otherwise = let (ts',ts'') = loop (n - len) ts
                           in (Chunk t ts', ts'')
             where len = fromIntegral (T.length t)

-- | /O(n)/ 'splitAtWord' @n t@ returns a strict pair whose first
-- element is a prefix of @t@ whose chunks contain @n@ 'Word16'
-- values, and whose second is the remainder of the string.
splitAtWord :: Int64 -> Text -> PairS Text Text
splitAtWord _ Empty = empty :*: empty
splitAtWord x (Chunk c@(T.Text arr off len) cs)
    | y >= len  = let h :*: t = splitAtWord (x-fromIntegral len) cs
                  in  Chunk c h :*: t
    | otherwise = chunk (text arr off y) empty :*:
                  chunk (text arr (off+y) (len-y)) cs
    where y = fromIntegral x

-- | /O(n+m)/ Find the first instance of @needle@ (which must be
-- non-'null') in @haystack@.  The first element of the returned tuple
-- is the prefix of @haystack@ before @needle@ is matched.  The second
-- is the remainder of @haystack@, starting with the match.
--
-- Examples:
--
-- > breakOn "::" "a::b::c" ==> ("a", "::b::c")
-- > breakOn "/" "foobar"   ==> ("foobar", "")
--
-- Laws:
--
-- > append prefix match == haystack
-- >   where (prefix, match) = breakOn needle haystack
--
-- If you need to break a string by a substring repeatedly (e.g. you
-- want to break on every instance of a substring), use 'breakOnAll'
-- instead, as it has lower startup overhead.
--
-- This function is strict in its first argument, and lazy in its
-- second.
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
breakOn :: Text -> Text -> (Text, Text)
breakOn pat src
    | null pat  = emptyError "breakOn"
    | otherwise = case indices pat src of
                    []    -> (src, empty)
                    (x:_) -> let h :*: t = splitAtWord x src
                             in  (h, t)

-- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
--
-- The first element of the returned tuple is the prefix of @haystack@
-- up to and including the last match of @needle@.  The second is the
-- remainder of @haystack@, following the match.
--
-- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
breakOnEnd :: Text -> Text -> (Text, Text)
breakOnEnd pat src = let (a,b) = breakOn (reverse pat) (reverse src)
                   in  (reverse b, reverse a)
{-# INLINE breakOnEnd #-}

-- | /O(n+m)/ Find all non-overlapping instances of @needle@ in
-- @haystack@.  Each element of the returned list consists of a pair:
--
-- * The entire string prior to the /k/th match (i.e. the prefix)
--
-- * The /k/th match, followed by the remainder of the string
--
-- Examples:
--
-- > breakOnAll "::" ""
-- > ==> []
-- > breakOnAll "/" "a/b/c/"
-- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]
--
-- This function is strict in its first argument, and lazy in its
-- second.
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
--
-- The @needle@ parameter may not be empty.
breakOnAll :: Text              -- ^ @needle@ to search for
           -> Text              -- ^ @haystack@ in which to search
           -> [(Text, Text)]
breakOnAll pat src
    | null pat  = emptyError "breakOnAll"
    | otherwise = go 0 empty src (indices pat src)
  where
    go !n p s (x:xs) = let h :*: t = splitAtWord (x-n) s
                           h'      = append p h
                       in (h',t) : go x h' t xs
    go _  _ _ _      = []

-- | /O(n)/ 'break' is like 'span', but the prefix returned is over
-- elements that fail the predicate @p@.
break :: (Char -> Bool) -> Text -> (Text, Text)
break p t0 = break' t0
  where break' Empty          = (empty, empty)
        break' c@(Chunk t ts) =
          case T.findIndex p t of
            Nothing      -> let (ts', ts'') = break' ts
                            in (Chunk t ts', ts'')
            Just n | n == 0    -> (Empty, c)
                   | otherwise -> let (a,b) = T.splitAt n t
                                  in (Chunk a Empty, Chunk b ts)

-- | /O(n)/ 'span', applied to a predicate @p@ and text @t@, returns
-- a pair whose first element is the longest prefix (possibly empty)
-- of @t@ of elements that satisfy @p@, and whose second is the
-- remainder of the list.
span :: (Char -> Bool) -> Text -> (Text, Text)
span p = break (not . p)
{-# INLINE span #-}

-- | The 'group' function takes a 'Text' and returns a list of 'Text's
-- such that the concatenation of the result is equal to the argument.
-- Moreover, each sublist in the result contains only equal elements.
-- For example,
--
-- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]
--
-- It is a special case of 'groupBy', which allows the programmer to
-- supply their own equality test.
group :: Text -> [Text]
group =  groupBy (==)
{-# INLINE group #-}

-- | The 'groupBy' function is the non-overloaded version of 'group'.
groupBy :: (Char -> Char -> Bool) -> Text -> [Text]
groupBy _  Empty        = []
groupBy eq (Chunk t ts) = cons x ys : groupBy eq zs
                          where (ys,zs) = span (eq x) xs
                                x  = T.unsafeHead t
                                xs = chunk (T.unsafeTail t) ts

-- | /O(n)/ Return all initial segments of the given 'Text',
-- shortest first.
inits :: Text -> [Text]
inits = (Empty :) . inits'
  where inits' Empty        = []
        inits' (Chunk t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
                           ++ L.map (Chunk t) (inits' ts)

-- | /O(n)/ Return all final segments of the given 'Text', longest
-- first.
tails :: Text -> [Text]
tails Empty         = Empty : []
tails ts@(Chunk t ts')
  | T.length t == 1 = ts : tails ts'
  | otherwise       = ts : tails (Chunk (T.unsafeTail t) ts')

-- $split
--
-- Splitting functions in this library do not perform character-wise
-- copies to create substrings; they just construct new 'Text's that
-- are slices of the original.

-- | /O(m+n)/ Break a 'Text' into pieces separated by the first 'Text'
-- argument (which cannot be an empty string), consuming the
-- delimiter. An empty delimiter is invalid, and will cause an error
-- to be raised.
--
-- Examples:
--
-- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"]
-- > splitOn "aaa"  "aaaXaaaXaaaXaaa"  == ["","X","X","X",""]
-- > splitOn "x"    "x"                == ["",""]
--
-- and
--
-- > intercalate s . splitOn s         == id
-- > splitOn (singleton c)             == split (==c)
--
-- (Note: the string @s@ to split on above cannot be empty.)
--
-- This function is strict in its first argument, and lazy in its
-- second.
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
splitOn :: Text
        -- ^ String to split on. If this string is empty, an error
        -- will occur.
        -> Text
        -- ^ Input text.
        -> [Text]
splitOn pat src
    | null pat        = emptyError "splitOn"
    | isSingleton pat = split (== head pat) src
    | otherwise       = go 0 (indices pat src) src
  where
    go  _ []     cs = [cs]
    go !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
                      in  h : go (x+l) xs (dropWords l t)
    l = foldlChunks (\a (T.Text _ _ b) -> a + fromIntegral b) 0 pat
{-# INLINE [1] splitOn #-}

{-# RULES
"LAZY TEXT splitOn/singleton -> split/==" [~1] forall c t.
    splitOn (singleton c) t = split (==c) t
  #-}

-- | /O(n)/ Splits a 'Text' into components delimited by separators,
-- where the predicate returns True for a separator element.  The
-- resulting components do not contain the separators.  Two adjacent
-- separators result in an empty component in the output.  eg.
--
-- > split (=='a') "aabbaca" == ["","","bb","c",""]
-- > split (=='a') []        == [""]
split :: (Char -> Bool) -> Text -> [Text]
split _ Empty = [Empty]
split p (Chunk t0 ts0) = comb [] (T.split p t0) ts0
  where comb acc (s:[]) Empty        = revChunks (s:acc) : []
        comb acc (s:[]) (Chunk t ts) = comb (s:acc) (T.split p t) ts
        comb acc (s:ss) ts           = revChunks (s:acc) : comb [] ss ts
        comb _   []     _            = impossibleError "split"
{-# INLINE split #-}

-- | /O(n)/ Splits a 'Text' into components of length @k@.  The last
-- element may be shorter than the other chunks, depending on the
-- length of the input. Examples:
--
-- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]
-- > chunksOf 4 "haskell.org" == ["hask","ell.","org"]
chunksOf :: Int64 -> Text -> [Text]
chunksOf k = go
  where
    go t = case splitAt k t of
             (a,b) | null a    -> []
                   | otherwise -> a : go b
{-# INLINE chunksOf #-}

-- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at
-- newline 'Char's. The resulting strings do not contain newlines.
lines :: Text -> [Text]
lines Empty = []
lines t = let (l,t') = break ((==) '\n') t
          in l : if null t' then []
                 else lines (tail t')

-- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's
-- representing white space.
words :: Text -> [Text]
words = L.filter (not . null) . split isSpace
{-# INLINE words #-}

-- | /O(n)/ Joins lines, after appending a terminating newline to
-- each.
unlines :: [Text] -> Text
unlines = concat . L.map (`snoc` '\n')
{-# INLINE unlines #-}

-- | /O(n)/ Joins words using single space characters.
unwords :: [Text] -> Text
unwords = intercalate (singleton ' ')
{-# INLINE unwords #-}

-- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns
-- 'True' iff the first is a prefix of the second.  Subject to fusion.
isPrefixOf :: Text -> Text -> Bool
isPrefixOf Empty _  = True
isPrefixOf _ Empty  = False
isPrefixOf (Chunk x xs) (Chunk y ys)
    | lx == ly  = x == y  && isPrefixOf xs ys
    | lx <  ly  = x == yh && isPrefixOf xs (Chunk yt ys)
    | otherwise = xh == y && isPrefixOf (Chunk xt xs) ys
  where (xh,xt) = T.splitAt ly x
        (yh,yt) = T.splitAt lx y
        lx = T.length x
        ly = T.length y
{-# INLINE [1] isPrefixOf #-}

{-# RULES
"LAZY TEXT isPrefixOf -> fused" [~1] forall s t.
    isPrefixOf s t = S.isPrefixOf (stream s) (stream t)
"LAZY TEXT isPrefixOf -> unfused" [1] forall s t.
    S.isPrefixOf (stream s) (stream t) = isPrefixOf s t
  #-}

-- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returns
-- 'True' iff the first is a suffix of the second.
isSuffixOf :: Text -> Text -> Bool
isSuffixOf x y = reverse x `isPrefixOf` reverse y
{-# INLINE isSuffixOf #-}
-- TODO: a better implementation

-- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns
-- 'True' iff the first is contained, wholly and intact, anywhere
-- within the second.
--
-- This function is strict in its first argument, and lazy in its
-- second.
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
isInfixOf :: Text -> Text -> Bool
isInfixOf needle haystack
    | null needle        = True
    | isSingleton needle = S.elem (head needle) . S.stream $ haystack
    | otherwise          = not . L.null . indices needle $ haystack
{-# INLINE [1] isInfixOf #-}

{-# RULES
"LAZY TEXT isInfixOf/singleton -> S.elem/S.stream" [~1] forall n h.
    isInfixOf (singleton n) h = S.elem n (S.stream h)
  #-}

-------------------------------------------------------------------------------
-- * View patterns

-- | /O(n)/ Return the suffix of the second string if its prefix
-- matches the entire first string.
--
-- Examples:
--
-- > stripPrefix "foo" "foobar" == Just "bar"
-- > stripPrefix ""    "baz"    == Just "baz"
-- > stripPrefix "foo" "quux"   == Nothing
--
-- This is particularly useful with the @ViewPatterns@ extension to
-- GHC, as follows:
--
-- > {-# LANGUAGE ViewPatterns #-}
-- > import Data.Text.Lazy as T
-- >
-- > fnordLength :: Text -> Int
-- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf
-- > fnordLength _                                 = -1
stripPrefix :: Text -> Text -> Maybe Text
stripPrefix p t
    | null p    = Just t
    | otherwise = case commonPrefixes p t of
                    Just (_,c,r) | null c -> Just r
                    _                     -> Nothing

-- | /O(n)/ Find the longest non-empty common prefix of two strings
-- and return it, along with the suffixes of each string at which they
-- no longer match.
--
-- If the strings do not have a common prefix or either one is empty,
-- this function returns 'Nothing'.
--
-- Examples:
--
-- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
-- > commonPrefixes "veeble" "fetzer"  == Nothing
-- > commonPrefixes "" "baz"           == Nothing
commonPrefixes :: Text -> Text -> Maybe (Text,Text,Text)
commonPrefixes Empty _ = Nothing
commonPrefixes _ Empty = Nothing
commonPrefixes a0 b0   = Just (go a0 b0 [])
  where
    go t0@(Chunk x xs) t1@(Chunk y ys) ps
        = case T.commonPrefixes x y of
            Just (p,a,b)
              | T.null a  -> go xs (chunk b ys) (p:ps)
              | T.null b  -> go (chunk a xs) ys (p:ps)
              | otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
            Nothing       -> (fromChunks (L.reverse ps),t0,t1)
    go t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)

-- | /O(n)/ Return the prefix of the second string if its suffix
-- matches the entire first string.
--
-- Examples:
--
-- > stripSuffix "bar" "foobar" == Just "foo"
-- > stripSuffix ""    "baz"    == Just "baz"
-- > stripSuffix "foo" "quux"   == Nothing
--
-- This is particularly useful with the @ViewPatterns@ extension to
-- GHC, as follows:
--
-- > {-# LANGUAGE ViewPatterns #-}
-- > import Data.Text.Lazy as T
-- >
-- > quuxLength :: Text -> Int
-- > quuxLength (stripSuffix "quux" -> Just pre) = T.length pre
-- > quuxLength _                                = -1
stripSuffix :: Text -> Text -> Maybe Text
stripSuffix p t = reverse `fmap` stripPrefix (reverse p) (reverse t)

-- | /O(n)/ 'filter', applied to a predicate and a 'Text',
-- returns a 'Text' containing those characters that satisfy the
-- predicate.
filter :: (Char -> Bool) -> Text -> Text
filter p t = unstream (S.filter p (stream t))
{-# INLINE filter #-}

-- | /O(n)/ The 'find' function takes a predicate and a 'Text', and
-- returns the first element in matching the predicate, or 'Nothing'
-- if there is no such element.
find :: (Char -> Bool) -> Text -> Maybe Char
find p t = S.findBy p (stream t)
{-# INLINE find #-}

-- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
-- and returns the pair of 'Text's with elements which do and do not
-- satisfy the predicate, respectively; i.e.
--
-- > partition p t == (filter p t, filter (not . p) t)
partition :: (Char -> Bool) -> Text -> (Text, Text)
partition p t = (filter p t, filter (not . p) t)
{-# INLINE partition #-}

-- | /O(n)/ 'Text' index (subscript) operator, starting from 0.
index :: Text -> Int64 -> Char
index t n = S.index (stream t) n
{-# INLINE index #-}

-- | /O(n+m)/ The 'count' function returns the number of times the
-- query string appears in the given 'Text'. An empty query string is
-- invalid, and will cause an error to be raised.
--
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.
count :: Text -> Text -> Int64
count pat src
    | null pat        = emptyError "count"
    | otherwise       = go 0 (indices pat src)
  where go !n []     = n
        go !n (_:xs) = go (n+1) xs
{-# INLINE [1] count #-}

{-# RULES
"LAZY TEXT count/singleton -> countChar" [~1] forall c t.
    count (singleton c) t = countChar c t
  #-}

-- | /O(n)/ The 'countChar' function returns the number of times the
-- query element appears in the given 'Text'.  Subject to fusion.
countChar :: Char -> Text -> Int64
countChar c t = S.countChar c (stream t)

-- | /O(n)/ 'zip' takes two 'Text's and returns a list of
-- corresponding pairs of bytes. If one input 'Text' is short,
-- excess elements of the longer 'Text' are discarded. This is
-- equivalent to a pair of 'unpack' operations.
zip :: Text -> Text -> [(Char,Char)]
zip a b = S.unstreamList $ S.zipWith (,) (stream a) (stream b)
{-# INLINE [0] zip #-}

-- | /O(n)/ 'zipWith' generalises 'zip' by zipping with the function
-- given as the first argument, instead of a tupling function.
-- Performs replacement on invalid scalar values.
zipWith :: (Char -> Char -> Char) -> Text -> Text -> Text
zipWith f t1 t2 = unstream (S.zipWith g (stream t1) (stream t2))
    where g a b = safe (f a b)
{-# INLINE [0] zipWith #-}

revChunks :: [T.Text] -> Text
revChunks = L.foldl' (flip chunk) Empty

emptyError :: String -> a
emptyError fun = P.error ("Data.Text.Lazy." ++ fun ++ ": empty input")

impossibleError :: String -> a
impossibleError fun = P.error ("Data.Text.Lazy." ++ fun ++ ": impossible case")
</pre></br><h2>printed</h2></br><pre>{-# OPTIONS_GHC -fno-warn-orphans #-}
{-# LANGUAGE BangPatterns, MagicHash, CPP #-}
#if __GLASGOW_HASKELL__ >= 702
{-# LANGUAGE Trustworthy #-}
#endif
#if __GLASGOW_HASKELL__ >= 708
{-# LANGUAGE TypeFamilies #-}
#endif

-- |
-- Module      : Data.Text.Lazy
-- Copyright   : (c) 2009, 2010, 2012 Bryan O'Sullivan
--
-- License     : BSD-style
-- Maintainer  : bos@serpentine.com
-- Stability   : experimental
-- Portability : GHC
--
-- A time and space-efficient implementation of Unicode text using
-- lists of packed arrays.
--
-- /Note/: Read below the synopsis for important notes on the use of
-- this module.
--
-- The representation used by this module is suitable for high
-- performance use and for streaming large quantities of data.  It
-- provides a means to manipulate a large body of text without
-- requiring that the entire content be resident in memory.
--
-- Some operations, such as 'concat', 'append', 'reverse' and 'cons',
-- have better time complexity than their "Data.Text" equivalents, due
-- to the underlying representation being a list of chunks. For other
-- operations, lazy 'Text's are usually within a few percent of strict
-- ones, but often with better heap usage if used in a streaming
-- fashion. For data larger than available memory, or if you have
-- tight memory constraints, this module will be the only option.
--
-- This module is intended to be imported @qualified@, to avoid name
-- clashes with "Prelude" functions.  eg.
--
-- > import qualified Data.Text.Lazy as L

module Data.Text.Lazy
    (
    -- * Fusion
    -- $fusion

    -- * Acceptable data
    -- $replacement

    -- * Types
      Text

    -- * Creation and elimination
    , pack
    , unpack
    , singleton
    , empty
    , fromChunks
    , toChunks
    , toStrict
    , fromStrict
    , foldrChunks
    , foldlChunks

    -- * Basic interface
    , cons
    , snoc
    , append
    , uncons
    , head
    , last
    , tail
    , init
    , null
    , length
    , compareLength

    -- * Transformations
    , map
    , intercalate
    , intersperse
    , transpose
    , reverse
    , replace

    -- ** Case conversion
    -- $case
    , toCaseFold
    , toLower
    , toUpper
    , toTitle

    -- ** Justification
    , justifyLeft
    , justifyRight
    , center

    -- * Folds
    , foldl
    , foldl'
    , foldl1
    , foldl1'
    , foldr
    , foldr1

    -- ** Special folds
    , concat
    , concatMap
    , any
    , all
    , maximum
    , minimum

    -- * Construction

    -- ** Scans
    , scanl
    , scanl1
    , scanr
    , scanr1

    -- ** Accumulating maps
    , mapAccumL
    , mapAccumR

    -- ** Generation and unfolding
    , replicate
    , unfoldr
    , unfoldrN

    -- * Substrings

    -- ** Breaking strings
    , take
    , takeEnd
    , drop
    , dropEnd
    , takeWhile
    , dropWhile
    , dropWhileEnd
    , dropAround
    , strip
    , stripStart
    , stripEnd
    , splitAt
    , span
    , breakOn
    , breakOnEnd
    , break
    , group
    , groupBy
    , inits
    , tails

    -- ** Breaking into many substrings
    -- $split
    , splitOn
    , split
    , chunksOf
    -- , breakSubstring

    -- ** Breaking into lines and words
    , lines
    , words
    , unlines
    , unwords

    -- * Predicates
    , isPrefixOf
    , isSuffixOf
    , isInfixOf

    -- ** View patterns
    , stripPrefix
    , stripSuffix
    , commonPrefixes

    -- * Searching
    , filter
    , find
    , breakOnAll
    , partition

    -- , findSubstring

    -- * Indexing
    , index
    , count

    -- * Zipping and unzipping
    , zip
    , zipWith

    -- -* Ordered text
    -- , sort
    ) where

import Prelude (Char, Bool(..), Maybe(..), String,
                Eq(..), Ord(..), Ordering(..), Read(..), Show(..),
                (&&), (||), (+), (-), (.), ($), (++),
                error, flip, fmap, fromIntegral, not, otherwise, quot)
import qualified Prelude as P
#if defined(HAVE_DEEPSEQ)
import Control.DeepSeq (NFData(..))
#endif
import Data.Int (Int64)
import qualified Data.List as L
import Data.Char (isSpace)
import Data.Data (Data(gfoldl, toConstr, gunfold, dataTypeOf))
import Data.Data (mkNoRepType)
import Data.Monoid (Monoid(..))
import Data.String (IsString(..))
import qualified Data.Text as T
import qualified Data.Text.Internal as T
import qualified Data.Text.Internal.Fusion.Common as S
import qualified Data.Text.Unsafe as T
import qualified Data.Text.Internal.Lazy.Fusion as S
import Data.Text.Internal.Fusion.Types (PairS(..))
import Data.Text.Internal.Lazy.Fusion (stream, unstream)
import Data.Text.Internal.Lazy (Text(..), chunk, empty, foldlChunks, foldrChunks)
import Data.Text.Internal (firstf, safe, text)
import qualified Data.Text.Internal.Functions as F
import Data.Text.Internal.Lazy.Search (indices)
#if __GLASGOW_HASKELL__ >= 702
import qualified GHC.CString as GHC
#else
import qualified GHC.Base as GHC
#endif
#if __GLASGOW_HASKELL__ >= 708
import qualified GHC.Exts as Exts
#endif
import GHC.Prim (Addr#)

-- $fusion
--
-- Most of the functions in this module are subject to /fusion/,
-- meaning that a pipeline of such functions will usually allocate at
-- most one 'Text' value.
--
-- As an example, consider the following pipeline:
--
-- > import Data.Text.Lazy as T
-- > import Data.Text.Lazy.Encoding as E
-- > import Data.ByteString.Lazy (ByteString)
-- >
-- > countChars :: ByteString -> Int
-- > countChars = T.length . T.toUpper . E.decodeUtf8
--
-- From the type signatures involved, this looks like it should
-- allocate one 'ByteString' value, and two 'Text' values. However,
-- when a module is compiled with optimisation enabled under GHC, the
-- two intermediate 'Text' values will be optimised away, and the
-- function will be compiled down to a single loop over the source
-- 'ByteString'.
--
-- Functions that can be fused by the compiler are documented with the
-- phrase \"Subject to fusion\".

-- $replacement
--
-- A 'Text' value is a sequence of Unicode scalar values, as defined
-- in &#xa7;3.9, definition D76 of the Unicode 5.2 standard:
-- <http://www.unicode.org/versions/Unicode5.2.0/ch03.pdf#page=35>. As
-- such, a 'Text' cannot contain values in the range U+D800 to U+DFFF
-- inclusive. Haskell implementations admit all Unicode code points
-- (&#xa7;3.4, definition D10) as 'Char' values, including code points
-- from this invalid range.  This means that there are some 'Char'
-- values that are not valid Unicode scalar values, and the functions
-- in this module must handle those cases.
--
-- Within this module, many functions construct a 'Text' from one or
-- more 'Char' values. Those functions will substitute 'Char' values
-- that are not valid Unicode scalar values with the replacement
-- character \"&#xfffd;\" (U+FFFD).  Functions that perform this
-- inspection and replacement are documented with the phrase
-- \"Performs replacement on invalid scalar values\".
--
-- (One reason for this policy of replacement is that internally, a
-- 'Text' value is represented as packed UTF-16 data. Values in the
-- range U+D800 through U+DFFF are used by UTF-16 to denote surrogate
-- code points, and so cannot be represented. The functions replace
-- invalid scalar values, instead of dropping them, as a security
-- measure. For details, see Unicode Technical Report 36, &#xa7;3.5:
-- <http://unicode.org/reports/tr36#Deletion_of_Noncharacters>)

equal :: Text -> Text -> Bool
equal Empty Empty = True
equal Empty _     = False
equal _ Empty     = False
equal (Chunk a as) (Chunk b bs) =
    case compare lenA lenB of
      LT -> a == (T.takeWord16 lenA b) &&
            as `equal` Chunk (T.dropWord16 lenA b) bs
      EQ -> a == b && as `equal` bs
      GT -> T.takeWord16 lenB a == b &&
            Chunk (T.dropWord16 lenB a) as `equal` bs
  where lenA = T.lengthWord16 a
        lenB = T.lengthWord16 b

instance Eq Text where
    (==) = equal
    {-# INLINE (==) #-}

instance Ord Text where
    compare = compareText

compareText :: Text -> Text -> Ordering
compareText Empty Empty = EQ
compareText Empty _     = LT
compareText _     Empty = GT
compareText (Chunk a0 as) (Chunk b0 bs) = outer a0 b0
 where
  outer ta@(T.Text arrA offA lenA) tb@(T.Text arrB offB lenB) = go 0 0
   where
    go !i !j
      | i >= lenA = compareText as (chunk (T.Text arrB (offB+j) (lenB-j)) bs)
      | j >= lenB = compareText (chunk (T.Text arrA (offA+i) (lenA-i)) as) bs
      | a < b     = LT
      | a > b     = GT
      | otherwise = go (i+di) (j+dj)
      where T.Iter a di = T.iter ta i
            T.Iter b dj = T.iter tb j

instance Show Text where
    showsPrec p ps r = showsPrec p (unpack ps) r

instance Read Text where
    readsPrec p str = [(pack x,y) | (x,y) <- readsPrec p str]

instance Monoid Text where
    mempty  = empty
    mappend = append
    mconcat = concat

instance IsString Text where
    fromString = pack

#if __GLASGOW_HASKELL__ >= 708
instance Exts.IsList Text where
    type Item Text = Char
    fromList       = pack
    toList         = unpack
#endif

#if defined(HAVE_DEEPSEQ)
instance NFData Text where
    rnf Empty        = ()
    rnf (Chunk _ ts) = rnf ts
#endif

instance Data Text where
  gfoldl f z txt = z pack `f` (unpack txt)
  toConstr _     = error "Data.Text.Lazy.Text.toConstr"
  gunfold _ _    = error "Data.Text.Lazy.Text.gunfold"
  dataTypeOf _   = mkNoRepType "Data.Text.Lazy.Text"

-- | /O(n)/ Convert a 'String' into a 'Text'.
--
-- Subject to fusion.  Performs replacement on invalid scalar values.
pack :: String -> Text
pack = unstream . S.streamList . L.map safe
{-# INLINE [1] pack #-}

-- | /O(n)/ Convert a 'Text' into a 'String'.
-- Subject to fusion.
unpack :: Text -> String
unpack t = S.unstreamList (stream t)
{-# INLINE [1] unpack #-}

-- | /O(n)/ Convert a literal string into a Text.
unpackCString# :: Addr# -> Text
unpackCString# addr# = unstream (S.streamCString# addr#)
{-# NOINLINE unpackCString# #-}

{-# RULES "TEXT literal" forall a.
    unstream (S.streamList (L.map safe (GHC.unpackCString# a)))
      = unpackCString# a #-}

{-# RULES "TEXT literal UTF8" forall a.
    unstream (S.streamList (L.map safe (GHC.unpackCStringUtf8# a)))
      = unpackCString# a #-}

{-# RULES "LAZY TEXT empty literal"
    unstream (S.streamList (L.map safe []))
      = Empty #-}

{-# RULES "LAZY TEXT empty literal" forall a.
    unstream (S.streamList (L.map safe [a]))
      = Chunk (T.singleton a) Empty #-}

-- | /O(1)/ Convert a character into a Text.  Subject to fusion.
-- Performs replacement on invalid scalar values.
singleton :: Char -> Text
singleton c = Chunk (T.singleton c) Empty
{-# INLINE [1] singleton #-}

{-# RULES
"LAZY TEXT singleton -> fused" [~1] forall c.
    singleton c = unstream (S.singleton c)
"LAZY TEXT singleton -> unfused" [1] forall c.
    unstream (S.singleton c) = singleton c
  #-}

-- | /O(c)/ Convert a list of strict 'T.Text's into a lazy 'Text'.
fromChunks-- | /O(c)/ Convert a list of strict 'T.Text's into a lazy 'Text'.:: [T.Text] -> Text
fromChunks :: [T.TextL.foldr] ->chunkEmpty cs
fromChunks cs = L.foldr chunk Empty cs
-- | /O(n)/ Convert a lazy 'Text' into a list of strict 'T.Text's.
toChunks-- | /O(n)/ Convert a lazy 'Text' into a list of strict 'T.Text's.:: Text -> [T.Text]
toChunks :: Text= foldrChunks-> [T.Text(]) [] cs
toChunks cs = foldrChunks (:) [] cs
-- | /O(n)/ Convert a lazy 'Text' into a strict 'T.Text'.
toStrict-- | /O(n)/ Convert a lazy 'Text' into a strict 'T.Text'.:: Text -> T.Text
toStrict ::t =TextT.concat-> T.Text(toChunks t)
toStrict{-# INLINE =1T.concat] toStricttoChunks#-}     t)
{-# INLINE [1] toStrict #-}
-- | /O(c)/ Convert a strict 'T.Text' into a lazy 'Text'.
fromStrict-- | /O(c)/ Convert a strict 'T.Text' into a lazy 'Text'.:: T.Text -> Text
fromStrict ::t =T.Textchunk ->t Empty
fromStrict t1= chunkfromStrict Empty#-}
{-# INLINE [1] fromStrict #-}
-- -----------------------------------------------------------------------------
-- * Basic functions-- -----------------------------------------------------------------------------
-- * Basic functions
-- | /O(n)/ Adds a character to the front of a 'Text'.  This function
-- is more costly than its 'List' counterpart because it requires-- | /O(n)/ Adds a character to the front of a 'Text'.  This function
-- copying a new array.  Subject to fusion.-- is more costly than its 'List' counterpart because it requires
cons-- copying a new array.  Subject to fusion.:: Char -> Text -> Text
cons ::c tChar= Chunk-> Text(T.singleton-> Text  c) t
cons{-# INLINE t = Chunk[1] consT.singleton#-}       c) t
{-# INLINE [1] cons #-}
infixr 5 `cons`
infixr 5 `cons`
{-# RULES
{-# RULES"LAZY TEXT cons -> fused" [~1] forall c t.
"LAZY TEXT cons -> fused"cons c t = unstream (S.cons[~1] forallc (stream t.t))
"LAZY TEXT cons -> unfused" c t = unstream (S.cons[1] cforallstreamc tt))
"LAZY TEXT cons -> unfused"unstream (S.cons c (stream[1]tforall)) = cons t. t
 #-}unstream (S.cons c (stream t)) = cons c t
 #-}
-- | /O(n)/ Adds a character to the end of a 'Text'.  This copies the
-- entire array in the process, unless fused.  Subject to fusion.
snoc-- | /O(n)/ Adds a character to the end of a 'Text'.  This copies the:: Text -> Char -> Text
snoc-- entire array in the process, unless fused.  Subject to fusion.t c = foldrChunks Chunk (singleton c) t
snoc{-# INLINE:: Text[1->] snoc#-}-> Text
snoc t c = foldrChunks Chunk (singleton c) t
{-# INLINE{-# RULES  [1] snoc #-}
"LAZY TEXT snoc -> fused" [~1] forall t c.
{-# RULESsnoc t c = unstream (S.snoc (stream t) c)
"LAZY TEXT snoc -> fused""LAZY TEXT snoc -> unfused"[~1]]forallforallttc..
    snocunstream c =S.snoc(streamS.snoct) (stream) = snoc)tc)
"LAZY TEXT snoc -> unfused"#-}                        [1] forall t c.
    unstream (S.snoc (stream t) c) = snoc t c
-- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.#-}
append :: Text -> Text -> Text
append xs ys = foldrChunks Chunk ys xs
{-# INLINE-- | /O(n\/c)/ Appends one 'Text' to another.  Subject to fusion.[1] append #-}
append :: Text -> Text -> Text
append{-# RULES ys = foldrChunks Chunk ys xs
{-# INLINE"LAZY TEXT append -> fused"[1] append #-}   [~1] forall t1 t2.
    append t1 t2 = unstream (S.append (stream t1) (stream t2))
{-# RULES"LAZY TEXT append -> unfused" [1] forall t1 t2.
"LAZY TEXT append -> fused"unstream (S.append (stream[~1]t1forall) (stream t2.) = append t1 t2
 #-}append t1 t2 = unstream (S.append (stream t1) (stream t2))
"LAZY TEXT append -> unfused" [1] forall t1 t2.
-- | /O(1)/ Returns the first character and rest of a 'Text', or (S.append (stream t1) (stream t2)) = append t1 t2
-- 'Nothing' if empty. Subject to fusion.#-}
uncons :: Text -> Maybe (Char, Text)
uncons Empty        = Nothing
uncons-- | /O(1)/ Returns the first character and rest of a 'Text', or(Chunk t ts) = Just (T.unsafeHead t, ts')
-- 'Nothing' if empty. Subject to fusion.where ts' | T.compareLength t 1 == EQ = ts
uncons :: Text| otherwise-> Maybe (Char, Text)    = Chunk (T.unsafeTail t) ts
uncons{-# INLINEuncons #-}= Nothing
uncons (Chunk t ts) = Just (T.unsafeHead t, ts')
-- | /O(1)/ Returns the first character of a 'Text', which must bewhere ts' | T.compareLength t 1 == EQ = ts
                                                                -- non-empty.  Subject to fusion. otherwise                 = Chunk (T.unsafeTail t) ts
{-# INLINEhead :: Text-> Char#-}
head t = S.head (stream t)
{-# INLINE-- | /O(1)/ Returns the first character of a 'Text', which must behead #-}
-- non-empty.  Subject to fusion.
head-- | /O(1)/ Returns all characters after the head of a 'Text', which:: Text -> Char
head-- must be non-empty.  Subject to fusion. = S.head (stream t)
{-# INLINEtail :: Text-> #-}Text
tail (Chunk t ts) = chunk (T.tail t) ts
tail-- | /O(1)/ Returns all characters after the head of a 'Text', whichEmpty        = emptyError "tail"
{-# INLINE-- must be non-empty.  Subject to fusion.[1] tail #-}
tail :: Text -> Text
tail{-# RULESChunk t ts) = chunk (T.tail t) ts
tail"LAZY TEXT tail -> fused"        = emptyError[~1] "tail" t.
{-# INLINEtail t [1]unstream #-}(S.tail (stream t))
"LAZY TEXT tail -> unfused" [1] forall t.
{-# RULESunstream (S.tail (stream t)) = tail t
"LAZY TEXT tail -> fused"#-}                      [~1] forall t.
    tail t = unstream (S.tail (stream t))
"LAZY TEXT tail -> unfused"-- | /O(1)/ Returns all but the last character of a 'Text', which must[1] forall t.
-- be non-empty.  Subject to fusion. (S.tail (stream t)) = tail t
init#-} :: Text -> Text
init (Chunk t0 ts0) = go t0 ts0
    where go t (Chunk t' ts) = Chunk t (go t' ts)
-- | /O(1)/ Returns all but the last character of a 'Text', which mustgo t Empty         = chunk (T.init t) Empty
init-- be non-empty.  Subject to fusion.Empty = emptyError "init"
init{-# INLINE:: Text[1->] init#-}
init (Chunk t0 ts0) = go t0 ts0
{-# RULESwhere go t (Chunk t' ts) = Chunk t (go t' ts)
     "LAZY TEXT init -> fused" t Empty      [~1= chunkforall(T.initt.     t) Empty
initinitt = emptyErrorunstream (S.init(stream t))
{-# INLINE"LAZY TEXT init -> unfused"[1] init #-}     [1] forall t.
    unstream (S.init (stream t)) = init t
{-# RULES#-}
"LAZY TEXT init -> fused" [~1] forall t.
-- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to t = unstream (S.init (stream t))
"LAZY TEXT init -> unfused"-- fusion.                  [1] forall t.
nullunstream:: Text (->S.initBool (stream t)) = init t
null#-} Empty = True
null _     = False
{-# INLINE [1] null #-}
-- | /O(1)/ Tests whether a 'Text' is empty or not.  Subject to
{-# RULES-- fusion.
null"LAZY TEXT null -> fused":: Text -> Bool      [~1] forall t.
nullnullt = TrueS.null (stream t)
null"LAZY TEXT null -> unfused"     = False          [1] forall t.
{-# INLINES.null [1stream] nullt#-}) = null t
 #-}
{-# RULES
"LAZY TEXT null -> fused"-- | /O(1)/ Tests whether a 'Text' contains exactly one character.[~1] forall t.
-- Subject to fusion. t = S.null (stream t)
"LAZY TEXT null -> unfused"isSingleton :: Text -> Bool [1] forall t.
isSingleton (stream= S.isSingleton) = null.tstream
{-# INLINE#-}       isSingleton #-}

-- | /O(1)/ Returns the last character of a 'Text', which must be
-- non-empty.  Subject to fusion.-- | /O(1)/ Tests whether a 'Text' contains exactly one character.
last-- Subject to fusion.:: Text -> Char
isSingletonlast Empty  :: Text= ->emptyError    "last"
isSingletonlast (Chunk = S.isSingletonts) = go t ts . stream
{-# INLINEwhere go_ (Chunk t'#-}ts') = go t' ts'
          go t' Empty         = T.last t'
{-# INLINE-- | /O(1)/ Returns the last character of a 'Text', which must be[1] last #-}
-- non-empty.  Subject to fusion.
last{-# RULES:: Text -> Char
last"LAZY TEXT last -> fused"        = emptyError[~1] "last" t.
lastlastChunkt =tS.last) = go(stream ts t)
"LAZY TEXT last -> unfused"where go _ (Chunk t' ts')1= goforall ts't.
                           S.lastgo(stream Emptyt) = last t= T.last t'
{-# INLINE#-}      [1] last #-}

{-# RULES-- | /O(n)/ Returns the number of characters in a 'Text'.
"LAZY TEXT last -> fused"-- Subject to fusion.     [~1] forall t.
length::tText= S.last-> Int64stream t)
"LAZY TEXT last -> unfused"length = foldlChunks go 0   [1] forall t.
    S.lastwhere gostreaml t = t)+=fromIntegral t      (T.length t)
{-# INLINE#-}      [1] length #-}

{-# RULES
"LAZY TEXT length -> fused"-- | /O(n)/ Returns the number of characters in a 'Text'.[~1] forall t.
-- Subject to fusion.length t = S.length (stream t)
length"LAZY TEXT length -> unfused":: Text -> Int64       [1] forall t.
lengthS.length= foldlChunks(stream got) 0 length t
 #-}where go l t = l + fromIntegral (T.length t)
{-# INLINE [1] length #-}
-- | /O(n)/ Compare the count of characters in a 'Text' to a number.
{-# RULES-- Subject to fusion.
"LAZY TEXT length -> fused"--                          [~1] forall t.
-- This function gives the same answer as comparing against the result t = S.length (stream t)
"LAZY TEXT length -> unfused"-- of 'length', but can short circuit if the count of characters is[1] forall t.
-- greater than the number, and hence be more efficient. (stream t) = length t
compareLength#-}          :: Text -> Int64 -> Ordering
compareLength t n = S.compareLengthI (stream t) n
{-# INLINE [1] compareLength #-}
-- | /O(n)/ Compare the count of characters in a 'Text' to a number.
-- Subject to fusion.-- We don't apply those otherwise appealing length-to-compareLength
---- rewrite rules here, because they can change the strictness
-- properties of code.-- This function gives the same answer as comparing against the result
-- of 'length', but can short circuit if the count of characters is
-- greater than the number, and hence be more efficient.-- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
compareLength-- each element of @t@.  Subject to fusion.  Performs replacement on:: Text -> Int64 -> Ordering
compareLength-- invalid scalar values. n = S.compareLengthI (stream t) n
{-# INLINEmap :: (Char[1]->compareLengthChar) -> Text#-}-> Text
map f t = unstream (S.map (safe . f) (stream t))
{-# INLINE-- We don't apply those otherwise appealing length-to-compareLength[1] map #-}
-- rewrite rules here, because they can change the strictness
-- properties of code.-- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
-- 'Text's and concatenates the list after interspersing the first
-- argument between each element of the list.-- | /O(n)/ 'map' @f@ @t@ is the 'Text' obtained by applying @f@ to
intercalate-- each element of @t@.  Subject to fusion.  Performs replacement on:: Text -> [Text] -> Text
intercalate-- invalid scalar values.t = concat . (F.intersperse t)
map{-# INLINE:: (Charintercalate-> Char) ->#-} -> Text
map f t = unstream (S.map (safe . f) (stream t))
{-# INLINE-- | /O(n)/ The 'intersperse' function takes a character and places it[1] map #-}
-- between the characters of a 'Text'.  Subject to fusion.  Performs
-- replacement on invalid scalar values.-- | /O(n)/ The 'intercalate' function takes a 'Text' and a list of
intersperse-- 'Text's and concatenates the list after interspersing the first:: Char -> Text -> Text
intersperse-- argument between each element of the list.c t = unstream (S.intersperse (safe c) (stream t))
intercalate{-# INLINE intersperse:: Text -> [#-}Text] -> Text
intercalate t = concat . (F.intersperse t)
{-# INLINE-- | /O(n)/ Left-justify a string to the given length, using the #-}
-- specified fill character on the right. Subject to fusion.  Performs
-- replacement on invalid scalar values.-- | /O(n)/ The 'intersperse' function takes a character and places it
---- between the characters of a 'Text'.  Subject to fusion.  Performs
-- Examples:-- replacement on invalid scalar values.
intersperse--          :: Char -> Text -> Text
intersperse-- > justifyLeft 7 'x' "foo"    == "fooxxxx" t = unstream (S.intersperse (safe c) (stream t))
{-# INLINE-- > justifyLeft 3 'x' "foobar" == "foobar" #-}
justifyLeft :: Int64 -> Char -> Text -> Text
justifyLeft-- | /O(n)/ Left-justify a string to the given length, using thek c t
-- specified fill character on the right. Subject to fusion.  Performs| len >= k  = t
-- replacement on invalid scalar values.| otherwise = t `append` replicateChar (k-len) c
--where len = length t
{-# INLINE-- Examples:[1] justifyLeft #-}
--
{-# RULES-- > justifyLeft 7 'x' "foo"    == "fooxxxx"
"LAZY TEXT justifyLeft -> fused"-- > justifyLeft 3 'x' "foobar" == "foobar"[~1] forall k c t.
justifyLeftjustifyLeft:: Int64k c t->= Charunstream-> Text(S.justifyLeftI-> Text     k c (stream t))
justifyLeft"LAZY TEXT justifyLeft -> unfused" c t                  [1] forall k c t.
    |unstream >= kS.justifyLeftI= t          k c (stream t)) = justifyLeft k c t
  #-} otherwise = t `append` replicateChar (k-len) c
  where len = length t
{-# INLINE-- | /O(n)/ Right-justify a string to the given length, using the[1] justifyLeft #-}
-- specified fill character on the left.  Performs replacement on
{-# RULES-- invalid scalar values.
"LAZY TEXT justifyLeft -> fused"--                               [~1] forall k c t.
-- Examples: k c t = unstream (S.justifyLeftI k c (stream t))
"LAZY TEXT justifyLeft -> unfused"--                                 [1] forall k c t.
-- > justifyRight 7 'x' "bar"    == "xxxxbar" (S.justifyLeftI k c (stream t)) = justifyLeft k c t
-- > justifyRight 3 'x' "foobar" == "foobar"#-}
justifyRight :: Int64 -> Char -> Text -> Text
justifyRight k c t
-- | /O(n)/ Right-justify a string to the given length, using the| len >= k  = t
-- specified fill character on the left.  Performs replacement on| otherwise = replicateChar (k-len) c `append` t
-- invalid scalar values.where len = length t
--{-# INLINE justifyRight #-}
-- Examples:
---- | /O(n)/ Center a string to the given length, using the specified
-- > justifyRight 7 'x' "bar"    == "xxxxbar"-- fill character on either side.  Performs replacement on invalid
-- scalar values.-- > justifyRight 3 'x' "foobar" == "foobar"
justifyRight--           :: Int64 -> Char -> Text -> Text
justifyRight k c t
--  | len >= k  = t
-- > center 8 'x' "HS" = "xxxHSxxx" otherwise = replicateChar (k-len) c `append` t
centerwhere::Int64= length-> Char  -> Text -> Text
{-# INLINEcenter k c justifyRightt            #-}
    | len >= k  = t
-- | /O(n)/ Center a string to the given length, using the specified| otherwise = replicateChar l c `append` t `append` replicateChar r c
-- fill character on either side.  Performs replacement on invalidwhere len = length t
-- scalar values.d   = k - len
--      r   = d `quot` 2
-- Examples:l   = d - r
--{-# INLINE center #-}
-- > center 8 'x' "HS" = "xxxHSxxx"
center-- | /O(n)/ The 'transpose' function transposes the rows and columns:: Int64 -> Char -> Text -> Text
center-- of its 'Text' argument.  Note that this function uses 'pack', c t
-- 'unpack', and the list version of transpose, and is thus not very len >= k  = t
-- efficient. otherwise = replicateChar l c `append` t `append` replicateChar r c
transposewhere len::=[lengthText] -> [Text]
       transpose ts==kL.map len(\ss -> Chunk (T.pack ss) Empty)
               r   = d `quot`L.transpose          (L.map unpack ts))
       -- TODO: make this fast   = d - r
{-# INLINE center #-}
-- | /O(n)/ 'reverse' @t@ returns the elements of @t@ in reverse order.
reverse-- | /O(n)/ The 'transpose' function transposes the rows and columns:: Text -> Text
reverse-- of its 'Text' argument.  Note that this function uses 'pack',= rev Empty
-- 'unpack', and the list version of transpose, and is thus not verywhere rev a Empty        = a
-- efficient.rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts
transpose :: [Text] -> [Text]
transpose-- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in = L.map (\ss -> Chunk (T.pack ss) Empty)
-- @haystack@ with @replacement@.L.transpose (L.map unpack ts))
---- TODO: make this fast
-- This function behaves as though it was defined as follows:
---- | /O(n)/ 'reverse' @t@ returns the elements of @t@ in reverse order.
reverse-- @    :: Text -> Text
reverse-- replace needle replacement haystack == rev Empty
--   'intercalate' replacement ('splitOn' needle haystack)where rev a Empty        = a
                                                        -- @    rev a (Chunk t ts) = rev (Chunk (T.reverse t) a) ts
--
-- | /O(m+n)/ Replace every non-overlapping occurrence of @needle@ in
-- @haystack@ with @replacement@.-- @needle@ occurs in @replacement@, that occurrence will /not/ itself
---- be replaced recursively:
---- This function behaves as though it was defined as follows:
---- > replace "oo" "foo" "oo" == "foo"
---- @
-- replace needle replacement haystack =-- In cases where several instances of @needle@ overlap, only the
-- first one will be replaced:--   'intercalate' replacement ('splitOn' needle haystack)
---- @
---- > replace "ofo" "bar" "ofofo" == "barfo"
---- As this suggests, each occurrence is replaced exactly once.  So if
-- In (unlikely) bad cases, this function's time complexity degrades-- @needle@ occurs in @replacement@, that occurrence will /not/ itself
-- towards /O(n*m)/.-- be replaced recursively:
--replace :: Text
-- > replace "oo" "foo" "oo" == "foo"-- ^ @needle@ to search for.  If this string is empty, an
--      -- error will occur.
-- In cases where several instances of @needle@ overlap, only the-> Text
-- first one will be replaced:-- ^ @replacement@ to replace @needle@ with.
--      -> Text
-- > replace "ofo" "bar" "ofofo" == "barfo"-- ^ @haystack@ in which to search.
--      -> Text
replace-- In (unlikely) bad cases, this function's time complexity degradess d = intercalate d . splitOn s
{-# INLINE-- towards /O(n*m)/.replace #-}
replace :: Text
-- ------------------------------------------------------------------------------ ^ @needle@ to search for.  If this string is empty, an
-- ** Case conversions (folds)-- error will occur.
        -> Text
-- $case-- ^ @replacement@ to replace @needle@ with.
--      -> Text
-- With Unicode text, it is incorrect to use combinators like @map-- ^ @haystack@ in which to search.
-- toUpper@ to case convert each character of a string individually.-> Text
replace-- Instead, use the whole-string case conversion functions from this d = intercalate d . splitOn s
{-# INLINE-- module.  For correctness in different writing systems, these #-}
-- functions may map one input character to two or three output
-- characters.-- ----------------------------------------------------------------------------
-- ** Case conversions (folds)
-- | /O(n)/ Convert a string to folded case.  Subject to fusion.
---- $case
---- This function is mainly useful for performing caseless (or case
-- insensitive) string comparisons.-- With Unicode text, it is incorrect to use combinators like @map
---- toUpper@ to case convert each character of a string individually.
-- Instead, use the whole-string case conversion functions from this
---- module.  For correctness in different writing systems, these
-- @toCaseFold x == toCaseFold y@-- functions may map one input character to two or three output
---- characters.
-- The result string may be longer than the input string, and may
-- | /O(n)/ Convert a string to folded case.  Subject to fusion.-- differ from applying 'toLower' to the input string.  For instance,
---- the Armenian small ligature men now (U+FB13) is case folded to the
-- This function is mainly useful for performing caseless (or case-- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
-- insensitive) string comparisons.-- case folded to the Greek small letter letter mu (U+03BC) instead of
---- itself.
toCaseFold-- A string @x@ is a caseless match for a string @y@ if and only if::: Text -> Text
--toCaseFold t = unstream (S.toCaseFold (stream t))
{-# INLINE-- @toCaseFold x == toCaseFold y@[0] toCaseFold #-}
--
-- | /O(n)/ Convert a string to lower case, using simple case-- The result string may be longer than the input string, and may
-- conversion.  Subject to fusion.-- differ from applying 'toLower' to the input string.  For instance,
---- the Armenian small ligature men now (U+FB13) is case folded to the
-- The result string may be longer than the input string.  For-- bigram men now (U+0574 U+0576), while the micro sign (U+00B5) is
-- instance, the Latin capital letter I with dot above (U+0130) maps-- case folded to the Greek small letter letter mu (U+03BC) instead of
-- itself.-- to the sequence Latin small letter i (U+0069) followed by combining
toCaseFold-- dot above (U+0307).:: Text -> Text
toCaseFoldtoLower :: tText= unstream-> Text (S.toCaseFold (stream t))
{-# INLINEtoLower t =[0unstream] toCaseFold(S.toLower#-}   (stream t))
{-# INLINE toLower #-}
-- | /O(n)/ Convert a string to lower case, using simple case
-- conversion.  Subject to fusion.-- | /O(n)/ Convert a string to upper case, using simple case
---- conversion.  Subject to fusion.
---- The result string may be longer than the input string.  For
-- The result string may be longer than the input string.  For-- instance, the Latin capital letter I with dot above (U+0130) maps
-- instance, the German eszett (U+00DF) maps to the two-letter-- to the sequence Latin small letter i (U+0069) followed by combining
-- sequence SS.-- dot above (U+0307).
toLower :: Text -> Text
toLower t = unstream (S.toLower (stream t))
{-# INLINE toLower #-}

-- | /O(n)/ Convert a string to upper case, using simple case
-- conversion.  Subject to fusion.-- | /O(n)/ Convert a string to title case, using simple case
---- conversion.  Subject to fusion.
---- The result string may be longer than the input string.  For
-- instance, the German eszett (U+00DF) maps to the two-letter-- The first letter of the input is converted to title case, as is
-- sequence SS.-- every subsequent letter that immediately follows a non-letter.
toUpper-- Every letter that immediately follows another letter is converted:: Text -> Text
toUpper-- to lower case. = unstream (S.toUpper (stream t))
{-# INLINE--         toUpper #-}
-- The result string may be longer than the input string. For example,
-- the Latin small ligature &#xfb02; (U+FB02) is converted to the
-- | /O(n)/ Convert a string to title case, using simple case-- sequence Latin capital letter F (U+0046) followed by Latin small
-- letter l (U+006C).-- conversion.  Subject to fusion.
--
-- The first letter of the input is converted to title case, as is-- /Note/: this function does not take language or culture specific
-- rules into account. For instance, in English, different style-- every subsequent letter that immediately follows a non-letter.
-- guides disagree on whether the book name \"The Hill of the Red-- Every letter that immediately follows another letter is converted
-- to lower case.-- Fox\" is correctly title cased&#x2014;but this function will
---- capitalize /every/ word.
toTitle-- The result string may be longer than the input string. For example,:: Text -> Text
toTitle-- the Latin small ligature &#xfb02; (U+FB02) is converted to thet = unstream (S.toTitle (stream t))
{-# INLINE-- sequence Latin capital letter F (U+0046) followed by Latin smalltoTitle #-}
-- letter l (U+006C).
---- | /O(n)/ 'foldl', applied to a binary operator, a starting value
-- (typically the left-identity of the operator), and a 'Text',-- /Note/: this function does not take language or culture specific
-- rules into account. For instance, in English, different style-- reduces the 'Text' using the binary operator, from left to right.
-- Subject to fusion.-- guides disagree on whether the book name \"The Hill of the Red
foldl-- Fox\" is correctly title cased&#x2014;but this function will:: (a -> Char -> a) -> a -> Text -> a
foldl-- capitalize /every/ word.f z t = S.foldl f z (stream t)
toTitle{-# INLINE:: Textfoldl->#-}
toTitle t = unstream (S.toTitle (stream t))
{-# INLINE-- | /O(n)/ A strict version of 'foldl'. #-}
-- Subject to fusion.
foldl'-- | /O(n)/ 'foldl', applied to a binary operator, a starting value:: (a -> Char -> a) -> a -> Text -> a
foldl'-- (typically the left-identity of the operator), and a 'Text',f z t = S.foldl' f z (stream t)
{-# INLINE-- reduces the 'Text' using the binary operator, from left to right.foldl' #-}
-- Subject to fusion.
foldl-- | /O(n)/ A variant of 'foldl' that has no starting value argument,:: (a -> Char -> a) -> a -> Text -> a
foldl-- and thus must be applied to a non-empty 'Text'.  Subject to fusion. z t = S.foldl f z (stream t)
{-# INLINEfoldl1 :: (foldlChar ->#-}Char -> Char) -> Text -> Char
foldl1 f t = S.foldl1 f (stream t)
{-# INLINE-- | /O(n)/ A strict version of 'foldl'.foldl1 #-}
-- Subject to fusion.
foldl'-- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.:: (a -> Char -> a) -> a -> Text -> a
foldl'foldl1'f:: tChar= S.foldl'-> Charf-> (Charstream) ->t)Text -> Char
{-# INLINEfoldl1' f tfoldl'= S.foldl1'#-}   f (stream t)
{-# INLINE foldl1' #-}
-- | /O(n)/ A variant of 'foldl' that has no starting value argument,
-- | /O(n)/ 'foldr', applied to a binary operator, a starting value-- and thus must be applied to a non-empty 'Text'.  Subject to fusion.
foldl1-- (typically the right-identity of the operator), and a 'Text',:: (Char -> Char -> Char) -> Text -> Char
foldl1-- reduces the 'Text' using the binary operator, from right to left. t = S.foldl1 f (stream t)
{-# INLINE-- Subject to fusion. #-}
foldr :: (Char -> a -> a) -> a -> Text -> a
foldr-- | /O(n)/ A strict version of 'foldl1'.  Subject to fusion.f z t = S.foldr f z (stream t)
foldl1'{-# INLINE:: (foldrChar ->#-}Char -> Char) -> Text -> Char
foldl1' f t = S.foldl1' f (stream t)
{-# INLINE-- | /O(n)/ A variant of 'foldr' that has no starting value argument, #-}
-- and thus must be applied to a non-empty 'Text'.  Subject to
-- fusion.-- | /O(n)/ 'foldr', applied to a binary operator, a starting value
foldr1-- (typically the right-identity of the operator), and a 'Text',:: (Char -> Char -> Char) -> Text -> Char
foldr1-- reduces the 'Text' using the binary operator, from right to left.f t = S.foldr1 f (stream t)
{-# INLINE-- Subject to fusion.foldr1 #-}
foldr :: (Char -> a -> a) -> a -> Text -> a
foldr-- | /O(n)/ Concatenate a list of 'Text's. z t = S.foldr f z (stream t)
{-# INLINEconcat :: [foldrText] #-}-> Text
concat = to
-- | /O(n)/ A variant of 'foldr' that has no starting value argument,where
-- and thus must be applied to a non-empty 'Text'.  Subject togo Empty        css = to css
-- fusion.go (Chunk c cs) css = Chunk c (go cs css)
foldr1to ::[] (Char -> Char ->= Empty) -> Text -> Char
foldr1to fcs:=css)       f (streamgo cs tcss)
{-# INLINE foldr1 #-}

-- | /O(n)/ Concatenate a list of 'Text's.-- | /O(n)/ Map a function over a 'Text' that results in a 'Text', and
concat-- concatenate the results.:: [Text] -> Text
concatconcatMap= to:: (Char -> Text) -> Text -> Text
concatMapwhere   f = concat . foldr ((:) . f) []
{-# INLINE EmptyconcatMapcss#-}= to css
    go (Chunk c cs) css = Chunk c (go cs css)
-- | /O(n)/ 'any' @p@ @t@ determines whether any character in the []               = Empty
-- 'Text' @t@ satisifes the predicate @p@. Subject to fusion. (cs:css)         = go cs css
{-# INLINEany :: (Char-> Bool#-}) -> Text -> Bool
any p t = S.any p (stream t)
{-# INLINE-- | /O(n)/ Map a function over a 'Text' that results in a 'Text', andany #-}
-- concatenate the results.
concatMap-- | /O(n)/ 'all' @p@ @t@ determines whether all characters in the:: (Char -> Text) -> Text -> Text
concatMap-- 'Text' @t@ satisify the predicate @p@. Subject to fusion. = concat . foldr ((:) . f) []
{-# INLINEall :: (Char-> Bool)#-}-> Text -> Bool
all p t = S.all p (stream t)
{-# INLINE-- | /O(n)/ 'any' @p@ @t@ determines whether any character in theall #-}
-- 'Text' @t@ satisifes the predicate @p@. Subject to fusion.
any-- | /O(n)/ 'maximum' returns the maximum value from a 'Text', which:: (Char -> Bool) -> Text -> Bool
any-- must be non-empty. Subject to fusion. t = S.any p (stream t)
{-# INLINEmaximum :: anyText#-}-> Char
maximum t = S.maximum (stream t)
{-# INLINE-- | /O(n)/ 'all' @p@ @t@ determines whether all characters in themaximum #-}
-- 'Text' @t@ satisify the predicate @p@. Subject to fusion.
all-- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which:: (Char -> Bool) -> Text -> Bool
all-- must be non-empty. Subject to fusion. t = S.all p (stream t)
{-# INLINEminimum :: allText#-}-> Char
minimum t = S.minimum (stream t)
{-# INLINE-- | /O(n)/ 'maximum' returns the maximum value from a 'Text', whichminimum #-}
-- must be non-empty. Subject to fusion.
maximum-- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list of:: Text -> Char
maximum-- successive reduced values from the left. Subject to fusion. = S.maximum (stream t)
{-# INLINE-- Performs replacement on invalid scalar values. #-}
--
-- | /O(n)/ 'minimum' returns the minimum value from a 'Text', which-- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
---- must be non-empty. Subject to fusion.
minimum-- Note that:: Text -> Char
minimum--      t = S.minimum (stream t)
{-# INLINE-- > last (scanl f z xs) == foldl f z xs. #-}
scanl :: (Char -> Char -> Char) -> Char -> Text -> Text
scanl-- | /O(n)/ 'scanl' is similar to 'foldl', but returns a list off z t = unstream (S.scanl g z (stream t))
-- successive reduced values from the left. Subject to fusion.where g a b = safe (f a b)
{-# INLINE-- Performs replacement on invalid scalar values.scanl #-}
--
-- | /O(n)/ 'scanl1' is a variant of 'scanl' that has no starting-- > scanl f z [x1, x2, ...] == [z, z `f` x1, (z `f` x1) `f` x2, ...]
---- value argument.  Subject to fusion.  Performs replacement on
-- Note that-- invalid scalar values.
--
-- > last (scanl f z xs) == foldl f z xs.-- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]
scanlscanl1::::(Char(Char->->CharChar->->CharChar))->->CharText->->TextText-> Text
scanlscanl1ffzt0 = unstreamcase unconsS.scanlt0 of g z (stream t))
    where g a b =Nothing (f->aempty)
{-# INLINE scanlJust#-} (t,ts) -> scanl f t ts
{-# INLINE scanl1 #-}
-- | /O(n)/ 'scanl1' is a variant of 'scanl' that has no starting
-- value argument.  Subject to fusion.  Performs replacement on-- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs
-- invalid scalar values.-- replacement on invalid scalar values.
--
-- > scanl1 f [x1, x2, ...] == [x1, x1 `f` x2, ...]-- > scanr f v == reverse . scanl (flip f) v . reverse
scanl1scanr ::::((CharChar->->Char->->Char))->->Char->->Text-> Text
scanl1scanr ffvt0= =reverse uncons. scanlgofv . reverse
    where g a b Nothing= safe (->f bemptya)
                Just (t,ts) -> scanl f t ts
{-# INLINE-- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting #-}
-- value argument.  Performs replacement on invalid scalar values.
scanr1-- | /O(n)/ 'scanr' is the right-to-left dual of 'scanl'.  Performs:: (Char -> Char -> Char) -> Text -> Text
scanr1-- replacement on invalid scalar values.f t | null t    = empty
--         | otherwise = scanr f (last t) (init t)
-- > scanr f v == reverse . scanl (flip f) v . reverse
scanr-- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies a:: (Char -> Char -> Char) -> Char -> Text -> Text
scanr-- function to each element of a 'Text', passing an accumulating v = reverse . scanl g v . reverse
-- parameter from left to right, and returns a final 'Text'.  Performswhere g a b = safe (f b a)
-- replacement on invalid scalar values.
mapAccumL-- | /O(n)/ 'scanr1' is a variant of 'scanr' that has no starting:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
mapAccumL-- value argument.  Performs replacement on invalid scalar values.f = go
scanr1where:: (Char -> Char -> Char) -> Text -> Text
scanr1go f tChunk nullc tcs)  = empty= (z'', Chunk c' cs')
        where otherwise(z',  c')= scanr= T.mapAccumL (last t)z(initc    t)
              (z'', cs') = go z' cs
-- | /O(n)/ Like a combination of 'map' and 'foldl''. Applies ago z Empty           = (z, Empty)
{-# INLINE-- function to each element of a 'Text', passing an accumulatingmapAccumL #-}
-- parameter from left to right, and returns a final 'Text'.  Performs
-- replacement on invalid scalar values.-- | The 'mapAccumR' function behaves like a combination of 'map' and
mapAccumL-- a strict 'foldr'; it applies a function to each element of a:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
mapAccumL-- 'Text', passing an accumulating parameter from right to left, and = go
-- returning a final value of this accumulator together with the newwhere
-- 'Text'.  Performs replacement on invalid scalar values. z (Chunk c cs)    = (z'', Chunk c' cs')
mapAccumRwhere:: ((z'->, Char) ->= T.mapAccumL(a,Char)) ->faz-> Text -> (a, Text)
 mapAccumR f = (goz'', cs') = go z' cs
  where z Empty           = (z, Empty)
{-# INLINEgo z (Chunkc cs)#-}= (z'', Chunk c' cs')
        where (z'', c') = T.mapAccumR f z' c
-- | The 'mapAccumR' function behaves like a combination of 'map' and(z', cs') = go z cs
-- a strict 'foldr'; it applies a function to each element of ago z Empty          = (z, Empty)
{-# INLINE-- 'Text', passing an accumulating parameter from right to left, andmapAccumR #-}
-- returning a final value of this accumulator together with the new
-- 'Text'.  Performs replacement on invalid scalar values.-- | /O(n*m)/ 'replicate' @n@ @t@ is a 'Text' consisting of the input
mapAccumR-- @t@ repeated @n@ times.:: (a -> Char -> (a,Char)) -> a -> Text -> (a, Text)
mapAccumR f::=Int64   -> Text -> Text
replicatewhere   n t
    go| null (Chunkt || c cs)0 ==emptyz'', Chunk c' cs')
    | isSingletonwhere (z'', c')==replicateChar fnz'(head   t)
             | otherwisez', cs')==concat z cs(rep 0)
    gowhere Emptyrep !i | i >= = (z,=Empty[]  )
{-# INLINE mapAccumR| otherwise#-}     = t : rep (i+1)
{-# INLINE [1] replicate #-}
-- | /O(n*m)/ 'replicate' @n@ @t@ is a 'Text' consisting of the input
-- @t@ repeated @n@ times.-- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
replicate-- value of every element. Subject to fusion.:: Int64 -> Text -> Text
replicatereplicateChar t :: Int64 -> Char -> Text
replicateChar null t ||n n <== unstream = empty(S.replicateCharI n (safe c))
{-# INLINE isSingletonreplicateChar    = replicateChar#-}           n (head t)
    | otherwise        = concat (rep 0)
{-# RULESwhere rep !i | i >= n    = []
     "LAZY TEXT replicate/singleton -> replicateChar" otherwise = t : rep (i+1)     [~1] forall n c.
{-# INLINEreplicate[1]nreplicate(singleton#-}c) = replicateChar n c
  #-}
-- | /O(n)/ 'replicateChar' @n@ @c@ is a 'Text' of length @n@ with @c@ the
-- value of every element. Subject to fusion.-- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'
replicateChar-- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a:: Int64 -> Char -> Text
replicateChar-- 'Text' from a seed value. The function takes the element and c = unstream (S.replicateCharI n (safe c))
{-# INLINE-- returns 'Nothing' if it is done producing the 'Text', otherwise #-}
-- 'Just' @(a,b)@.  In this case, @a@ is the next 'Char' in the
{-# RULES-- string, and @b@ is the seed value for further production.  Performs
"LAZY TEXT replicate/singleton -> replicateChar"-- replacement on invalid scalar values.         [~1] forall n c.
unfoldr:: (a n->(singletonMaybe (Char)a=)replicateChar-> a -> Text n c
unfoldr#-}   f s = unstream (S.unfoldr (firstf safe . f) s)
{-# INLINE unfoldr #-}

-- | /O(n)/, where @n@ is the length of the result. The 'unfoldr'-- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed
-- function is analogous to the List 'L.unfoldr'. 'unfoldr' builds a
-- 'Text' from a seed value. The function takes the element and-- first argument to 'unfoldrN'. This function is more efficient than
-- 'unfoldr' when the maximum length of the result is known and-- returns 'Nothing' if it is done producing the 'Text', otherwise
-- correct, otherwise its performance is similar to 'unfoldr'.-- 'Just' @(a,b)@.  In this case, @a@ is the next 'Char' in the
-- Performs replacement on invalid scalar values.-- string, and @b@ is the seed value for further production.  Performs
unfoldrN-- replacement on invalid scalar values.:: Int64 -> (a -> Maybe (Char,a)) -> a -> Text
unfoldrunfoldrN::n (as->= MaybeunstreamChar(S.unfoldrN,a)) -> a ->n (Textfirstf safe . f) s)
unfoldr{-# INLINE sunfoldrN= unstream#-}(S.unfoldr (firstf safe . f) s)
{-# INLINE unfoldr #-}
-- | /O(n)/ 'take' @n@, applied to a 'Text', returns the prefix of the
-- | /O(n)/ Like 'unfoldr', 'unfoldrN' builds a 'Text' from a seed-- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than
-- the length of the Text. Subject to fusion.-- value. However, the length of the result should be limited by the
take-- first argument to 'unfoldrN'. This function is more efficient than:: Int64 -> Text -> Text
take-- 'unfoldr' when the maximum length of the result is known andi _ | i <= 0 = Empty
take-- correct, otherwise its performance is similar to 'unfoldr'.i t0         = take' i t0
-- Performs replacement on invalid scalar values.where take' 0 _            = Empty
unfoldrNtake':: Int64_ Empty-> (a -> Maybe= EmptyChar,a)) -> a -> Text
unfoldrNtake' f sn=(unstreamChunk t tsS.unfoldrN)          n (firstf safe . f) s)
{-# INLINE unfoldrN| n < len#-} = Chunk (T.take (fromIntegral n) t) Empty
            | otherwise = Chunk t (take' (n - len) ts)
-- | /O(n)/ 'take' @n@, applied to a 'Text', returns the prefix of thewhere len = fromIntegral (T.length t)
{-# INLINE-- 'Text' of length @n@, or the 'Text' itself if @n@ is greater than[1] take #-}
-- the length of the Text. Subject to fusion.
take{-# RULES:: Int64 -> Text -> Text
take"LAZY TEXT take -> fused" _ | i <= 0 = Empty [~1] forall n t.
taketake t0n t = unstream= take'(S.take t0  n (stream t))
"LAZY TEXT take -> unfused"where take' 0 _           [=]Emptyforall n t.
                             unstream(_S.taken (stream= Emptyt)) = take n t
                           #-}   take' n (Chunk t ts)
                                     | n < len   = Chunk (T.take (fromIntegral n) t) Empty
                         -- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after otherwise = Chunk t (take' (n - len) ts)
                         -- taking @n@ characters from the end of @t@.where len = fromIntegral (T.length t)
{-# INLINE--         [1] take #-}
-- Examples:
{-# RULES--
"LAZY TEXT take -> fused"-- > takeEnd 3 "foobar" == "bar"[~1] forall n t.
takeEnd:: tInt64= unstream-> Text(S.take-> Textn (stream t))
"LAZY TEXT take -> unfused"takeEnd n t0                [1] forall n t.
    unstream| n <= 0 (S.take= empty (stream t)) = take n t
  #-}| otherwise = takeChunk n empty . L.reverse . toChunks $ t0
  where takeChunk _ acc [] = acc
        takeChunk i acc (t:ts)
-- | /O(n)/ 'takeEnd' @n@ @t@ returns the suffix remaining after| i <= l    = chunk (T.takeEnd (fromIntegral i) t) acc
-- taking @n@ characters from the end of @t@.| otherwise = takeChunk (i-l) (Chunk t acc) ts
--        where l = fromIntegral (T.length t)
-- Examples:
---- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of the
-- > takeEnd 3 "foobar" == "bar"-- 'Text' after the first @n@ characters, or the empty 'Text' if @n@
takeEnd-- is greater than the length of the 'Text'. Subject to fusion.:: Int64 -> Text -> Text
takeEnddrop :: nInt64  -> Text -> Text
drop|int0 0    = empty
    | otherwisei <= 0    = takeChunkt0        n empty . L.reverse . toChunks $ t0
  where| otherwise= _drop' []t0= acc
  where takeChunkdrop' 0 tsi acc (t:ts) ts
        drop' i <=_ Empty    = chunk=(T.takeEndEmpty     (fromIntegral i) t) acc
        drop' otherwisen (Chunk=ttakeChunkts)      (i-l) (Chunk t acc) ts
          where| n l =len= Chunk ((T.dropT.length(fromIntegral)         n) t) ts
            | otherwise = drop' (n - len) ts
-- | /O(n)/ 'drop' @n@, applied to a 'Text', returns the suffix of thewhere len   = fromIntegral (T.length t)
{-# INLINE-- 'Text' after the first @n@ characters, or the empty 'Text' if @n@[1] drop #-}
-- is greater than the length of the 'Text'. Subject to fusion.
drop{-# RULES:: Int64 -> Text -> Text
drop"LAZY TEXT drop -> fused" t0                 [~1] forall n t.
    |drop <=n 0 = unstream= t0    (S.drop n (stream t))
"LAZY TEXT drop -> unfused" otherwise = drop' i t0[1] forall n t.
  whereunstream(0S.drop   n (stream= tst)) = drop n t
  #-}   drop' _ Empty        = Empty
        drop' n (Chunk t ts)
-- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after n < len   = Chunk (T.drop (fromIntegral n) t) ts
-- dropping @n@ characters from the end of @t@. otherwise = drop' (n - len) ts
--          where len   = fromIntegral (T.length t)
{-# INLINE-- Examples:[1] drop #-}
--
{-# RULES-- > dropEnd 3 "foobar" == "foo"
"LAZY TEXT drop -> fused"dropEnd :: Int64 -> Text ->[~1Text] forall n t.
dropEndnnt0 = unstream (S.drop n (stream t))
"LAZY TEXT drop -> unfused"| n <= 0    = t0        [1] forall n t.
    unstream| otherwiseS.drop= dropChunk (streamn .t)L.reverse) = drop n ttoChunks $ t0
  #-}where dropChunk _ [] = empty
        dropChunk m (t:ts)
          | m >= l    = dropChunk (m-l) ts
-- | /O(n)/ 'dropEnd' @n@ @t@ returns the prefix remaining after| otherwise = fromChunks . L.reverse $
-- dropping @n@ characters from the end of @t@.T.dropEnd (fromIntegral m) t : ts
--        where l = fromIntegral (T.length t)
-- Examples:
---- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'
-- > dropEnd 3 "foobar" == "foo"-- values dropped, or the empty 'Text' if @n@ is greater than the
dropEnd-- number of 'Word16' values present.:: Int64 -> Text -> Text
dropEnddropWords t0 Int64 -> Text -> Text
dropWords n <=i0t0  = t0
    | otherwisei <= 0    = dropChunkt0        n . L.reverse . toChunks $ t0
  where| otherwise= _drop'] =iemptyt0
  where dropChunkdrop' 0 tsm (t:ts)   = ts
        drop' m >=_ Empty    = dropChunk= Emptym-l) ts
        drop' otherwisen (Chunk=(fromChunksT.Text arr .offlen) ts)$
            | n < len'  T.dropEnd= chunk (textfromIntegralarr (off+n') tlen ts-n')) ts
          where| otherwise = fromIntegral= drop' ((T.length- len') tts)
            where len'  = fromIntegral len
-- | /O(n)/ 'dropWords' @n@ returns the suffix with @n@ 'Word16'n'    = fromIntegral n
-- values dropped, or the empty 'Text' if @n@ is greater than the
-- number of 'Word16' values present.-- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
dropWords-- returns the longest prefix (possibly empty) of elements that:: Int64 -> Text -> Text
dropWords-- satisfy @p@.  Subject to fusion. t0
takeWhile i <=:: (Char= t0-> Bool) -> Text -> Text
takeWhile otherwisep t0 ==takeWhile' i t0t0
  where drop'takeWhile' ts Empty     = ts= Empty
        drop'takeWhile' Empty(Chunk t ts=)Empty=
        drop'casenT.findIndexChunk (T.Text(notarr. poff) t lenof ) ts)
            |Just <nlen'| n >=0chunk->textChunk(T.takeoff+n'n)t(lenEmpty-n')) ts
            | otherwise| otherwise= drop'->nEmpty len') ts
            whereNothing  = fromIntegral-> Chunklent (takeWhile' ts)
{-# INLINE [1] takeWhile    =#-} n

{-# RULES-- | /O(n)/ 'takeWhile', applied to a predicate @p@ and a 'Text',
"LAZY TEXT takeWhile -> fused"-- returns the longest prefix (possibly empty) of elements that[~1] forall p t.
-- satisfy @p@.  Subject to fusion.takeWhile p t = unstream (S.takeWhile p (stream t))
takeWhile"LAZY TEXT takeWhile -> unfused":: (Char -> Bool) -> Text[1]->forall p t.
takeWhileunstream t0(S.takeWhile= takeWhile'p t0(stream t)) = takeWhile p t
  where#-}   takeWhile' Empty        = Empty
        takeWhile' (Chunk t ts) =
-- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after T.findIndex (not . p) t of
-- 'takeWhile' @p@ @t@.  Subject to fusion. n | n > 0     -> Chunk (T.take n t) Empty
dropWhile :: (Char |->otherwiseBool) -> ->Text-> Text
dropWhile p Nothingt0 = dropWhile' t0 -> Chunk t (takeWhile' ts)
{-# INLINEwhere dropWhile'[1] takeWhileEmpty #-}    = Empty
        dropWhile' (Chunk t ts) =
{-# RULES case T.findIndex (not . p) t of
"LAZY TEXT takeWhile -> fused"Just n  -> Chunk (T.drop[~1] foralln t) ts t.
    takeWhileNothing t = unstream-> dropWhile'S.takeWhilets      p (stream t))
"LAZY TEXT takeWhile -> unfused"{-# INLINE [1] dropWhile #-}     [1] forall p t.
    unstream (S.takeWhile p (stream t)) = takeWhile p t
{-# RULES#-}
"LAZY TEXT dropWhile -> fused" [~1] forall p t.
    dropWhile p t = unstream (S.dropWhile p (stream t))
"LAZY TEXT dropWhile -> unfused"-- | /O(n)/ 'dropWhile' @p@ @t@ returns the suffix remaining after[1] forall p t.
-- 'takeWhile' @p@ @t@.  Subject to fusion.unstream (S.dropWhile p (stream t)) = dropWhile p t
dropWhile#-}     :: (Char -> Bool) -> Text -> Text
dropWhile-- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining after t0 = dropWhile' t0
-- dropping characters that fail the predicate @p@ from the end ofwhere dropWhile' Empty        = Empty
                                                                -- @t@. dropWhile' (Chunk t ts) =
                                                                -- Examples: T.findIndex (not . p) t of
                                                                --          Just n  -> Chunk (T.drop n t) ts
                                                                -- > dropWhileEnd (=='.') "foo..." == "foo" -> dropWhile' ts
{-# INLINEdropWhileEnd[1]::dropWhile(Char -> #-}Bool) -> Text -> Text
dropWhileEnd p = go
{-# RULESwhere go Empty = Empty
"LAZY TEXT dropWhile -> fused"go (Chunk t Empty) = if[~T.null1] forallt'  p t.
    dropWhile p t = unstream (thenS.dropWhileEmpty   p (stream t))
"LAZY TEXT dropWhile -> unfused"else[1Chunk] forallt' Empty t.
    unstreamwhereS.dropWhilet' = T.dropWhileEnd (stream t)) = dropWhile p t
  #-}   go (Chunk t ts) = case go ts of
                            Empty -> go (Chunk t Empty)
-- | /O(n)/ 'dropWhileEnd' @p@ @t@ returns the prefix remaining afterts' -> Chunk t ts'
{-# INLINE-- dropping characters that fail the predicate @p@ from the end ofdropWhileEnd #-}
-- @t@.
-- Examples:-- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
---- dropping characters that fail the predicate @p@ from both the
-- > dropWhileEnd (=='.') "foo..." == "foo"-- beginning and end of @t@.  Subject to fusion.
dropWhileEnddropAround ::::(CharChar->->Bool) )->->Text->->Text
dropWhileEnddropAround p p =dropWhile      p . dropWhileEnd p
{-# INLINEwhere go Empty[1] dropAround= Empty  #-}
                go (Chunk t Empty) = if T.null t'
        -- | /O(n)/ Remove leading white space from a string.  Equivalent to:then Empty
        --                           else Chunk t' Empty
        -- > dropWhile isSpacewhere t' = T.dropWhileEnd p t
        stripStart (::ChunkTextt->)Text= case go ts of
        stripStart = dropWhile isSpace -> go (Chunk t Empty)
        {-# INLINE [1] stripStart #-} -> Chunk t ts'
{-# INLINE dropWhileEnd #-}
-- | /O(n)/ Remove trailing white space from a string.  Equivalent to:
---- | /O(n)/ 'dropAround' @p@ @t@ returns the substring remaining after
-- > dropWhileEnd isSpace-- dropping characters that fail the predicate @p@ from both the
stripEnd-- beginning and end of @t@.  Subject to fusion.:: Text -> Text
dropAroundstripEnd = ::dropWhileEndChar -> BoolisSpace) -> Text -> Text
dropAround p1= dropWhilestripEnd #-} . dropWhileEnd p
{-# INLINE [1] dropAround #-}
-- | /O(n)/ Remove leading and trailing white space from a string.
-- Equivalent to:-- | /O(n)/ Remove leading white space from a string.  Equivalent to:
--
-- > dropWhile isSpace-- > dropAround isSpace
stripStartstrip :: Text:: Text-> Text-> Text
stripStartstrip = dropAround= dropWhileisSpace
{-# INLINE [1] stripStartstrip #-}  #-}

-- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a-- | /O(n)/ Remove trailing white space from a string.  Equivalent to:
---- prefix of @t@ of length @n@, and whose second is the remainder of
-- > dropWhileEnd isSpace-- the string. It is equivalent to @('take' n t, 'drop' n t)@.
stripEndsplitAt ::::Int64 -> Text -> (Text, Text)
stripEndsplitAt ==loop isSpace
{-# INLINEwhere loop[1] stripEndEmpty    #-}= (empty, empty)
        loop n t | n <= 0 = (empty, t)
-- | /O(n)/ Remove leading and trailing white space from a string.loop n (Chunk t ts)
-- Equivalent to:| n < len   = let (t',t'') = T.splitAt (fromIntegral n) t
--                         in (Chunk t' Empty, Chunk t'' ts)
-- > dropAround isSpace| otherwise = let (ts',ts'') = loop (n - len) ts
strip :: Text -> Text      in (Chunk t ts', ts'')
strip = dropAroundwhere isSpacelen = fromIntegral (T.length t)
{-# INLINE [1] strip #-}
-- | /O(n)/ 'splitAtWord' @n t@ returns a strict pair whose first
-- element is a prefix of @t@ whose chunks contain @n@ 'Word16'-- | /O(n)/ 'splitAt' @n t@ returns a pair whose first element is a
-- values, and whose second is the remainder of the string.-- prefix of @t@ of length @n@, and whose second is the remainder of
splitAtWord-- the string. It is equivalent to @('take' n t, 'drop' n t)@.:: Int64 -> Text -> PairS Text Text
splitAtsplitAtWord:: Int64_ Empty-> Text= empty-> (:*:Textempty, Text)
splitAtsplitAtWord= loopx (Chunk c@(T.Text arr off len) cs)
  where| y loop>= len Empty= let h :*:= (empty= splitAtWord, empty)  (x-fromIntegral len) cs
        loop n t |in <=Chunk = (emptyh :*:, t)
    | otherwise n (Chunk= chunk ts(text)   arr off y) empty :*:
             | n <chunk  (=textarrt',t'')y= T.splitAt(len-y)) csfromIntegral n) t
       where y = fromIntegral inx  (Chunk t' Empty, Chunk t'' ts)
             | otherwise = let (ts',ts'') = loop (n - len) ts
-- | /O(n+m)/ Find the first instance of @needle@ (which must bein (Chunk t ts', ts'')
-- non-'null') in @haystack@.  The first element of the returned tuplewhere len = fromIntegral (T.length t)
-- is the prefix of @haystack@ before @needle@ is matched.  The second
-- is the remainder of @haystack@, starting with the match.-- | /O(n)/ 'splitAtWord' @n t@ returns a strict pair whose first
---- element is a prefix of @t@ whose chunks contain @n@ 'Word16'
-- Examples:-- values, and whose second is the remainder of the string.
splitAtWord--          :: Int64 -> Text -> PairS Text Text
splitAtWord-- > breakOn "::" "a::b::c" ==> ("a", "::b::c") Empty = empty :*: empty
splitAtWord-- > breakOn "/" "foobar"   ==> ("foobar", "") (Chunk c@(T.Text arr off len) cs)
--  | y >= len  = let h :*: t = splitAtWord (x-fromIntegral len) cs
-- Laws:          in  Chunk c h :*: t
--  | otherwise = chunk (text arr off y) empty :*:
-- > append prefix match == haystack (text arr (off+y) (len-y)) cs
-- >   where (prefix, match) = breakOn needle haystackwhere y = fromIntegral x
--
-- | /O(n+m)/ Find the first instance of @needle@ (which must be-- If you need to break a string by a substring repeatedly (e.g. you
-- want to break on every instance of a substring), use 'breakOnAll'-- non-'null') in @haystack@.  The first element of the returned tuple
-- instead, as it has lower startup overhead.-- is the prefix of @haystack@ before @needle@ is matched.  The second
---- is the remainder of @haystack@, starting with the match.
---- This function is strict in its first argument, and lazy in its
-- second.-- Examples:
--
-- > breakOn "::" "a::b::c" ==> ("a", "::b::c")-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- > breakOn "/" "foobar"   ==> ("foobar", "")
--breakOn :: Text -> Text -> (Text, Text)
breakOn-- Laws:pat src
--  | null pat  = emptyError "breakOn"
-- > append prefix match == haystack| otherwise = case indices pat src of
-- >   where (prefix, match) = breakOn needle haystack[]    -> (src, empty)
--                  (x:_) -> let h :*: t = splitAtWord x src
-- If you need to break a string by a substring repeatedly (e.g. youin  (h, t)
-- want to break on every instance of a substring), use 'breakOnAll'
-- instead, as it has lower startup overhead.-- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
--
-- This function is strict in its first argument, and lazy in its-- The first element of the returned tuple is the prefix of @haystack@
-- second.-- up to and including the last match of @needle@.  The second is the
---- remainder of @haystack@, following the match.
---- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
breakOnbreakOnEnd:: Text:: Text-> Text-> Text-> (->Text(Text, Text, Text)  )
breakOnbreakOnEndpatsrc = let (a,b) = breakOn (reverse pat) (reverse src)
    | null pat  = emptyErrorin  (reverseb, reverse a)
{-# INLINE otherwisebreakOnEnd= case#-} pat src of
                    []    -> (src, empty)
-- | /O(n+m)/ Find all non-overlapping instances of @needle@ inx:_) -> let h :*: t = splitAtWord x src
                                          -- @haystack@.  Each element of the returned list consists of a pair:in  (h, t)
--
-- * The entire string prior to the /k/th match (i.e. the prefix)-- | /O(n+m)/ Similar to 'breakOn', but searches from the end of the string.
--
-- * The /k/th match, followed by the remainder of the string-- The first element of the returned tuple is the prefix of @haystack@
---- up to and including the last match of @needle@.  The second is the
-- Examples:-- remainder of @haystack@, following the match.
--
-- > breakOnAll "::" ""-- > breakOnEnd "::" "a::b::c" ==> ("a::b::", "c")
breakOnEnd-- > ==> []:: Text -> Text -> (Text, Text)
breakOnEnd-- > breakOnAll "/" "a/b/c/" src = let (a,b) = breakOn (reverse pat) (reverse src)
              -- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]in  (reverse b, reverse a)
{-# INLINE--         breakOnEnd #-}
-- This function is strict in its first argument, and lazy in its
-- second.-- | /O(n+m)/ Find all non-overlapping instances of @needle@ in
---- @haystack@.  Each element of the returned list consists of a pair:
---- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- * The entire string prior to the /k/th match (i.e. the prefix)
--
-- The @needle@ parameter may not be empty.-- * The /k/th match, followed by the remainder of the string
--breakOnAll :: Text              -- ^ @needle@ to search for
-- Examples:-> Text              -- ^ @haystack@ in which to search
--         -> [(Text, Text)]
breakOnAll-- > breakOnAll "::" ""pat src
-- > ==> []| null pat  = emptyError "breakOnAll"
-- > breakOnAll "/" "a/b/c/"| otherwise = go 0 empty src (indices pat src)
-- > ==> [("a", "/b/c/"), ("a/b", "/c/"), ("a/b/c", "/")]where
--  go !n p s (x:xs) = let h :*: t = splitAtWord (x-n) s
-- This function is strict in its first argument, and lazy in itsh'      = append p h
-- second.             in (h',t) : go x h' t xs
--  go _  _ _ _      = []
-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- | /O(n)/ 'break' is like 'span', but the prefix returned is over
---- elements that fail the predicate @p@.
break-- The @needle@ parameter may not be empty.:: (Char -> Bool) -> Text -> (Text, Text)
breakOnAllbreak p t0 ::= break'  t0          -- ^ @needle@ to search for
  where break'-> TextEmpty          = (-- ^ @haystack@ in which to searchempty, empty)
        break'-> [(Text@(Chunk, Textt )ts]) =
breakOnAllcase srcT.findIndex p t of
    | null patNothing= emptyError-> let(ts', ts'') = break' ts
    | otherwise = go 0 emptyin(Chunkindicest ts', ts'')
  where     Just n | n == 0    -> (Empty, c)
    go !n p s (x:xs) =otherwise h :*:->tlet= splitAtWord(a,b) = T.splitAtx-n) sn t
                               h'     in= append(Chunk p hEmpty, Chunk b ts)
                              in (h',t) : go x h' t xs
-- | /O(n)/ 'span', applied to a predicate @p@ and text @t@, returns _  _ _ _      = []
-- a pair whose first element is the longest prefix (possibly empty)
-- of @t@ of elements that satisfy @p@, and whose second is the-- | /O(n)/ 'break' is like 'span', but the prefix returned is over
-- remainder of the list.-- elements that fail the predicate @p@.
breakspan ::::((CharChar->->Bool))->->Text->->((TextText,,Text))
breakspan pp=t0break= break'(not t0. p)
{-# INLINEwhere break'spanEmpty#-}           = (empty, empty)
                break' c@(Chunk t ts) =
        -- | The 'group' function takes a 'Text' and returns a list of 'Text's T.findIndex p t of
        -- such that the concatenation of the result is equal to the argument.      -> let (ts', ts'') = break' ts
                                                           -- Moreover, each sublist in the result contains only equal elements.in (Chunk t ts', ts'')
        -- For example, n | n == 0    -> (Empty, c)
        --                 | otherwise -> let (a,b) = T.splitAt n t
        -- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]in (Chunk a Empty, Chunk b ts)
--
-- | /O(n)/ 'span', applied to a predicate @p@ and text @t@, returns
-- supply their own equality test.-- a pair whose first element is the longest prefix (possibly empty)
group-- of @t@ of elements that satisfy @p@, and whose second is the:: Text -> [Text]
group-- remainder of the list.=  groupBy (==)
span{-# INLINE:: (Chargroup-> Bool#-} ) -> Text -> (Text, Text)
span p = break (not . p)
{-# INLINE-- | The 'groupBy' function is the non-overloaded version of 'group'. #-}
groupBy :: (Char -> Char -> Bool) -> Text -> [Text]
groupBy-- | The 'group' function takes a 'Text' and returns a list of 'Text's_  Empty        = []
groupBy-- such that the concatenation of the result is equal to the argument.eq (Chunk t ts) = cons x ys : groupBy eq zs
-- Moreover, each sublist in the result contains only equal elements.where (ys,zs) = span (eq x) xs
-- For example,                 x  = T.unsafeHead t
--                              xs = chunk (T.unsafeTail t) ts
-- > group "Mississippi" = ["M","i","ss","i","ss","i","pp","i"]
---- | /O(n)/ Return all initial segments of the given 'Text',
-- shortest first.-- It is a special case of 'groupBy', which allows the programmer to
inits-- supply their own equality test.:: Text -> [Text]
group ::= (TextEmpty->:)[Text. inits']
groupwhere= inits'Empty==)       = []
{-# INLINEinits'(Chunk#-}  t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
                           ++ L.map (Chunk t) (inits' ts)
-- | The 'groupBy' function is the non-overloaded version of 'group'.
groupBy-- | /O(n)/ Return all final segments of the given 'Text', longest:: (Char -> Char -> Bool) -> Text -> [Text]
groupBy-- first.  Empty        = []
groupBytails ::eqTextChunk-> [tText) = cons x ys : groupBy eq zs
tails Empty         = Emptywhere: [](ys,zs) = span (eq x) xs
 tails ts@(Chunk t ts')          x  = T.unsafeHead t
   | T.length t == 1 = ts : tailsxsts'= chunk (T.unsafeTail t) ts
  | otherwise       = ts : tails (Chunk (T.unsafeTail t) ts')
-- | /O(n)/ Return all initial segments of the given 'Text',
-- $split-- shortest first.
inits--    :: Text -> [Text]
inits-- Splitting functions in this library do not perform character-wise= (Empty :) . inits'
-- copies to create substrings; they just construct new 'Text's thatwhere inits' Empty        = []
                                                                  -- are slices of the original. (Chunk t ts) = L.map (\t' -> Chunk t' Empty) (L.tail (T.inits t))
                                                                                             ++ L.map (Chunk t) (inits' ts)
-- | /O(m+n)/ Break a 'Text' into pieces separated by the first 'Text'
-- argument (which cannot be an empty string), consuming the-- | /O(n)/ Return all final segments of the given 'Text', longest
-- first.-- delimiter. An empty delimiter is invalid, and will cause an error
tails-- to be raised.:: Text -> [Text]
tails--    Empty         = Empty : []
tails-- Examples:@(Chunk t ts')
--| T.length t == 1 = ts : tails ts'
-- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"] otherwise       = ts : tails (Chunk (T.unsafeTail t) ts')
-- > splitOn "aaa"  "aaaXaaaXaaaXaaa"  == ["","X","X","X",""]
-- $split-- > splitOn "x"    "x"                == ["",""]
--
-- and-- Splitting functions in this library do not perform character-wise
---- copies to create substrings; they just construct new 'Text's that
-- are slices of the original.-- > intercalate s . splitOn s         == id
-- > splitOn (singleton c)             == split (==c)
---- | /O(m+n)/ Break a 'Text' into pieces separated by the first 'Text'
-- argument (which cannot be an empty string), consuming the
---- delimiter. An empty delimiter is invalid, and will cause an error
-- to be raised.-- This function is strict in its first argument, and lazy in its
---- second.
---- Examples:
---- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- > splitOn "\r\n" "a\r\nb\r\nd\r\ne" == ["a","b","d","e"]
splitOn-- > splitOn "aaa"  "aaaXaaaXaaaXaaa"  == ["","X","X","X",""]:: Text
-- > splitOn "x"    "x"                == ["",""]-- ^ String to split on. If this string is empty, an error
--      -- will occur.
-- and  -> Text
--      -- ^ Input text.
-- > intercalate s . splitOn s         == id-> [Text]
splitOn-- > splitOn (singleton c)             == split (==c)pat src
--  | null pat        = emptyError "splitOn"
-- (Note: the string @s@ to split on above cannot be empty.)| isSingleton pat = split (== head pat) src
--  | otherwise       = go 0 (indices pat src) src
-- This function is strict in its first argument, and lazy in itswhere
-- second.go  _ []     cs = [cs]
--  go !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
-- In (unlikely) bad cases, this function's time complexity degradesin  h : go (x+l) xs (dropWords l t)
-- towards /O(n*m)/.l = foldlChunks (\a (T.Text _ _ b) -> a + fromIntegral b) 0 pat
splitOn{-# INLINE:: Text[1] splitOn #-}
        -- ^ String to split on. If this string is empty, an error
{-# RULES-- will occur.
"LAZY TEXT splitOn/singleton -> split/=="-> Text                           [~1] forall c t.
    splitOn-- ^ Input text.(singleton c) t = split (==c) t
  #-}   -> [Text]
splitOn pat src
-- | /O(n)/ Splits a 'Text' into components delimited by separators, null pat        = emptyError "splitOn"
-- where the predicate returns True for a separator element.  The isSingleton pat = split (== head pat) src
-- resulting components do not contain the separators.  Two adjacent otherwise       = go 0 (indices pat src) src
-- separators result in an empty component in the output.  eg.where
--  go  _ []     cs = [cs]
-- > split (=='a') "aabbaca" == ["","","bb","c",""] !i (x:xs) cs = let h :*: t = splitAtWord (x-i) cs
                                             -- > split (=='a') []        == [""]in  h : go (x+l) xs (dropWords l t)
split =::foldlChunks(Char -> Bool\a (->T.TextText _->_[bText) ->] a + fromIntegral b) 0 pat
{-# INLINEsplit _ Empty[1]=splitOn[Empty]#-}
split p (Chunk t0 ts0) = comb [] (T.split p t0) ts0
{-# RULESwhere comb acc (s:[]) Empty        = revChunks (s:acc) : []
"LAZY TEXT splitOn/singleton -> split/=="comb acc (s:[]) (Chunk t ts) = comb[~1]:forallacc) (T.split t.   p t) ts
    splitOncomb(singletonacc (s:ss)c)tst = split (=== crevChunks) t      (s:acc) : comb [] ss ts
  #-}   comb _   []     _            = impossibleError "split"
{-# INLINE split #-}

-- | /O(n)/ Splits a 'Text' into components delimited by separators,
-- where the predicate returns True for a separator element.  The
-- length of the input. Examples:-- resulting components do not contain the separators.  Two adjacent
---- separators result in an empty component in the output.  eg.
---- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]
-- > split (=='a') "aabbaca" == ["","","bb","c",""]-- > chunksOf 4 "haskell.org" == ["hask","ell.","org"]
chunksOf-- > split (=='a') []        == [""]:: Int64 -> Text -> [Text]
splitchunksOf:: (Char= go-> Bool) -> Text -> [Text]
splitwhere Empty = [Empty]
splitgopt(Chunk= caset0splitAt) =kcombt of[] (T.split p t0) ts0
  where comb acc(a,b(s:[]null) Emptya    -> [] = revChunks (s:acc) : []
        comb acc (s:[]otherwise) (Chunk t->tsa):=gob  (s:acc) (T.split p t) ts
{-# INLINEchunksOf (s:ss#-}) ts           = revChunks (s:acc) : comb [] ss ts
        comb _   []     _            = impossibleError "split"
{-# INLINE-- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at #-}
-- newline 'Char's. The resulting strings do not contain newlines.
lines-- | /O(n)/ Splits a 'Text' into components of length @k@.  The last:: Text -> [Text]
lines-- element may be shorter than the other chunks, depending on theEmpty = []
lines-- length of the input. Examples:t = let (l,t') = break ((==) '\n') t
--        in l : if null t' then []
-- > chunksOf 3 "foobarbaz"   == ["foo","bar","baz"]else lines (tail t')
-- > chunksOf 4 "haskell.org" == ["hask","ell.","org"]
chunksOf-- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's:: Int64 -> Text -> [Text]
chunksOf-- representing white space. = go
wordswhere:: Text -> [Text]
words=tL.filter= case splitAt(not . knull of) . split isSpace
{-# INLINE wordsa,b)#-} null a    -> []
                   | otherwise -> a : go b
{-# INLINE-- | /O(n)/ Joins lines, after appending a terminating newline to #-}
-- each.
unlines-- | /O(n)/ Breaks a 'Text' up into a list of 'Text's at:: [Text] -> Text
unlines-- newline 'Char's. The resulting strings do not contain newlines.= concat . L.map (`snoc` '\n')
lines{-# INLINE:: Textunlines-> [Text#-}]
lines Empty = []
lines-- | /O(n)/ Joins words using single space characters. = let (l,t') = break ((==) '\n') t
                                               unwords ::in[Text :]if->nullTextt' then []
                                               unwords = intercalateelse lines(singletontail' ')
{-# INLINE unwords #-}
-- | /O(n)/ Breaks a 'Text' up into a list of words, delimited by 'Char's
-- representing white space.-- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns
words-- 'True' iff the first is a prefix of the second.  Subject to fusion.:: Text -> [Text]
wordsisPrefixOf= L.filter:: Textnot-> .Text->) .Bool isSpace
{-# INLINE words #-}_  = True
isPrefixOf _ Empty  = False
isPrefixOf-- | /O(n)/ Joins lines, after appending a terminating newline to(Chunk x xs) (Chunk y ys)
-- each.| lx == ly  = x == y  && isPrefixOf xs ys
unlines| lx::< [Textly  ] ->x ==yh && isPrefixOf xs (Chunk yt ys)
unlines| otherwise= concat=.xh== y(`&&snocisPrefixOf` '\n')  (Chunk xt xs) ys
{-# INLINEwhere (xhunlines,xt) = T.splitAt#-}      ly x
        (yh,yt) = T.splitAt lx y
-- | /O(n)/ Joins words using single space characters.lx = T.length x
unwords ::   [TextT.length] -> Texty
unwords{-# INLINE= intercalate[1] isPrefixOfsingleton#-}    ' ')
{-# INLINE unwords #-}
{-# RULES
"LAZY TEXT isPrefixOf -> fused"-- | /O(n)/ The 'isPrefixOf' function takes two 'Text's and returns[~1] forall s t.
-- 'True' iff the first is a prefix of the second.  Subject to fusion.isPrefixOf s t = S.isPrefixOf (stream s) (stream t)
isPrefixOf"LAZY TEXT isPrefixOf -> unfused":: Text -> Text -> Bool[1] forall s t.
isPrefixOfS.isPrefixOf _stream= Trues) (stream t) = isPrefixOf s t
isPrefixOf#-}      _ Empty  = False
isPrefixOf (Chunk x xs) (Chunk y ys)
-- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returns lx == ly  = x == y  && isPrefixOf xs ys
-- 'True' iff the first is a suffix of the second. lx <  ly  = x == yh && isPrefixOf xs (Chunk yt ys)
isSuffixOf otherwise:: Text= xh->==Text &&->isPrefixOfBool      (Chunk xt xs) ys
isSuffixOfwhere (xh,xty)==reversex `lyisPrefixOf      ` reverse y
        {-# INLINEyh,isSuffixOfyt) = T.splitAt#-}   lx y
        -- TODO: a better implementation = T.length x
                ly = T.length y
{-# INLINE-- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns[1] isPrefixOf #-}
-- 'True' iff the first is contained, wholly and intact, anywhere
{-# RULES-- within the second.
"LAZY TEXT isPrefixOf -> fused"--                              [~1] forall s t.
-- This function is strict in its first argument, and lazy in its s t = S.isPrefixOf (stream s) (stream t)
"LAZY TEXT isPrefixOf -> unfused"-- second.                        [1] forall s t.
--  S.isPrefixOf (stream s) (stream t) = isPrefixOf s t
-- In (unlikely) bad cases, this function's time complexity degrades#-}
-- towards /O(n*m)/.
isInfixOf :: Text -> Text -> Bool
isInfixOf-- | /O(n)/ The 'isSuffixOf' function takes two 'Text's and returnsneedle haystack
-- 'True' iff the first is a suffix of the second.| null needle        = True
isSuffixOf| isSingleton:: Textneedle-> Text= ->S.elem(head needle) . S.stream $ haystack
isSuffixOf| otherwise y = reverse x `notisPrefixOf. L.null` reverse. indices needle $ haystack
{-# INLINE isSuffixOf[1] isInfixOf#-}#-}
-- TODO: a better implementation
{-# RULES
"LAZY TEXT isInfixOf/singleton -> S.elem/S.stream"-- | /O(n+m)/ The 'isInfixOf' function takes two 'Text's and returns[~1] forall n h.
-- 'True' iff the first is contained, wholly and intact, anywhereisInfixOf (singleton n) h = S.elem n (S.stream h)
-- within the second.#-}
--
-- This function is strict in its first argument, and lazy in its-------------------------------------------------------------------------------
-- second.-- * View patterns
--
-- | /O(n)/ Return the suffix of the second string if its prefix-- In (unlikely) bad cases, this function's time complexity degrades
-- towards /O(n*m)/.-- matches the entire first string.
isInfixOf--        :: Text -> Text -> Bool
isInfixOf-- Examples: haystack
--  | null needle        = True
-- > stripPrefix "foo" "foobar" == Just "bar" isSingleton needle = S.elem (head needle) . S.stream $ haystack
-- > stripPrefix ""    "baz"    == Just "baz" otherwise          = not . L.null . indices needle $ haystack
{-# INLINE-- > stripPrefix "foo" "quux"   == Nothing[1] isInfixOf #-}
--
{-# RULES-- This is particularly useful with the @ViewPatterns@ extension to
"LAZY TEXT isInfixOf/singleton -> S.elem/S.stream"-- GHC, as follows:                                [~1] forall n h.
--  isInfixOf (singleton n) h = S.elem n (S.stream h)
-- > {-# LANGUAGE ViewPatterns #-}#-}
-- > import Data.Text.Lazy as T
-- >
-- > fnordLength :: Text -> Int-------------------------------------------------------------------------------
-- * View patterns-- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf
-- > fnordLength _                                 = -1
stripPrefix-- | /O(n)/ Return the suffix of the second string if its prefix:: Text -> Text -> Maybe Text
stripPrefix-- matches the entire first string.p t
--  | null p    = Just t
-- Examples:| otherwise = case commonPrefixes p t of
--                  Just (_,c,r) | null c -> Just r
-- > stripPrefix "foo" "foobar" == Just "bar"_                     -> Nothing
-- > stripPrefix ""    "baz"    == Just "baz"
-- > stripPrefix "foo" "quux"   == Nothing-- | /O(n)/ Find the longest non-empty common prefix of two strings
---- and return it, along with the suffixes of each string at which they
-- no longer match.-- This is particularly useful with the @ViewPatterns@ extension to
---- GHC, as follows:
---- If the strings do not have a common prefix or either one is empty,
-- > {-# LANGUAGE ViewPatterns #-}-- this function returns 'Nothing'.
---- > import Data.Text.Lazy as T
-- >-- Examples:
---- > fnordLength :: Text -> Int
-- > fnordLength (stripPrefix "fnord" -> Just suf) = T.length suf-- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
-- > commonPrefixes "veeble" "fetzer"  == Nothing-- > fnordLength _                                 = -1
stripPrefix-- > commonPrefixes "" "baz"           == Nothing:: Text -> Text -> Maybe Text
stripPrefixcommonPrefixes t:: Text -> Text -> Maybe (Text,Text,Text)
commonPrefixes null p   Empty= Just_ t Nothing
commonPrefixes otherwise_=Empty commonPrefixes= Nothing      p t of
commonPrefixes a0 b0Just= (Just_,c,r)go|a0b0 c]->)  Just r
  where             _                     -> Nothing
    go t0@(Chunk x xs) t1@(Chunk y ys) ps
-- | /O(n)/ Find the longest non-empty common prefix of two strings= case T.commonPrefixes x y of
-- and return it, along with the suffixes of each string at which theyJust (p,a,b)
-- no longer match.| T.null a  -> go xs (chunk b ys) (p:ps)
--            | T.null b  -> go (chunk a xs) ys (p:ps)
-- If the strings do not have a common prefix or either one is empty,| otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
-- this function returns 'Nothing'.Nothing       -> (fromChunks (L.reverse ps),t0,t1)
--  go t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)
-- Examples:
---- | /O(n)/ Return the prefix of the second string if its suffix
-- matches the entire first string.-- > commonPrefixes "foobar" "fooquux" == Just ("foo","bar","quux")
---- > commonPrefixes "veeble" "fetzer"  == Nothing
-- Examples:-- > commonPrefixes "" "baz"           == Nothing
commonPrefixes--             :: Text -> Text -> Maybe (Text,Text,Text)
commonPrefixes-- > stripSuffix "bar" "foobar" == Just "foo" _ = Nothing
commonPrefixes-- > stripSuffix ""    "baz"    == Just "baz" Empty = Nothing
commonPrefixes-- > stripSuffix "foo" "quux"   == Nothing b0   = Just (go a0 b0 [])
--where
-- This is particularly useful with the @ViewPatterns@ extension to t0@(Chunk x xs) t1@(Chunk y ys) ps
-- GHC, as follows:= case T.commonPrefixes x y of
--          Just (p,a,b)
-- > {-# LANGUAGE ViewPatterns #-} T.null a  -> go xs (chunk b ys) (p:ps)
-- > import Data.Text.Lazy as T T.null b  -> go (chunk a xs) ys (p:ps)
-- >          | otherwise -> (fromChunks (L.reverse (p:ps)),chunk a xs, chunk b ys)
-- > quuxLength :: Text -> Int       -> (fromChunks (L.reverse ps),t0,t1)
-- > quuxLength (stripSuffix "quux" -> Just pre) = T.length pre t0 t1 ps = (fromChunks (L.reverse ps),t0,t1)
-- > quuxLength _                                = -1
stripSuffix-- | /O(n)/ Return the prefix of the second string if its suffix:: Text -> Text -> Maybe Text
stripSuffix-- matches the entire first string.p t = reverse `fmap` stripPrefix (reverse p) (reverse t)
--
-- Examples:-- | /O(n)/ 'filter', applied to a predicate and a 'Text',
---- returns a 'Text' containing those characters that satisfy the
-- predicate.-- > stripSuffix "bar" "foobar" == Just "foo"
filter-- > stripSuffix ""    "baz"    == Just "baz":: (Char -> Bool) -> Text -> Text
filter-- > stripSuffix "foo" "quux"   == Nothingp t = unstream (S.filter p (stream t))
--{-# INLINE filter #-}
-- This is particularly useful with the @ViewPatterns@ extension to
-- GHC, as follows:-- | /O(n)/ The 'find' function takes a predicate and a 'Text', and
---- returns the first element in matching the predicate, or 'Nothing'
-- if there is no such element.-- > {-# LANGUAGE ViewPatterns #-}
find-- > import Data.Text.Lazy as T:: (Char -> Bool) -> Text -> Maybe Char
-- > p t = S.findBy p (stream t)
{-# INLINE-- > quuxLength :: Text -> Intfind #-}
-- > quuxLength (stripSuffix "quux" -> Just pre) = T.length pre
-- > quuxLength _                                = -1-- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
stripSuffix-- and returns the pair of 'Text's with elements which do and do not:: Text -> Text -> Maybe Text
stripSuffix-- satisfy the predicate, respectively; i.e. t = reverse `fmap` stripPrefix (reverse p) (reverse t)
--
-- > partition p t == (filter p t, filter (not . p) t)-- | /O(n)/ 'filter', applied to a predicate and a 'Text',
partition-- returns a 'Text' containing those characters that satisfy the:: (Char -> Bool) -> Text -> (Text, Text)
partition-- predicate.p t = (filter p t, filter (not . p) t)
filter{-# INLINE:: (Charpartition-> Bool#-}) -> Text -> Text
filter p t = unstream (S.filter p (stream t))
{-# INLINE-- | /O(n)/ 'Text' index (subscript) operator, starting from 0. #-}
index :: Text -> Int64 -> Char
index-- | /O(n)/ The 'find' function takes a predicate and a 'Text', andt n = S.index (stream t) n
{-# INLINE-- returns the first element in matching the predicate, or 'Nothing'index #-}
-- if there is no such element.
find-- | /O(n+m)/ The 'count' function returns the number of times the:: (Char -> Bool) -> Text -> Maybe Char
find-- query string appears in the given 'Text'. An empty query string is t = S.findBy p (stream t)
{-# INLINE-- invalid, and will cause an error to be raised. #-}
--
-- | /O(n)/ The 'partition' function takes a predicate and a 'Text',
-- towards /O(n*m)/.-- and returns the pair of 'Text's with elements which do and do not
count-- satisfy the predicate, respectively; i.e.:: Text -> Text -> Int64
--count pat src
-- > partition p t == (filter p t, filter (not . p) t)| null pat        = emptyError "count"
partition| otherwise:: (Char -> Bool= go)0->(indices ->patTextsrc,)Text)
partitionwhere gop!t =](filter= np t, filter (not . p) t)
{-# INLINEgo partition!n (_:xs) #-}= go (n+1) xs
{-# INLINE [1] count #-}
-- | /O(n)/ 'Text' index (subscript) operator, starting from 0.
index{-# RULES:: Text -> Int64 -> Char
index"LAZY TEXT count/singleton -> countChar" n = S.index (stream t) n         [~1] forall c t.
{-# INLINEcount (indexsingleton#-} c) t = countChar c t
  #-}
-- | /O(n+m)/ The 'count' function returns the number of times the
-- | /O(n)/ The 'countChar' function returns the number of times the-- query string appears in the given 'Text'. An empty query string is
-- invalid, and will cause an error to be raised.-- query element appears in the given 'Text'.  Subject to fusion.
--countChar :: Char -> Text -> Int64
countChar-- In (unlikely) bad cases, this function's time complexity degradesc t = S.countChar c (stream t)
-- towards /O(n*m)/.
count-- | /O(n)/ 'zip' takes two 'Text's and returns a list of:: Text -> Text -> Int64
count-- corresponding pairs of bytes. If one input 'Text' is short, src
-- excess elements of the longer 'Text' are discarded. This is null pat        = emptyError "count"
-- equivalent to a pair of 'unpack' operations. otherwise       = go 0 (indices pat src)
zipwhere:: Text !n->[]Text ->= n(Char,Char)]
 zip a b go= S.unstreamList!n (_:xs) = go$(nS.zipWith+1) xs   (,) (stream a) (stream b)
{-# INLINE [1] countzip #-}#-}

{-# RULES-- | /O(n)/ 'zipWith' generalises 'zip' by zipping with the function
"LAZY TEXT count/singleton -> countChar"-- given as the first argument, instead of a tupling function.[~1] forall c t.
-- Performs replacement on invalid scalar values. (singleton c) t = countChar c t
zipWith#-}   :: (Char -> Char -> Char) -> Text -> Text -> Text
zipWith f t1 t2 = unstream (S.zipWith g (stream t1) (stream t2))
    where g a b = safe (f a b)
{-# INLINE-- | /O(n)/ The 'countChar' function returns the number of times the[0] zipWith #-}
-- query element appears in the given 'Text'.  Subject to fusion.
countChar :: Char[T.Text->]Text-> Text-> Int64
countChar c tL.foldl'= S.countChar(flip chunk (stream) Empty)

emptyError-- | /O(n)/ 'zip' takes two 'Text's and returns a list of:: String -> a
emptyError-- corresponding pairs of bytes. If one input 'Text' is short,fun = P.error ("Data.Text.Lazy." ++ fun ++ ": empty input")
-- excess elements of the longer 'Text' are discarded. This is
impossibleError-- equivalent to a pair of 'unpack' operations.:: String -> a
zipimpossibleError:: Text -> Textfun ->= P.error(Char,Char("Data.Text.Lazy.")]             ++ fun ++ ": impossible case")

</pre>